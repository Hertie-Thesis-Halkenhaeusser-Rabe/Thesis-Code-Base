{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python3.8-venv is already the newest version (3.8.10-0ubuntu1~20.04.6).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!yes | sudo apt install python3.8-venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "g++ is already the newest version (4:9.3.0-1ubuntu2).\n",
      "gcc is already the newest version (4:9.3.0-1ubuntu2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install gcc g\\+\\+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: detectron2 0.6+cu111\n",
      "Uninstalling detectron2-0.6+cu111:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.8/dist-packages/detectron2-0.6+cu111.dist-info/*\n",
      "    /usr/local/lib/python3.8/dist-packages/detectron2/*\n",
      "    /usr/local/lib/python3.8/dist-packages/tools/*\n",
      "Proceed (Y/n)?   Successfully uninstalled detectron2-0.6+cu111\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0myes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!yes | pip uninstall detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#johannes try\n",
    "#!pip install torch==1.10.1 torchvision==0.11.2 torchaudio==0.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /usr/local/lib/python3.8/dist-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /usr/local/lib/python3.8/dist-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0+cu111) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (1.23.4)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (9.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# dinah try\n",
    "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to remove old detectron installations\n",
    "!rm -r detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ninja in /usr/local/lib/python3.8/dist-packages (1.11.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools==58.2.0 in /usr/local/lib/python3.8/dist-packages (58.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install setuptools==58.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure detectron installation files knows where to find torch\n",
    "!LD_LIBRARY_PATH=.../python3.9/site-packages/torch/lib/nvidia/cublas/lib/:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22911,
     "status": "ok",
     "timestamp": 1675596988114,
     "user": {
      "displayName": "Johannes Halkenhäußer",
      "userId": "10212423884318197669"
     },
     "user_tz": -60
    },
    "id": "BnpY8yjyK4Mw",
    "outputId": "1b95e374-5a76-45af-a0d5-8abdfcabf71d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml==5.3.1\n",
      "  Using cached PyYAML-5.3.1-cp38-cp38-linux_x86_64.whl\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.1\n",
      "    Uninstalling PyYAML-5.1:\n",
      "      Successfully uninstalled PyYAML-5.1\n",
      "Successfully installed pyyaml-5.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCloning into 'detectron2'...\n",
      "remote: Enumerating objects: 14935, done.\u001b[K\n",
      "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 14935 (delta 7), reused 13 (delta 3), pack-reused 14915\u001b[K\n",
      "Receiving objects: 100% (14935/14935), 6.06 MiB | 20.74 MiB/s, done.\n",
      "Resolving deltas: 100% (10823/10823), done.\n",
      "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.8/dist-packages (9.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.6.2)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.8/dist-packages (2.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (2.1.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.8/dist-packages (0.1.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (2.2.1)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.8/dist-packages (4.65.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.8/dist-packages (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.8/dist-packages (0.1.9)\n",
      "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.8/dist-packages (1.3.2)\n",
      "Requirement already satisfied: black in /usr/local/lib/python3.8/dist-packages (21.4b2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs>=0.1.8) (5.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.28.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.14.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (58.2.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.38.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.50.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath<0.1.10,>=0.1.7) (2.7.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.8/dist-packages (from omegaconf>=2.1) (4.9.3)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.1) (5.10.0)\n",
      "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from black) (0.10.2)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.8/dist-packages (from black) (1.4.4)\n",
      "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.8/dist-packages (from black) (2023.3.22)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from black) (1.0.0)\n",
      "Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from black) (0.11.0)\n",
      "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from black) (8.1.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.14.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (5.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard) (2019.11.28)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core>=1.1) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyyaml==5.3.1\n",
    "import sys, os, distutils.core\n",
    "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1675596988546,
     "user": {
      "displayName": "Johannes Halkenhäußer",
      "userId": "10212423884318197669"
     },
     "user_tz": -60
    },
    "id": "8lbUPGorLIfW",
    "outputId": "b0b28677-7ab1-44cc-930c-51a88084f46b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Sun_Feb_14_21:12:58_PST_2021\n",
      "Cuda compilation tools, release 11.2, V11.2.152\n",
      "Build cuda_11.2.r11.2/compiler.29618528_0\n",
      "torch:  1.9 ; cuda:  cu111\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import sys, os, distutils.core\n",
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.23.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libgl1-mesa-glx is already the newest version (21.2.6-0ubuntu0.1~20.04.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!yes | sudo apt-get install libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1675596989273,
     "user": {
      "displayName": "Johannes Halkenhäußer",
      "userId": "10212423884318197669"
     },
     "user_tz": -60
    },
    "id": "r3tW5K73LMHw"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!LD_LIBRARY_PATH=.../python3.9/site-packages/cv2/:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/scripts'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1675524173583,
     "user": {
      "displayName": "Johannes Halkenhäußer",
      "userId": "10212423884318197669"
     },
     "user_tz": -60
    },
    "id": "BSV7C6p6Lv5O",
    "outputId": "416da254-8c50-4a02-c018-dae71b11402b"
   },
   "outputs": [],
   "source": [
    "## CRASHT DAS KERNEL !!\n",
    "#cv2.imshow(\"testimage\", im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN3QOxMvYtPb"
   },
   "source": [
    "## Train on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 3                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=3, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set a counter to register the same dataset again under a different name when we are debugging\n",
    "global regis_num \n",
    "regis_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://eidos-ai.medium.com/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e\n",
    "# https://gist.github.com/ortegatron/c0dad15e49c2b74de8bb09a5615d9f6b\n",
    "\n",
    "from EvalLossHook import LossEvalHook\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import DatasetMapper\n",
    "\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "                     \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1,LossEvalHook(\n",
    "            self.cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg,True)\n",
    "            )\n",
    "        ))\n",
    "        return hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1675597987945,
     "user": {
      "displayName": "Johannes Halkenhäußer",
      "userId": "10212423884318197669"
     },
     "user_tz": -60
    },
    "id": "_3jmsmS_M5pU"
   },
   "outputs": [],
   "source": [
    "def train_detectron_standard(dataset_name_train, dataset_name_val, resolution, batch_size=2):\n",
    "\n",
    "    '''\n",
    "    func:   trains a standard detectron model with the given dataset name\n",
    "\n",
    "    inputs:\n",
    "    dataset_name_train: string name of the dataset that was registered with COCODataset\n",
    "    resolution:         the resolution that the images have\n",
    "\n",
    "    returns:\n",
    "    cfg:        configurations object\n",
    "    trainer:    trainer object from the model\n",
    "    predictor:  predictor object from the model\n",
    "    '''\n",
    "    now = datetime.now() \n",
    "    output_dir = f\"/workspace/output/output_res{resolution}_bs{str(batch_size)}_{now.strftime('%m.%d.%H.%M')}\"\n",
    "    print(\"OUTPUT DIR:\" ,output_dir)\n",
    "    cfg = get_cfg()\n",
    "    cfg.INPUT.FORMAT = \"RGB\"\n",
    "    \n",
    "    # try different model: changed to X101 FPN: faster_rcnn_X_101_32x8d_FPN_3x\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.OUTPUT_DIR = output_dir\n",
    "    cfg.DATASETS.TRAIN = (dataset_name_train)\n",
    "    cfg.DATASETS.TEST = (dataset_name_val,)\n",
    "    cfg.TEST.EVAL_PERIOD = 2000\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[4, 8, 16, 32, 64]]\n",
    "    cfg.SOLVER.IMS_PER_BATCH = batch_size  # This is the real \"batch size\" commonly known to deep learning people\n",
    "    cfg.SOLVER.BASE_LR = 0.000025  # pick a good LR - davor\n",
    "    cfg.SOLVER.MAX_ITER = 6000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "    cfg.SOLVER.STEPS = [2500,4000,5000]        # decay learning rate\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # has two plus one classes transmission and distribution tower + other towers. (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "    # NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "    #print(cfg.OUTPUT_DIR)\n",
    "\n",
    "\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = MyTrainer(cfg) \n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "    # Inference should use the config with parameters that are used in training\n",
    "    # cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   # set a custom testing threshold\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "    return cfg, trainer, predictor\n",
    "\n",
    "def evaluate_detectron(cfg, predictor_obj, resolution, dataset_name_val): \n",
    "\n",
    "    \"\"\"\n",
    "    func:   evaluates a trained detectron model\n",
    "\n",
    "    input:\n",
    "    cfg:                configuration object of the model\n",
    "    predictor_obj:      the predictor object of the same model \n",
    "    resolution:         the resolution of the images\n",
    "    dataset_name_val:   the COCO registered name of the val dataset\n",
    "\n",
    "    returns:            dictionary with model metrics \n",
    "    \"\"\"\n",
    "\n",
    "    evaluator = COCOEvaluator(dataset_name_val, output_dir=\"/workspace/output/output\"+str(resolution), max_dets_per_image = 30)\n",
    "    val_loader = build_detection_test_loader(cfg, dataset_name_val)\n",
    "    \n",
    "    return inference_on_dataset(predictor_obj.model, val_loader, evaluator)\n",
    "    # another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg = get_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CUDNN_BENCHMARK': False,\n",
      " 'DATALOADER': {'ASPECT_RATIO_GROUPING': True,\n",
      "                'FILTER_EMPTY_ANNOTATIONS': True,\n",
      "                'NUM_WORKERS': 4,\n",
      "                'REPEAT_THRESHOLD': 0.0,\n",
      "                'SAMPLER_TRAIN': 'TrainingSampler'},\n",
      " 'DATASETS': {'PRECOMPUTED_PROPOSAL_TOPK_TEST': 1000,\n",
      "              'PRECOMPUTED_PROPOSAL_TOPK_TRAIN': 2000,\n",
      "              'PROPOSAL_FILES_TEST': (),\n",
      "              'PROPOSAL_FILES_TRAIN': (),\n",
      "              'TEST': (),\n",
      "              'TRAIN': ()},\n",
      " 'GLOBAL': CfgNode({'HACK': 1.0}),\n",
      " 'INPUT': {'CROP': {'ENABLED': False,\n",
      "                    'SIZE': [0.9, 0.9],\n",
      "                    'TYPE': 'relative_range'},\n",
      "           'FORMAT': 'BGR',\n",
      "           'MASK_FORMAT': 'polygon',\n",
      "           'MAX_SIZE_TEST': 1333,\n",
      "           'MAX_SIZE_TRAIN': 1333,\n",
      "           'MIN_SIZE_TEST': 800,\n",
      "           'MIN_SIZE_TRAIN': (800,),\n",
      "           'MIN_SIZE_TRAIN_SAMPLING': 'choice',\n",
      "           'RANDOM_FLIP': 'horizontal'},\n",
      " 'MODEL': {'ANCHOR_GENERATOR': {'ANGLES': [[-90, 0, 90]],\n",
      "                                'ASPECT_RATIOS': [[0.5, 1.0, 2.0]],\n",
      "                                'NAME': 'DefaultAnchorGenerator',\n",
      "                                'OFFSET': 0.0,\n",
      "                                'SIZES': [[32, 64, 128, 256, 512]]},\n",
      "           'BACKBONE': {'FREEZE_AT': 2,\n",
      "                        'NAME': 'build_resnet_backbone'},\n",
      "           'DEVICE': 'cuda',\n",
      "           'FPN': {'FUSE_TYPE': 'sum',\n",
      "                   'IN_FEATURES': [],\n",
      "                   'NORM': '',\n",
      "                   'OUT_CHANNELS': 256},\n",
      "           'KEYPOINT_ON': False,\n",
      "           'LOAD_PROPOSALS': False,\n",
      "           'MASK_ON': False,\n",
      "           'META_ARCHITECTURE': 'GeneralizedRCNN',\n",
      "           'PANOPTIC_FPN': {'COMBINE': {'ENABLED': True,\n",
      "                                        'INSTANCES_CONFIDENCE_THRESH': 0.5,\n",
      "                                        'OVERLAP_THRESH': 0.5,\n",
      "                                        'STUFF_AREA_LIMIT': 4096},\n",
      "                            'INSTANCE_LOSS_WEIGHT': 1.0},\n",
      "           'PIXEL_MEAN': [103.53, 116.28, 123.675],\n",
      "           'PIXEL_STD': [1.0, 1.0, 1.0],\n",
      "           'PROPOSAL_GENERATOR': CfgNode({'NAME': 'RPN', 'MIN_SIZE': 0}),\n",
      "           'RESNETS': {'DEFORM_MODULATED': False,\n",
      "                       'DEFORM_NUM_GROUPS': 1,\n",
      "                       'DEFORM_ON_PER_STAGE': [False, False, False, False],\n",
      "                       'DEPTH': 50,\n",
      "                       'NORM': 'FrozenBN',\n",
      "                       'NUM_GROUPS': 1,\n",
      "                       'OUT_FEATURES': ['res4'],\n",
      "                       'RES2_OUT_CHANNELS': 256,\n",
      "                       'RES5_DILATION': 1,\n",
      "                       'STEM_OUT_CHANNELS': 64,\n",
      "                       'STRIDE_IN_1X1': True,\n",
      "                       'WIDTH_PER_GROUP': 64},\n",
      "           'RETINANET': {'BBOX_REG_LOSS_TYPE': 'smooth_l1',\n",
      "                         'BBOX_REG_WEIGHTS': (1.0, 1.0, 1.0, 1.0),\n",
      "                         'FOCAL_LOSS_ALPHA': 0.25,\n",
      "                         'FOCAL_LOSS_GAMMA': 2.0,\n",
      "                         'IN_FEATURES': ['p3', 'p4', 'p5', 'p6', 'p7'],\n",
      "                         'IOU_LABELS': [0, -1, 1],\n",
      "                         'IOU_THRESHOLDS': [0.4, 0.5],\n",
      "                         'NMS_THRESH_TEST': 0.5,\n",
      "                         'NORM': '',\n",
      "                         'NUM_CLASSES': 80,\n",
      "                         'NUM_CONVS': 4,\n",
      "                         'PRIOR_PROB': 0.01,\n",
      "                         'SCORE_THRESH_TEST': 0.05,\n",
      "                         'SMOOTH_L1_LOSS_BETA': 0.1,\n",
      "                         'TOPK_CANDIDATES_TEST': 1000},\n",
      "           'ROI_BOX_CASCADE_HEAD': {'BBOX_REG_WEIGHTS': ((10.0, 10.0, 5.0, 5.0),\n",
      "                                                         (20.0,\n",
      "                                                          20.0,\n",
      "                                                          10.0,\n",
      "                                                          10.0),\n",
      "                                                         (30.0,\n",
      "                                                          30.0,\n",
      "                                                          15.0,\n",
      "                                                          15.0)),\n",
      "                                    'IOUS': (0.5, 0.6, 0.7)},\n",
      "           'ROI_BOX_HEAD': {'BBOX_REG_LOSS_TYPE': 'smooth_l1',\n",
      "                            'BBOX_REG_LOSS_WEIGHT': 1.0,\n",
      "                            'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),\n",
      "                            'CLS_AGNOSTIC_BBOX_REG': False,\n",
      "                            'CONV_DIM': 256,\n",
      "                            'FC_DIM': 1024,\n",
      "                            'FED_LOSS_FREQ_WEIGHT_POWER': 0.5,\n",
      "                            'FED_LOSS_NUM_CLASSES': 50,\n",
      "                            'NAME': '',\n",
      "                            'NORM': '',\n",
      "                            'NUM_CONV': 0,\n",
      "                            'NUM_FC': 0,\n",
      "                            'POOLER_RESOLUTION': 14,\n",
      "                            'POOLER_SAMPLING_RATIO': 0,\n",
      "                            'POOLER_TYPE': 'ROIAlignV2',\n",
      "                            'SMOOTH_L1_BETA': 0.0,\n",
      "                            'TRAIN_ON_PRED_BOXES': False,\n",
      "                            'USE_FED_LOSS': False,\n",
      "                            'USE_SIGMOID_CE': False},\n",
      "           'ROI_HEADS': {'BATCH_SIZE_PER_IMAGE': 512,\n",
      "                         'IN_FEATURES': ['res4'],\n",
      "                         'IOU_LABELS': [0, 1],\n",
      "                         'IOU_THRESHOLDS': [0.5],\n",
      "                         'NAME': 'Res5ROIHeads',\n",
      "                         'NMS_THRESH_TEST': 0.5,\n",
      "                         'NUM_CLASSES': 80,\n",
      "                         'POSITIVE_FRACTION': 0.25,\n",
      "                         'PROPOSAL_APPEND_GT': True,\n",
      "                         'SCORE_THRESH_TEST': 0.05},\n",
      "           'ROI_KEYPOINT_HEAD': {'CONV_DIMS': (512,\n",
      "                                               512,\n",
      "                                               512,\n",
      "                                               512,\n",
      "                                               512,\n",
      "                                               512,\n",
      "                                               512,\n",
      "                                               512),\n",
      "                                 'LOSS_WEIGHT': 1.0,\n",
      "                                 'MIN_KEYPOINTS_PER_IMAGE': 1,\n",
      "                                 'NAME': 'KRCNNConvDeconvUpsampleHead',\n",
      "                                 'NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS': True,\n",
      "                                 'NUM_KEYPOINTS': 17,\n",
      "                                 'POOLER_RESOLUTION': 14,\n",
      "                                 'POOLER_SAMPLING_RATIO': 0,\n",
      "                                 'POOLER_TYPE': 'ROIAlignV2'},\n",
      "           'ROI_MASK_HEAD': {'CLS_AGNOSTIC_MASK': False,\n",
      "                             'CONV_DIM': 256,\n",
      "                             'NAME': 'MaskRCNNConvUpsampleHead',\n",
      "                             'NORM': '',\n",
      "                             'NUM_CONV': 0,\n",
      "                             'POOLER_RESOLUTION': 14,\n",
      "                             'POOLER_SAMPLING_RATIO': 0,\n",
      "                             'POOLER_TYPE': 'ROIAlignV2'},\n",
      "           'RPN': {'BATCH_SIZE_PER_IMAGE': 256,\n",
      "                   'BBOX_REG_LOSS_TYPE': 'smooth_l1',\n",
      "                   'BBOX_REG_LOSS_WEIGHT': 1.0,\n",
      "                   'BBOX_REG_WEIGHTS': (1.0, 1.0, 1.0, 1.0),\n",
      "                   'BOUNDARY_THRESH': -1,\n",
      "                   'CONV_DIMS': [-1],\n",
      "                   'HEAD_NAME': 'StandardRPNHead',\n",
      "                   'IN_FEATURES': ['res4'],\n",
      "                   'IOU_LABELS': [0, -1, 1],\n",
      "                   'IOU_THRESHOLDS': [0.3, 0.7],\n",
      "                   'LOSS_WEIGHT': 1.0,\n",
      "                   'NMS_THRESH': 0.7,\n",
      "                   'POSITIVE_FRACTION': 0.5,\n",
      "                   'POST_NMS_TOPK_TEST': 1000,\n",
      "                   'POST_NMS_TOPK_TRAIN': 2000,\n",
      "                   'PRE_NMS_TOPK_TEST': 6000,\n",
      "                   'PRE_NMS_TOPK_TRAIN': 12000,\n",
      "                   'SMOOTH_L1_BETA': 0.0},\n",
      "           'SEM_SEG_HEAD': {'COMMON_STRIDE': 4,\n",
      "                            'CONVS_DIM': 128,\n",
      "                            'IGNORE_VALUE': 255,\n",
      "                            'IN_FEATURES': ['p2', 'p3', 'p4', 'p5'],\n",
      "                            'LOSS_WEIGHT': 1.0,\n",
      "                            'NAME': 'SemSegFPNHead',\n",
      "                            'NORM': 'GN',\n",
      "                            'NUM_CLASSES': 54},\n",
      "           'WEIGHTS': ''},\n",
      " 'OUTPUT_DIR': './output',\n",
      " 'SEED': -1,\n",
      " 'SOLVER': {'AMP': CfgNode({'ENABLED': False}),\n",
      "            'BASE_LR': 0.001,\n",
      "            'BASE_LR_END': 0.0,\n",
      "            'BIAS_LR_FACTOR': 1.0,\n",
      "            'CHECKPOINT_PERIOD': 5000,\n",
      "            'CLIP_GRADIENTS': {'CLIP_TYPE': 'value',\n",
      "                               'CLIP_VALUE': 1.0,\n",
      "                               'ENABLED': False,\n",
      "                               'NORM_TYPE': 2.0},\n",
      "            'GAMMA': 0.1,\n",
      "            'IMS_PER_BATCH': 16,\n",
      "            'LR_SCHEDULER_NAME': 'WarmupMultiStepLR',\n",
      "            'MAX_ITER': 40000,\n",
      "            'MOMENTUM': 0.9,\n",
      "            'NESTEROV': False,\n",
      "            'NUM_DECAYS': 3,\n",
      "            'REFERENCE_WORLD_SIZE': 0,\n",
      "            'RESCALE_INTERVAL': False,\n",
      "            'STEPS': (30000,),\n",
      "            'WARMUP_FACTOR': 0.001,\n",
      "            'WARMUP_ITERS': 1000,\n",
      "            'WARMUP_METHOD': 'linear',\n",
      "            'WEIGHT_DECAY': 0.0001,\n",
      "            'WEIGHT_DECAY_BIAS': None,\n",
      "            'WEIGHT_DECAY_NORM': 0.0},\n",
      " 'TEST': {'AUG': {'ENABLED': False,\n",
      "                  'FLIP': True,\n",
      "                  'MAX_SIZE': 4000,\n",
      "                  'MIN_SIZES': (400,\n",
      "                                500,\n",
      "                                600,\n",
      "                                700,\n",
      "                                800,\n",
      "                                900,\n",
      "                                1000,\n",
      "                                1100,\n",
      "                                1200)},\n",
      "          'DETECTIONS_PER_IMAGE': 100,\n",
      "          'EVAL_PERIOD': 0,\n",
      "          'EXPECTED_RESULTS': [],\n",
      "          'KEYPOINT_OKS_SIGMAS': [],\n",
      "          'PRECISE_BN': CfgNode({'ENABLED': False, 'NUM_ITER': 200})},\n",
      " 'VERSION': 2,\n",
      " 'VIS_PERIOD': 0}\n"
     ]
    }
   ],
   "source": [
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes for parameters\n",
    "# max_dets_per_image Anzahl zu detektierender Objekte - wir haben Bilder mit bis zu 30 Türmen\n",
    "# set learning rate von 0.00025 auf 0.0025\n",
    "# set training iterations von 300 auf 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments to conduct / TODO\n",
    "\n",
    "- train, val, test split\n",
    "- loss curves plotten\n",
    "- influence of batch size \n",
    "- ROI heads verkleinern\n",
    "- learning rate\n",
    "- image augmentation when training in loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 957,
     "status": "ok",
     "timestamp": 1675597055542,
     "user": {
      "displayName": "Johannes Halkenhäußer",
      "userId": "10212423884318197669"
     },
     "user_tz": -60
    },
    "id": "dSa1Eb7TLqi4"
   },
   "outputs": [],
   "source": [
    "base_path = '/workspace/data/'\n",
    "\n",
    "#im = cv2.imread(base_path + \"data_30/data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/data/'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378640,
     "status": "ok",
     "timestamp": 1675598377847,
     "user": {
      "displayName": "Johannes Halkenhäußer",
      "userId": "10212423884318197669"
     },
     "user_tz": -60
    },
    "id": "0b-MYQIACp-m",
    "outputId": "50bba6ff-00ff-40b6-dbce-1fc24aad11c7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT DIR: /workspace/output/output_res030_bs2_03.22.13.44\n",
      "[03/22 13:44:22 d2.engine.defaults]: Model:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING [03/22 13:44:22 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/22 13:44:22 d2.data.datasets.coco]: Loaded 11696 images in COCO format from /workspace/data/labels_train.json\n",
      "[03/22 13:44:23 d2.data.build]: Removed 0 images with no usable annotations. 11696 images left.\n",
      "[03/22 13:44:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "[03/22 13:44:23 d2.data.build]: Using training sampler TrainingSampler\n",
      "[03/22 13:44:23 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "[03/22 13:44:23 d2.data.common]: Serializing 11696 elements to byte tensors and concatenating them all ...\n",
      "[03/22 13:44:23 d2.data.common]: Serialized dataset takes 5.84 MiB\n",
      "[03/22 13:44:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "WARNING [03/22 13:44:23 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/22 13:44:23 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/22 13:44:23 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "[03/22 13:44:23 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/22 13:44:23 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "[03/22 13:44:23 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (15, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (60, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "proposal_generator.rpn_head.anchor_deltas.{bias, weight}\n",
      "proposal_generator.rpn_head.objectness_logits.{bias, weight}\n",
      "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
      "roi_heads.box_predictor.cls_score.{bias, weight}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:44:23 d2.engine.train_loop]: Starting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:44:25 d2.utils.events]:  eta: 0:07:51  iter: 19  total_loss: 2.288  loss_cls: 1.469  loss_box_reg: 0.001061  loss_rpn_cls: 0.7331  loss_rpn_loc: 0.09873    time: 0.0792  last_time: 0.0814  data_time: 0.0093  last_data_time: 0.0026   lr: 4.9952e-07  max_mem: 1980M\n",
      "[03/22 13:44:27 d2.utils.events]:  eta: 0:07:52  iter: 39  total_loss: 2.207  loss_cls: 1.399  loss_box_reg: 0.0008541  loss_rpn_cls: 0.7285  loss_rpn_loc: 0.07259    time: 0.0788  last_time: 0.0779  data_time: 0.0029  last_data_time: 0.0025   lr: 9.9902e-07  max_mem: 1980M\n",
      "[03/22 13:44:28 d2.utils.events]:  eta: 0:07:46  iter: 59  total_loss: 2.076  loss_cls: 1.287  loss_box_reg: 0.0007109  loss_rpn_cls: 0.7251  loss_rpn_loc: 0.05513    time: 0.0779  last_time: 0.0789  data_time: 0.0026  last_data_time: 0.0023   lr: 1.4985e-06  max_mem: 1980M\n",
      "[03/22 13:44:30 d2.utils.events]:  eta: 0:07:41  iter: 79  total_loss: 1.928  loss_cls: 1.117  loss_box_reg: 0.0004985  loss_rpn_cls: 0.7285  loss_rpn_loc: 0.06366    time: 0.0776  last_time: 0.0799  data_time: 0.0028  last_data_time: 0.0023   lr: 1.998e-06  max_mem: 1980M\n",
      "[03/22 13:44:31 d2.utils.events]:  eta: 0:07:39  iter: 99  total_loss: 1.704  loss_cls: 0.9011  loss_box_reg: 0.0007022  loss_rpn_cls: 0.7215  loss_rpn_loc: 0.07486    time: 0.0778  last_time: 0.0815  data_time: 0.0027  last_data_time: 0.0024   lr: 2.4975e-06  max_mem: 1980M\n",
      "[03/22 13:44:33 d2.utils.events]:  eta: 0:07:41  iter: 119  total_loss: 1.532  loss_cls: 0.7164  loss_box_reg: 0.0007276  loss_rpn_cls: 0.7227  loss_rpn_loc: 0.07792    time: 0.0781  last_time: 0.0780  data_time: 0.0027  last_data_time: 0.0024   lr: 2.997e-06  max_mem: 1980M\n",
      "[03/22 13:44:35 d2.utils.events]:  eta: 0:07:36  iter: 139  total_loss: 1.375  loss_cls: 0.5617  loss_box_reg: 0.0008804  loss_rpn_cls: 0.7213  loss_rpn_loc: 0.07465    time: 0.0779  last_time: 0.0765  data_time: 0.0028  last_data_time: 0.0025   lr: 3.4965e-06  max_mem: 1994M\n",
      "[03/22 13:44:36 d2.utils.events]:  eta: 0:07:33  iter: 159  total_loss: 1.246  loss_cls: 0.4469  loss_box_reg: 0.0004743  loss_rpn_cls: 0.7128  loss_rpn_loc: 0.08633    time: 0.0776  last_time: 0.0726  data_time: 0.0027  last_data_time: 0.0027   lr: 3.996e-06  max_mem: 1994M\n",
      "[03/22 13:44:38 d2.utils.events]:  eta: 0:07:30  iter: 179  total_loss: 1.131  loss_cls: 0.3433  loss_box_reg: 0.0003699  loss_rpn_cls: 0.711  loss_rpn_loc: 0.04985    time: 0.0774  last_time: 0.0777  data_time: 0.0029  last_data_time: 0.0031   lr: 4.4955e-06  max_mem: 1994M\n",
      "[03/22 13:44:39 d2.utils.events]:  eta: 0:07:27  iter: 199  total_loss: 1.068  loss_cls: 0.2686  loss_box_reg: 0.0006398  loss_rpn_cls: 0.7061  loss_rpn_loc: 0.06525    time: 0.0773  last_time: 0.0768  data_time: 0.0029  last_data_time: 0.0023   lr: 4.995e-06  max_mem: 1994M\n",
      "[03/22 13:44:41 d2.utils.events]:  eta: 0:07:26  iter: 219  total_loss: 0.9904  loss_cls: 0.2225  loss_box_reg: 0.000389  loss_rpn_cls: 0.6976  loss_rpn_loc: 0.06487    time: 0.0773  last_time: 0.0761  data_time: 0.0025  last_data_time: 0.0028   lr: 5.4945e-06  max_mem: 1998M\n",
      "[03/22 13:44:42 d2.utils.events]:  eta: 0:07:25  iter: 239  total_loss: 0.9375  loss_cls: 0.1745  loss_box_reg: 0.0002507  loss_rpn_cls: 0.6963  loss_rpn_loc: 0.06069    time: 0.0774  last_time: 0.0796  data_time: 0.0028  last_data_time: 0.0023   lr: 5.994e-06  max_mem: 1998M\n",
      "[03/22 13:44:44 d2.utils.events]:  eta: 0:07:24  iter: 259  total_loss: 0.9157  loss_cls: 0.1496  loss_box_reg: 0.0004323  loss_rpn_cls: 0.6899  loss_rpn_loc: 0.07566    time: 0.0774  last_time: 0.0784  data_time: 0.0027  last_data_time: 0.0031   lr: 6.4935e-06  max_mem: 1998M\n",
      "[03/22 13:44:45 d2.utils.events]:  eta: 0:07:22  iter: 279  total_loss: 0.8917  loss_cls: 0.117  loss_box_reg: 0.0002251  loss_rpn_cls: 0.6795  loss_rpn_loc: 0.07546    time: 0.0774  last_time: 0.0766  data_time: 0.0026  last_data_time: 0.0022   lr: 6.993e-06  max_mem: 1998M\n",
      "[03/22 13:44:47 d2.utils.events]:  eta: 0:07:22  iter: 299  total_loss: 0.8985  loss_cls: 0.1172  loss_box_reg: 0.0003413  loss_rpn_cls: 0.6714  loss_rpn_loc: 0.08643    time: 0.0775  last_time: 0.0734  data_time: 0.0026  last_data_time: 0.0024   lr: 7.4925e-06  max_mem: 2052M\n",
      "[03/22 13:44:49 d2.utils.events]:  eta: 0:07:20  iter: 319  total_loss: 0.8432  loss_cls: 0.1065  loss_box_reg: 0.0003701  loss_rpn_cls: 0.6663  loss_rpn_loc: 0.06502    time: 0.0777  last_time: 0.0802  data_time: 0.0026  last_data_time: 0.0024   lr: 7.992e-06  max_mem: 2052M\n",
      "[03/22 13:44:50 d2.utils.events]:  eta: 0:07:19  iter: 339  total_loss: 0.814  loss_cls: 0.09036  loss_box_reg: 0.0002795  loss_rpn_cls: 0.6549  loss_rpn_loc: 0.06019    time: 0.0776  last_time: 0.0799  data_time: 0.0025  last_data_time: 0.0025   lr: 8.4915e-06  max_mem: 2052M\n",
      "[03/22 13:44:52 d2.utils.events]:  eta: 0:07:18  iter: 359  total_loss: 0.8538  loss_cls: 0.09789  loss_box_reg: 0.0003382  loss_rpn_cls: 0.6507  loss_rpn_loc: 0.07903    time: 0.0778  last_time: 0.0829  data_time: 0.0026  last_data_time: 0.0026   lr: 8.991e-06  max_mem: 2052M\n",
      "[03/22 13:44:53 d2.utils.events]:  eta: 0:07:17  iter: 379  total_loss: 0.8148  loss_cls: 0.09951  loss_box_reg: 0.0003162  loss_rpn_cls: 0.6438  loss_rpn_loc: 0.07443    time: 0.0779  last_time: 0.0800  data_time: 0.0027  last_data_time: 0.0025   lr: 9.4905e-06  max_mem: 2052M\n",
      "[03/22 13:44:55 d2.utils.events]:  eta: 0:07:15  iter: 399  total_loss: 0.8063  loss_cls: 0.08874  loss_box_reg: 0.000339  loss_rpn_cls: 0.6257  loss_rpn_loc: 0.06588    time: 0.0779  last_time: 0.0788  data_time: 0.0026  last_data_time: 0.0023   lr: 9.99e-06  max_mem: 2052M\n",
      "[03/22 13:44:57 d2.utils.events]:  eta: 0:07:14  iter: 419  total_loss: 0.7721  loss_cls: 0.09458  loss_box_reg: 0.0003407  loss_rpn_cls: 0.6106  loss_rpn_loc: 0.06133    time: 0.0780  last_time: 0.0833  data_time: 0.0027  last_data_time: 0.0034   lr: 1.049e-05  max_mem: 2052M\n",
      "[03/22 13:44:58 d2.utils.events]:  eta: 0:07:13  iter: 439  total_loss: 0.7851  loss_cls: 0.08289  loss_box_reg: 0.0002956  loss_rpn_cls: 0.608  loss_rpn_loc: 0.09431    time: 0.0780  last_time: 0.0796  data_time: 0.0025  last_data_time: 0.0024   lr: 1.0989e-05  max_mem: 2052M\n",
      "[03/22 13:45:00 d2.utils.events]:  eta: 0:07:11  iter: 459  total_loss: 0.7673  loss_cls: 0.08955  loss_box_reg: 0.0003496  loss_rpn_cls: 0.5935  loss_rpn_loc: 0.07168    time: 0.0779  last_time: 0.0752  data_time: 0.0027  last_data_time: 0.0031   lr: 1.1489e-05  max_mem: 2052M\n",
      "[03/22 13:45:01 d2.utils.events]:  eta: 0:07:09  iter: 479  total_loss: 0.7655  loss_cls: 0.09293  loss_box_reg: 0.0003284  loss_rpn_cls: 0.5833  loss_rpn_loc: 0.06206    time: 0.0780  last_time: 0.0783  data_time: 0.0028  last_data_time: 0.0025   lr: 1.1988e-05  max_mem: 2052M\n",
      "[03/22 13:45:03 d2.utils.events]:  eta: 0:07:08  iter: 499  total_loss: 0.7353  loss_cls: 0.09787  loss_box_reg: 0.000485  loss_rpn_cls: 0.5738  loss_rpn_loc: 0.0637    time: 0.0780  last_time: 0.0830  data_time: 0.0029  last_data_time: 0.0041   lr: 1.2488e-05  max_mem: 2070M\n",
      "[03/22 13:45:04 d2.utils.events]:  eta: 0:07:07  iter: 519  total_loss: 0.7249  loss_cls: 0.07863  loss_box_reg: 0.0003155  loss_rpn_cls: 0.5655  loss_rpn_loc: 0.07307    time: 0.0781  last_time: 0.0800  data_time: 0.0027  last_data_time: 0.0026   lr: 1.2987e-05  max_mem: 2070M\n",
      "[03/22 13:45:06 d2.utils.events]:  eta: 0:07:05  iter: 539  total_loss: 0.7167  loss_cls: 0.08034  loss_box_reg: 0.0002803  loss_rpn_cls: 0.5531  loss_rpn_loc: 0.0849    time: 0.0780  last_time: 0.0741  data_time: 0.0027  last_data_time: 0.0024   lr: 1.3487e-05  max_mem: 2070M\n",
      "[03/22 13:45:08 d2.utils.events]:  eta: 0:07:03  iter: 559  total_loss: 0.6994  loss_cls: 0.0897  loss_box_reg: 0.0004681  loss_rpn_cls: 0.5273  loss_rpn_loc: 0.07221    time: 0.0780  last_time: 0.0800  data_time: 0.0026  last_data_time: 0.0023   lr: 1.3986e-05  max_mem: 2070M\n",
      "[03/22 13:45:09 d2.utils.events]:  eta: 0:07:02  iter: 579  total_loss: 0.692  loss_cls: 0.0925  loss_box_reg: 0.0005736  loss_rpn_cls: 0.5194  loss_rpn_loc: 0.07168    time: 0.0781  last_time: 0.0753  data_time: 0.0028  last_data_time: 0.0026   lr: 1.4486e-05  max_mem: 2070M\n",
      "[03/22 13:45:11 d2.utils.events]:  eta: 0:07:01  iter: 599  total_loss: 0.6729  loss_cls: 0.07468  loss_box_reg: 0.0002848  loss_rpn_cls: 0.5071  loss_rpn_loc: 0.06808    time: 0.0781  last_time: 0.0774  data_time: 0.0028  last_data_time: 0.0028   lr: 1.4985e-05  max_mem: 2070M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:45:12 d2.utils.events]:  eta: 0:06:59  iter: 619  total_loss: 0.6134  loss_cls: 0.07789  loss_box_reg: 0.0003333  loss_rpn_cls: 0.4899  loss_rpn_loc: 0.05361    time: 0.0781  last_time: 0.0691  data_time: 0.0028  last_data_time: 0.0026   lr: 1.5485e-05  max_mem: 2070M\n",
      "[03/22 13:45:14 d2.utils.events]:  eta: 0:06:58  iter: 639  total_loss: 0.6407  loss_cls: 0.07595  loss_box_reg: 0.0004717  loss_rpn_cls: 0.4761  loss_rpn_loc: 0.0584    time: 0.0781  last_time: 0.0713  data_time: 0.0026  last_data_time: 0.0026   lr: 1.5984e-05  max_mem: 2070M\n",
      "[03/22 13:45:15 d2.utils.events]:  eta: 0:06:56  iter: 659  total_loss: 0.6612  loss_cls: 0.06434  loss_box_reg: 0.0005682  loss_rpn_cls: 0.4715  loss_rpn_loc: 0.08866    time: 0.0781  last_time: 0.0808  data_time: 0.0027  last_data_time: 0.0029   lr: 1.6484e-05  max_mem: 2070M\n",
      "[03/22 13:45:17 d2.utils.events]:  eta: 0:06:55  iter: 679  total_loss: 0.5724  loss_cls: 0.0517  loss_box_reg: 0.0002163  loss_rpn_cls: 0.4405  loss_rpn_loc: 0.0484    time: 0.0782  last_time: 0.0768  data_time: 0.0028  last_data_time: 0.0026   lr: 1.6983e-05  max_mem: 2070M\n",
      "[03/22 13:45:19 d2.utils.events]:  eta: 0:06:54  iter: 699  total_loss: 0.5568  loss_cls: 0.0556  loss_box_reg: 0.0005775  loss_rpn_cls: 0.4215  loss_rpn_loc: 0.05541    time: 0.0782  last_time: 0.0731  data_time: 0.0026  last_data_time: 0.0025   lr: 1.7483e-05  max_mem: 2070M\n",
      "[03/22 13:45:20 d2.utils.events]:  eta: 0:06:52  iter: 719  total_loss: 0.5809  loss_cls: 0.05497  loss_box_reg: 0.0002529  loss_rpn_cls: 0.4221  loss_rpn_loc: 0.06674    time: 0.0782  last_time: 0.0781  data_time: 0.0026  last_data_time: 0.0031   lr: 1.7982e-05  max_mem: 2070M\n",
      "[03/22 13:45:22 d2.utils.events]:  eta: 0:06:51  iter: 739  total_loss: 0.582  loss_cls: 0.08076  loss_box_reg: 0.004001  loss_rpn_cls: 0.4175  loss_rpn_loc: 0.07878    time: 0.0782  last_time: 0.0764  data_time: 0.0025  last_data_time: 0.0026   lr: 1.8482e-05  max_mem: 2070M\n",
      "[03/22 13:45:23 d2.utils.events]:  eta: 0:06:50  iter: 759  total_loss: 0.6118  loss_cls: 0.06827  loss_box_reg: 0.0007018  loss_rpn_cls: 0.4241  loss_rpn_loc: 0.08893    time: 0.0782  last_time: 0.0807  data_time: 0.0026  last_data_time: 0.0024   lr: 1.8981e-05  max_mem: 2070M\n",
      "[03/22 13:45:25 d2.utils.events]:  eta: 0:06:48  iter: 779  total_loss: 0.5925  loss_cls: 0.0739  loss_box_reg: 0.002368  loss_rpn_cls: 0.4018  loss_rpn_loc: 0.08541    time: 0.0782  last_time: 0.0724  data_time: 0.0026  last_data_time: 0.0026   lr: 1.9481e-05  max_mem: 2070M\n",
      "[03/22 13:45:26 d2.utils.events]:  eta: 0:06:46  iter: 799  total_loss: 0.5431  loss_cls: 0.05265  loss_box_reg: 0.0004081  loss_rpn_cls: 0.3921  loss_rpn_loc: 0.07241    time: 0.0782  last_time: 0.0798  data_time: 0.0027  last_data_time: 0.0027   lr: 1.998e-05  max_mem: 2070M\n",
      "[03/22 13:45:28 d2.utils.events]:  eta: 0:06:45  iter: 819  total_loss: 0.5211  loss_cls: 0.0569  loss_box_reg: 0.0003946  loss_rpn_cls: 0.3749  loss_rpn_loc: 0.07132    time: 0.0783  last_time: 0.0777  data_time: 0.0028  last_data_time: 0.0024   lr: 2.048e-05  max_mem: 2070M\n",
      "[03/22 13:45:30 d2.utils.events]:  eta: 0:06:43  iter: 839  total_loss: 0.4966  loss_cls: 0.05479  loss_box_reg: 0.0002781  loss_rpn_cls: 0.3552  loss_rpn_loc: 0.06335    time: 0.0783  last_time: 0.0813  data_time: 0.0028  last_data_time: 0.0026   lr: 2.0979e-05  max_mem: 2070M\n",
      "[03/22 13:45:31 d2.utils.events]:  eta: 0:06:42  iter: 859  total_loss: 0.4711  loss_cls: 0.07178  loss_box_reg: 0.0009708  loss_rpn_cls: 0.3447  loss_rpn_loc: 0.0532    time: 0.0783  last_time: 0.0830  data_time: 0.0026  last_data_time: 0.0024   lr: 2.1479e-05  max_mem: 2070M\n",
      "[03/22 13:45:33 d2.utils.events]:  eta: 0:06:40  iter: 879  total_loss: 0.4512  loss_cls: 0.05849  loss_box_reg: 0.0002723  loss_rpn_cls: 0.3237  loss_rpn_loc: 0.05582    time: 0.0783  last_time: 0.0826  data_time: 0.0026  last_data_time: 0.0026   lr: 2.1978e-05  max_mem: 2070M\n",
      "[03/22 13:45:34 d2.utils.events]:  eta: 0:06:39  iter: 899  total_loss: 0.5341  loss_cls: 0.07178  loss_box_reg: 0.0004281  loss_rpn_cls: 0.3508  loss_rpn_loc: 0.0912    time: 0.0783  last_time: 0.0775  data_time: 0.0027  last_data_time: 0.0033   lr: 2.2478e-05  max_mem: 2070M\n",
      "[03/22 13:45:36 d2.utils.events]:  eta: 0:06:37  iter: 919  total_loss: 0.5689  loss_cls: 0.0573  loss_box_reg: 0.001711  loss_rpn_cls: 0.3591  loss_rpn_loc: 0.102    time: 0.0783  last_time: 0.0772  data_time: 0.0026  last_data_time: 0.0024   lr: 2.2977e-05  max_mem: 2070M\n",
      "[03/22 13:45:38 d2.utils.events]:  eta: 0:06:36  iter: 939  total_loss: 0.4193  loss_cls: 0.04562  loss_box_reg: 0.003835  loss_rpn_cls: 0.2944  loss_rpn_loc: 0.05858    time: 0.0784  last_time: 0.0752  data_time: 0.0028  last_data_time: 0.0023   lr: 2.3477e-05  max_mem: 2070M\n",
      "[03/22 13:45:39 d2.utils.events]:  eta: 0:06:34  iter: 959  total_loss: 0.464  loss_cls: 0.06019  loss_box_reg: 0.0003197  loss_rpn_cls: 0.3193  loss_rpn_loc: 0.04994    time: 0.0783  last_time: 0.0761  data_time: 0.0026  last_data_time: 0.0025   lr: 2.3976e-05  max_mem: 2070M\n",
      "[03/22 13:45:41 d2.utils.events]:  eta: 0:06:32  iter: 979  total_loss: 0.3784  loss_cls: 0.05965  loss_box_reg: 0.0003128  loss_rpn_cls: 0.2749  loss_rpn_loc: 0.04399    time: 0.0783  last_time: 0.0810  data_time: 0.0029  last_data_time: 0.0028   lr: 2.4476e-05  max_mem: 2070M\n",
      "[03/22 13:45:42 d2.utils.events]:  eta: 0:06:31  iter: 999  total_loss: 0.4808  loss_cls: 0.05769  loss_box_reg: 0.0003728  loss_rpn_cls: 0.2964  loss_rpn_loc: 0.05903    time: 0.0783  last_time: 0.0771  data_time: 0.0030  last_data_time: 0.0029   lr: 2.4975e-05  max_mem: 2070M\n",
      "[03/22 13:45:44 d2.utils.events]:  eta: 0:06:29  iter: 1019  total_loss: 0.4775  loss_cls: 0.08173  loss_box_reg: 0.0005086  loss_rpn_cls: 0.3182  loss_rpn_loc: 0.06151    time: 0.0784  last_time: 0.0828  data_time: 0.0030  last_data_time: 0.0029   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:45:45 d2.utils.events]:  eta: 0:06:28  iter: 1039  total_loss: 0.4054  loss_cls: 0.0561  loss_box_reg: 0.003787  loss_rpn_cls: 0.2808  loss_rpn_loc: 0.07426    time: 0.0784  last_time: 0.0758  data_time: 0.0029  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:45:47 d2.utils.events]:  eta: 0:06:26  iter: 1059  total_loss: 0.4316  loss_cls: 0.05763  loss_box_reg: 0.002754  loss_rpn_cls: 0.287  loss_rpn_loc: 0.06254    time: 0.0784  last_time: 0.0812  data_time: 0.0029  last_data_time: 0.0024   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:45:49 d2.utils.events]:  eta: 0:06:25  iter: 1079  total_loss: 0.4341  loss_cls: 0.06041  loss_box_reg: 0.006051  loss_rpn_cls: 0.2737  loss_rpn_loc: 0.06278    time: 0.0784  last_time: 0.0842  data_time: 0.0028  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:45:50 d2.utils.events]:  eta: 0:06:23  iter: 1099  total_loss: 0.477  loss_cls: 0.0758  loss_box_reg: 0.0005458  loss_rpn_cls: 0.3101  loss_rpn_loc: 0.07434    time: 0.0784  last_time: 0.0792  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:45:52 d2.utils.events]:  eta: 0:06:22  iter: 1119  total_loss: 0.4584  loss_cls: 0.05994  loss_box_reg: 0.0003538  loss_rpn_cls: 0.3065  loss_rpn_loc: 0.07107    time: 0.0784  last_time: 0.0826  data_time: 0.0029  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:45:53 d2.utils.events]:  eta: 0:06:20  iter: 1139  total_loss: 0.403  loss_cls: 0.05846  loss_box_reg: 0.0003971  loss_rpn_cls: 0.2708  loss_rpn_loc: 0.06213    time: 0.0784  last_time: 0.0751  data_time: 0.0028  last_data_time: 0.0028   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:45:55 d2.utils.events]:  eta: 0:06:19  iter: 1159  total_loss: 0.4645  loss_cls: 0.05381  loss_box_reg: 0.00473  loss_rpn_cls: 0.2884  loss_rpn_loc: 0.08079    time: 0.0784  last_time: 0.0831  data_time: 0.0028  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:45:57 d2.utils.events]:  eta: 0:06:18  iter: 1179  total_loss: 0.4171  loss_cls: 0.05637  loss_box_reg: 0.001685  loss_rpn_cls: 0.2808  loss_rpn_loc: 0.06493    time: 0.0785  last_time: 0.0801  data_time: 0.0028  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:45:58 d2.utils.events]:  eta: 0:06:17  iter: 1199  total_loss: 0.5238  loss_cls: 0.07136  loss_box_reg: 0.002277  loss_rpn_cls: 0.3272  loss_rpn_loc: 0.09549    time: 0.0785  last_time: 0.0772  data_time: 0.0026  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2070M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:46:00 d2.utils.events]:  eta: 0:06:16  iter: 1219  total_loss: 0.5033  loss_cls: 0.06411  loss_box_reg: 0.0007001  loss_rpn_cls: 0.3148  loss_rpn_loc: 0.0868    time: 0.0785  last_time: 0.0831  data_time: 0.0027  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:01 d2.utils.events]:  eta: 0:06:14  iter: 1239  total_loss: 0.4416  loss_cls: 0.05609  loss_box_reg: 0.0002968  loss_rpn_cls: 0.2887  loss_rpn_loc: 0.07041    time: 0.0785  last_time: 0.0789  data_time: 0.0027  last_data_time: 0.0021   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:03 d2.utils.events]:  eta: 0:06:13  iter: 1259  total_loss: 0.3457  loss_cls: 0.05687  loss_box_reg: 0.004243  loss_rpn_cls: 0.2431  loss_rpn_loc: 0.04733    time: 0.0785  last_time: 0.0790  data_time: 0.0030  last_data_time: 0.0032   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:05 d2.utils.events]:  eta: 0:06:12  iter: 1279  total_loss: 0.366  loss_cls: 0.0543  loss_box_reg: 0.004783  loss_rpn_cls: 0.2384  loss_rpn_loc: 0.06116    time: 0.0786  last_time: 0.0877  data_time: 0.0031  last_data_time: 0.0038   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:06 d2.utils.events]:  eta: 0:06:11  iter: 1299  total_loss: 0.4207  loss_cls: 0.0544  loss_box_reg: 0.004439  loss_rpn_cls: 0.2736  loss_rpn_loc: 0.06403    time: 0.0786  last_time: 0.0818  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:08 d2.utils.events]:  eta: 0:06:09  iter: 1319  total_loss: 0.4496  loss_cls: 0.07  loss_box_reg: 0.004605  loss_rpn_cls: 0.2766  loss_rpn_loc: 0.06078    time: 0.0786  last_time: 0.0779  data_time: 0.0028  last_data_time: 0.0029   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:09 d2.utils.events]:  eta: 0:06:08  iter: 1339  total_loss: 0.4226  loss_cls: 0.07181  loss_box_reg: 0.004698  loss_rpn_cls: 0.268  loss_rpn_loc: 0.05462    time: 0.0786  last_time: 0.0795  data_time: 0.0027  last_data_time: 0.0024   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:11 d2.utils.events]:  eta: 0:06:06  iter: 1359  total_loss: 0.3837  loss_cls: 0.06587  loss_box_reg: 0.01069  loss_rpn_cls: 0.2453  loss_rpn_loc: 0.06801    time: 0.0786  last_time: 0.0799  data_time: 0.0026  last_data_time: 0.0028   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:13 d2.utils.events]:  eta: 0:06:04  iter: 1379  total_loss: 0.3887  loss_cls: 0.06145  loss_box_reg: 0.005974  loss_rpn_cls: 0.2481  loss_rpn_loc: 0.0535    time: 0.0787  last_time: 0.0790  data_time: 0.0028  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:14 d2.utils.events]:  eta: 0:06:03  iter: 1399  total_loss: 0.4363  loss_cls: 0.06012  loss_box_reg: 0.007846  loss_rpn_cls: 0.2832  loss_rpn_loc: 0.07013    time: 0.0787  last_time: 0.0762  data_time: 0.0028  last_data_time: 0.0024   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:16 d2.utils.events]:  eta: 0:06:01  iter: 1419  total_loss: 0.3995  loss_cls: 0.05374  loss_box_reg: 0.0003519  loss_rpn_cls: 0.266  loss_rpn_loc: 0.06858    time: 0.0787  last_time: 0.0781  data_time: 0.0026  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:17 d2.utils.events]:  eta: 0:06:00  iter: 1439  total_loss: 0.4051  loss_cls: 0.05968  loss_box_reg: 0.006127  loss_rpn_cls: 0.262  loss_rpn_loc: 0.07002    time: 0.0787  last_time: 0.0834  data_time: 0.0027  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:19 d2.utils.events]:  eta: 0:05:58  iter: 1459  total_loss: 0.4083  loss_cls: 0.04832  loss_box_reg: 0.00553  loss_rpn_cls: 0.2616  loss_rpn_loc: 0.06532    time: 0.0787  last_time: 0.0711  data_time: 0.0024  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:21 d2.utils.events]:  eta: 0:05:57  iter: 1479  total_loss: 0.4257  loss_cls: 0.05294  loss_box_reg: 0.006038  loss_rpn_cls: 0.2637  loss_rpn_loc: 0.08008    time: 0.0787  last_time: 0.0805  data_time: 0.0024  last_data_time: 0.0028   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:22 d2.utils.events]:  eta: 0:05:55  iter: 1499  total_loss: 0.4632  loss_cls: 0.0468  loss_box_reg: 0.005045  loss_rpn_cls: 0.2926  loss_rpn_loc: 0.08881    time: 0.0787  last_time: 0.0751  data_time: 0.0024  last_data_time: 0.0022   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:24 d2.utils.events]:  eta: 0:05:53  iter: 1519  total_loss: 0.4138  loss_cls: 0.06249  loss_box_reg: 0.006494  loss_rpn_cls: 0.2727  loss_rpn_loc: 0.08152    time: 0.0787  last_time: 0.0836  data_time: 0.0023  last_data_time: 0.0021   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:25 d2.utils.events]:  eta: 0:05:52  iter: 1539  total_loss: 0.355  loss_cls: 0.0549  loss_box_reg: 0.0003025  loss_rpn_cls: 0.2375  loss_rpn_loc: 0.05496    time: 0.0787  last_time: 0.0773  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:27 d2.utils.events]:  eta: 0:05:50  iter: 1559  total_loss: 0.4234  loss_cls: 0.07107  loss_box_reg: 0.01044  loss_rpn_cls: 0.2616  loss_rpn_loc: 0.06859    time: 0.0787  last_time: 0.0784  data_time: 0.0028  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2070M\n",
      "[03/22 13:46:28 d2.utils.events]:  eta: 0:05:49  iter: 1579  total_loss: 0.3668  loss_cls: 0.05775  loss_box_reg: 0.01409  loss_rpn_cls: 0.255  loss_rpn_loc: 0.05277    time: 0.0787  last_time: 0.0741  data_time: 0.0024  last_data_time: 0.0022   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:30 d2.utils.events]:  eta: 0:05:47  iter: 1599  total_loss: 0.491  loss_cls: 0.07501  loss_box_reg: 0.008673  loss_rpn_cls: 0.2817  loss_rpn_loc: 0.06443    time: 0.0787  last_time: 0.0753  data_time: 0.0024  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:32 d2.utils.events]:  eta: 0:05:45  iter: 1619  total_loss: 0.3434  loss_cls: 0.0554  loss_box_reg: 0.007684  loss_rpn_cls: 0.2255  loss_rpn_loc: 0.05548    time: 0.0787  last_time: 0.0762  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:33 d2.utils.events]:  eta: 0:05:44  iter: 1639  total_loss: 0.3845  loss_cls: 0.065  loss_box_reg: 0.004139  loss_rpn_cls: 0.2433  loss_rpn_loc: 0.05141    time: 0.0787  last_time: 0.0764  data_time: 0.0028  last_data_time: 0.0024   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:35 d2.utils.events]:  eta: 0:05:42  iter: 1659  total_loss: 0.3605  loss_cls: 0.03966  loss_box_reg: 0.002023  loss_rpn_cls: 0.2263  loss_rpn_loc: 0.04608    time: 0.0787  last_time: 0.0784  data_time: 0.0024  last_data_time: 0.0023   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:36 d2.utils.events]:  eta: 0:05:40  iter: 1679  total_loss: 0.4289  loss_cls: 0.06636  loss_box_reg: 0.01273  loss_rpn_cls: 0.2472  loss_rpn_loc: 0.08558    time: 0.0787  last_time: 0.0821  data_time: 0.0026  last_data_time: 0.0028   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:38 d2.utils.events]:  eta: 0:05:39  iter: 1699  total_loss: 0.4328  loss_cls: 0.0729  loss_box_reg: 0.00923  loss_rpn_cls: 0.2758  loss_rpn_loc: 0.06572    time: 0.0787  last_time: 0.0769  data_time: 0.0029  last_data_time: 0.0030   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:39 d2.utils.events]:  eta: 0:05:37  iter: 1719  total_loss: 0.3979  loss_cls: 0.06292  loss_box_reg: 0.006612  loss_rpn_cls: 0.2606  loss_rpn_loc: 0.06115    time: 0.0787  last_time: 0.0829  data_time: 0.0031  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:41 d2.utils.events]:  eta: 0:05:36  iter: 1739  total_loss: 0.3955  loss_cls: 0.05883  loss_box_reg: 0.006479  loss_rpn_cls: 0.252  loss_rpn_loc: 0.07201    time: 0.0787  last_time: 0.0764  data_time: 0.0027  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:43 d2.utils.events]:  eta: 0:05:34  iter: 1759  total_loss: 0.337  loss_cls: 0.05709  loss_box_reg: 0.005467  loss_rpn_cls: 0.2137  loss_rpn_loc: 0.03572    time: 0.0787  last_time: 0.0800  data_time: 0.0025  last_data_time: 0.0021   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:44 d2.utils.events]:  eta: 0:05:33  iter: 1779  total_loss: 0.3946  loss_cls: 0.046  loss_box_reg: 0.001636  loss_rpn_cls: 0.2394  loss_rpn_loc: 0.08133    time: 0.0787  last_time: 0.0835  data_time: 0.0025  last_data_time: 0.0022   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:46 d2.utils.events]:  eta: 0:05:31  iter: 1799  total_loss: 0.4576  loss_cls: 0.06007  loss_box_reg: 0.01561  loss_rpn_cls: 0.2633  loss_rpn_loc: 0.08679    time: 0.0787  last_time: 0.0822  data_time: 0.0025  last_data_time: 0.0023   lr: 2.5e-05  max_mem: 2107M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:46:47 d2.utils.events]:  eta: 0:05:29  iter: 1819  total_loss: 0.4487  loss_cls: 0.05514  loss_box_reg: 0.0002923  loss_rpn_cls: 0.2954  loss_rpn_loc: 0.08812    time: 0.0787  last_time: 0.0792  data_time: 0.0026  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:49 d2.utils.events]:  eta: 0:05:28  iter: 1839  total_loss: 0.447  loss_cls: 0.0521  loss_box_reg: 0.00398  loss_rpn_cls: 0.27  loss_rpn_loc: 0.1005    time: 0.0787  last_time: 0.0775  data_time: 0.0025  last_data_time: 0.0024   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:51 d2.utils.events]:  eta: 0:05:27  iter: 1859  total_loss: 0.3629  loss_cls: 0.04886  loss_box_reg: 0.0003334  loss_rpn_cls: 0.2422  loss_rpn_loc: 0.08505    time: 0.0787  last_time: 0.0770  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:52 d2.utils.events]:  eta: 0:05:25  iter: 1879  total_loss: 0.4086  loss_cls: 0.05107  loss_box_reg: 0.005178  loss_rpn_cls: 0.2366  loss_rpn_loc: 0.08806    time: 0.0787  last_time: 0.0803  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:54 d2.utils.events]:  eta: 0:05:24  iter: 1899  total_loss: 0.3603  loss_cls: 0.05735  loss_box_reg: 0.007193  loss_rpn_cls: 0.2208  loss_rpn_loc: 0.05375    time: 0.0788  last_time: 0.0824  data_time: 0.0027  last_data_time: 0.0023   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:55 d2.utils.events]:  eta: 0:05:22  iter: 1919  total_loss: 0.3957  loss_cls: 0.05864  loss_box_reg: 0.001675  loss_rpn_cls: 0.2436  loss_rpn_loc: 0.06054    time: 0.0788  last_time: 0.0775  data_time: 0.0026  last_data_time: 0.0024   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:57 d2.utils.events]:  eta: 0:05:21  iter: 1939  total_loss: 0.3938  loss_cls: 0.05429  loss_box_reg: 0.00372  loss_rpn_cls: 0.2501  loss_rpn_loc: 0.08162    time: 0.0788  last_time: 0.0839  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:46:59 d2.utils.events]:  eta: 0:05:20  iter: 1959  total_loss: 0.3769  loss_cls: 0.06241  loss_box_reg: 0.005872  loss_rpn_cls: 0.2223  loss_rpn_loc: 0.06547    time: 0.0788  last_time: 0.0753  data_time: 0.0025  last_data_time: 0.0023   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:47:00 d2.utils.events]:  eta: 0:05:19  iter: 1979  total_loss: 0.3459  loss_cls: 0.06218  loss_box_reg: 0.00736  loss_rpn_cls: 0.2136  loss_rpn_loc: 0.04544    time: 0.0788  last_time: 0.0815  data_time: 0.0026  last_data_time: 0.0028   lr: 2.5e-05  max_mem: 2107M\n",
      "WARNING [03/22 13:47:02 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/22 13:47:02 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/22 13:47:02 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[03/22 13:47:02 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "[03/22 13:47:02 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/22 13:47:02 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "[03/22 13:47:02 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n",
      "WARNING [03/22 13:47:02 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[03/22 13:47:02 d2.evaluation.evaluator]: Start inference on 1801 batches\n",
      "[03/22 13:47:03 d2.evaluation.evaluator]: Inference done 11/1801. Dataloading: 0.0007 s/iter. Inference: 0.0257 s/iter. Eval: 0.0001 s/iter. Total: 0.0265 s/iter. ETA=0:00:47\n",
      "[03/22 13:47:08 d2.evaluation.evaluator]: Inference done 199/1801. Dataloading: 0.0008 s/iter. Inference: 0.0257 s/iter. Eval: 0.0001 s/iter. Total: 0.0266 s/iter. ETA=0:00:42\n",
      "[03/22 13:47:13 d2.evaluation.evaluator]: Inference done 388/1801. Dataloading: 0.0008 s/iter. Inference: 0.0256 s/iter. Eval: 0.0001 s/iter. Total: 0.0266 s/iter. ETA=0:00:37\n",
      "[03/22 13:47:18 d2.evaluation.evaluator]: Inference done 577/1801. Dataloading: 0.0008 s/iter. Inference: 0.0256 s/iter. Eval: 0.0001 s/iter. Total: 0.0265 s/iter. ETA=0:00:32\n",
      "[03/22 13:47:23 d2.evaluation.evaluator]: Inference done 770/1801. Dataloading: 0.0008 s/iter. Inference: 0.0255 s/iter. Eval: 0.0001 s/iter. Total: 0.0264 s/iter. ETA=0:00:27\n",
      "[03/22 13:47:28 d2.evaluation.evaluator]: Inference done 962/1801. Dataloading: 0.0008 s/iter. Inference: 0.0254 s/iter. Eval: 0.0001 s/iter. Total: 0.0264 s/iter. ETA=0:00:22\n",
      "[03/22 13:47:33 d2.evaluation.evaluator]: Inference done 1155/1801. Dataloading: 0.0008 s/iter. Inference: 0.0254 s/iter. Eval: 0.0001 s/iter. Total: 0.0263 s/iter. ETA=0:00:16\n",
      "[03/22 13:47:38 d2.evaluation.evaluator]: Inference done 1349/1801. Dataloading: 0.0008 s/iter. Inference: 0.0253 s/iter. Eval: 0.0001 s/iter. Total: 0.0262 s/iter. ETA=0:00:11\n",
      "[03/22 13:47:43 d2.evaluation.evaluator]: Inference done 1544/1801. Dataloading: 0.0008 s/iter. Inference: 0.0253 s/iter. Eval: 0.0001 s/iter. Total: 0.0262 s/iter. ETA=0:00:06\n",
      "[03/22 13:47:48 d2.evaluation.evaluator]: Inference done 1738/1801. Dataloading: 0.0008 s/iter. Inference: 0.0252 s/iter. Eval: 0.0001 s/iter. Total: 0.0261 s/iter. ETA=0:00:01\n",
      "[03/22 13:47:49 d2.evaluation.evaluator]: Total inference time: 0:00:47.015888 (0.026178 s / iter per device, on 1 devices)\n",
      "[03/22 13:47:49 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:45 (0.025235 s / iter per device, on 1 devices)\n",
      "[03/22 13:47:49 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[03/22 13:47:49 d2.evaluation.coco_evaluation]: Saving results to /workspace/output/output_res030_bs2_03.22.13.44/inference/coco_instances_results.json\n",
      "[03/22 13:47:49 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "[03/22 13:47:51 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.001 | 0.005  | 0.000  | 0.002 | 0.000 | 0.000 |\n",
      "[03/22 13:47:51 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
      "| category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|\n",
      "| DT         | 0.003 | TT         | 0.000 |\n",
      "[03/22 13:47:51 d2.engine.defaults]: Evaluation results for tower_val_03012 in csv format:\n",
      "[03/22 13:47:51 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[03/22 13:47:51 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[03/22 13:47:51 d2.evaluation.testing]: copypaste: 0.0013,0.0052,0.0001,0.0017,0.0002,0.0000\n",
      "[03/22 13:48:52 d2.utils.events]:  eta: 0:05:17  iter: 1999  total_loss: 0.3093  loss_cls: 0.05433  loss_box_reg: 0.006907  loss_rpn_cls: 0.2005  loss_rpn_loc: 0.04083  validation_loss: 0.4095    time: 0.0789  last_time: 0.0792  data_time: 0.0026  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:48:54 d2.utils.events]:  eta: 0:05:15  iter: 2019  total_loss: 0.3467  loss_cls: 0.0522  loss_box_reg: 0.01578  loss_rpn_cls: 0.2131  loss_rpn_loc: 0.07922  validation_loss: 0.4095    time: 0.0789  last_time: 0.0779  data_time: 0.0025  last_data_time: 0.0023   lr: 2.5e-05  max_mem: 2107M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:48:55 d2.utils.events]:  eta: 0:05:14  iter: 2039  total_loss: 0.4385  loss_cls: 0.07235  loss_box_reg: 0.005026  loss_rpn_cls: 0.271  loss_rpn_loc: 0.08071  validation_loss: 0.4095    time: 0.0789  last_time: 0.0759  data_time: 0.0028  last_data_time: 0.0032   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:48:57 d2.utils.events]:  eta: 0:05:12  iter: 2059  total_loss: 0.4299  loss_cls: 0.06859  loss_box_reg: 0.01838  loss_rpn_cls: 0.2468  loss_rpn_loc: 0.06506  validation_loss: 0.4095    time: 0.0789  last_time: 0.0815  data_time: 0.0028  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:48:59 d2.utils.events]:  eta: 0:05:11  iter: 2079  total_loss: 0.4265  loss_cls: 0.07134  loss_box_reg: 0.0173  loss_rpn_cls: 0.2545  loss_rpn_loc: 0.06315  validation_loss: 0.4095    time: 0.0789  last_time: 0.0800  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:00 d2.utils.events]:  eta: 0:05:09  iter: 2099  total_loss: 0.4624  loss_cls: 0.06937  loss_box_reg: 0.03289  loss_rpn_cls: 0.2285  loss_rpn_loc: 0.05984  validation_loss: 0.4095    time: 0.0789  last_time: 0.0800  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:02 d2.utils.events]:  eta: 0:05:08  iter: 2119  total_loss: 0.4556  loss_cls: 0.0823  loss_box_reg: 0.02408  loss_rpn_cls: 0.2485  loss_rpn_loc: 0.07793  validation_loss: 0.4095    time: 0.0789  last_time: 0.0739  data_time: 0.0030  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:03 d2.utils.events]:  eta: 0:05:06  iter: 2139  total_loss: 0.3285  loss_cls: 0.06201  loss_box_reg: 0.01657  loss_rpn_cls: 0.1865  loss_rpn_loc: 0.04624  validation_loss: 0.4095    time: 0.0789  last_time: 0.0732  data_time: 0.0027  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:05 d2.utils.events]:  eta: 0:05:05  iter: 2159  total_loss: 0.471  loss_cls: 0.07147  loss_box_reg: 0.02161  loss_rpn_cls: 0.2543  loss_rpn_loc: 0.101  validation_loss: 0.4095    time: 0.0789  last_time: 0.0809  data_time: 0.0027  last_data_time: 0.0024   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:07 d2.utils.events]:  eta: 0:05:03  iter: 2179  total_loss: 0.453  loss_cls: 0.09078  loss_box_reg: 0.0247  loss_rpn_cls: 0.2577  loss_rpn_loc: 0.06721  validation_loss: 0.4095    time: 0.0789  last_time: 0.0735  data_time: 0.0028  last_data_time: 0.0029   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:08 d2.utils.events]:  eta: 0:05:01  iter: 2199  total_loss: 0.3842  loss_cls: 0.07076  loss_box_reg: 0.02112  loss_rpn_cls: 0.2192  loss_rpn_loc: 0.05189  validation_loss: 0.4095    time: 0.0789  last_time: 0.0811  data_time: 0.0024  last_data_time: 0.0021   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:10 d2.utils.events]:  eta: 0:05:00  iter: 2219  total_loss: 0.4747  loss_cls: 0.07598  loss_box_reg: 0.009538  loss_rpn_cls: 0.2629  loss_rpn_loc: 0.1021  validation_loss: 0.4095    time: 0.0789  last_time: 0.0805  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:11 d2.utils.events]:  eta: 0:04:58  iter: 2239  total_loss: 0.3666  loss_cls: 0.05708  loss_box_reg: 0.01166  loss_rpn_cls: 0.2183  loss_rpn_loc: 0.04396  validation_loss: 0.4095    time: 0.0789  last_time: 0.0755  data_time: 0.0026  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:13 d2.utils.events]:  eta: 0:04:56  iter: 2259  total_loss: 0.3892  loss_cls: 0.05077  loss_box_reg: 0.009973  loss_rpn_cls: 0.2232  loss_rpn_loc: 0.05783  validation_loss: 0.4095    time: 0.0789  last_time: 0.0788  data_time: 0.0026  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:15 d2.utils.events]:  eta: 0:04:55  iter: 2279  total_loss: 0.3365  loss_cls: 0.06398  loss_box_reg: 0.01572  loss_rpn_cls: 0.1987  loss_rpn_loc: 0.03781  validation_loss: 0.4095    time: 0.0789  last_time: 0.0814  data_time: 0.0029  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:16 d2.utils.events]:  eta: 0:04:53  iter: 2299  total_loss: 0.424  loss_cls: 0.0589  loss_box_reg: 0.01599  loss_rpn_cls: 0.2309  loss_rpn_loc: 0.07651  validation_loss: 0.4095    time: 0.0789  last_time: 0.0760  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:18 d2.utils.events]:  eta: 0:04:52  iter: 2319  total_loss: 0.483  loss_cls: 0.09421  loss_box_reg: 0.02891  loss_rpn_cls: 0.2331  loss_rpn_loc: 0.06656  validation_loss: 0.4095    time: 0.0789  last_time: 0.0800  data_time: 0.0028  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:19 d2.utils.events]:  eta: 0:04:50  iter: 2339  total_loss: 0.3929  loss_cls: 0.08701  loss_box_reg: 0.02507  loss_rpn_cls: 0.2098  loss_rpn_loc: 0.0479  validation_loss: 0.4095    time: 0.0789  last_time: 0.0827  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:21 d2.utils.events]:  eta: 0:04:48  iter: 2359  total_loss: 0.4284  loss_cls: 0.1003  loss_box_reg: 0.05803  loss_rpn_cls: 0.2082  loss_rpn_loc: 0.04908  validation_loss: 0.4095    time: 0.0789  last_time: 0.0742  data_time: 0.0028  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:23 d2.utils.events]:  eta: 0:04:46  iter: 2379  total_loss: 0.4311  loss_cls: 0.08234  loss_box_reg: 0.03687  loss_rpn_cls: 0.2366  loss_rpn_loc: 0.06133  validation_loss: 0.4095    time: 0.0789  last_time: 0.0768  data_time: 0.0027  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:24 d2.utils.events]:  eta: 0:04:45  iter: 2399  total_loss: 0.415  loss_cls: 0.08603  loss_box_reg: 0.04306  loss_rpn_cls: 0.2265  loss_rpn_loc: 0.07015  validation_loss: 0.4095    time: 0.0789  last_time: 0.0780  data_time: 0.0028  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:26 d2.utils.events]:  eta: 0:04:43  iter: 2419  total_loss: 0.4577  loss_cls: 0.07855  loss_box_reg: 0.02746  loss_rpn_cls: 0.2404  loss_rpn_loc: 0.0714  validation_loss: 0.4095    time: 0.0789  last_time: 0.0808  data_time: 0.0026  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:27 d2.utils.events]:  eta: 0:04:41  iter: 2439  total_loss: 0.4784  loss_cls: 0.07624  loss_box_reg: 0.03253  loss_rpn_cls: 0.2548  loss_rpn_loc: 0.09406  validation_loss: 0.4095    time: 0.0789  last_time: 0.0791  data_time: 0.0026  last_data_time: 0.0027   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:29 d2.utils.events]:  eta: 0:04:40  iter: 2459  total_loss: 0.4517  loss_cls: 0.09865  loss_box_reg: 0.04219  loss_rpn_cls: 0.2414  loss_rpn_loc: 0.04845  validation_loss: 0.4095    time: 0.0789  last_time: 0.0766  data_time: 0.0026  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:30 d2.utils.events]:  eta: 0:04:39  iter: 2479  total_loss: 0.4425  loss_cls: 0.07037  loss_box_reg: 0.03232  loss_rpn_cls: 0.2172  loss_rpn_loc: 0.06297  validation_loss: 0.4095    time: 0.0789  last_time: 0.0871  data_time: 0.0024  last_data_time: 0.0022   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:32 d2.utils.events]:  eta: 0:04:37  iter: 2499  total_loss: 0.3912  loss_cls: 0.07071  loss_box_reg: 0.02479  loss_rpn_cls: 0.2009  loss_rpn_loc: 0.04225  validation_loss: 0.4095    time: 0.0789  last_time: 0.0775  data_time: 0.0025  last_data_time: 0.0024   lr: 2.5e-05  max_mem: 2107M\n",
      "[03/22 13:49:34 d2.utils.events]:  eta: 0:04:36  iter: 2519  total_loss: 0.5102  loss_cls: 0.1158  loss_box_reg: 0.06422  loss_rpn_cls: 0.253  loss_rpn_loc: 0.06  validation_loss: 0.4095    time: 0.0789  last_time: 0.0739  data_time: 0.0028  last_data_time: 0.0023   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:35 d2.utils.events]:  eta: 0:04:34  iter: 2539  total_loss: 0.4435  loss_cls: 0.096  loss_box_reg: 0.04572  loss_rpn_cls: 0.2228  loss_rpn_loc: 0.04919  validation_loss: 0.4095    time: 0.0789  last_time: 0.0798  data_time: 0.0025  last_data_time: 0.0023   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:37 d2.utils.events]:  eta: 0:04:32  iter: 2559  total_loss: 0.4803  loss_cls: 0.1067  loss_box_reg: 0.06358  loss_rpn_cls: 0.2127  loss_rpn_loc: 0.05219  validation_loss: 0.4095    time: 0.0789  last_time: 0.0788  data_time: 0.0026  last_data_time: 0.0028   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:38 d2.utils.events]:  eta: 0:04:31  iter: 2579  total_loss: 0.3652  loss_cls: 0.07759  loss_box_reg: 0.04553  loss_rpn_cls: 0.2026  loss_rpn_loc: 0.04809  validation_loss: 0.4095    time: 0.0789  last_time: 0.0775  data_time: 0.0025  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2107M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:49:40 d2.utils.events]:  eta: 0:04:29  iter: 2599  total_loss: 0.4157  loss_cls: 0.0844  loss_box_reg: 0.03368  loss_rpn_cls: 0.2188  loss_rpn_loc: 0.062  validation_loss: 0.4095    time: 0.0789  last_time: 0.0757  data_time: 0.0026  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:41 d2.utils.events]:  eta: 0:04:27  iter: 2619  total_loss: 0.3989  loss_cls: 0.08134  loss_box_reg: 0.02861  loss_rpn_cls: 0.2367  loss_rpn_loc: 0.04826  validation_loss: 0.4095    time: 0.0789  last_time: 0.0773  data_time: 0.0025  last_data_time: 0.0022   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:43 d2.utils.events]:  eta: 0:04:26  iter: 2639  total_loss: 0.5842  loss_cls: 0.0855  loss_box_reg: 0.03934  loss_rpn_cls: 0.2702  loss_rpn_loc: 0.07165  validation_loss: 0.4095    time: 0.0789  last_time: 0.0760  data_time: 0.0024  last_data_time: 0.0022   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:45 d2.utils.events]:  eta: 0:04:24  iter: 2659  total_loss: 0.426  loss_cls: 0.08421  loss_box_reg: 0.03706  loss_rpn_cls: 0.2267  loss_rpn_loc: 0.06038  validation_loss: 0.4095    time: 0.0789  last_time: 0.0773  data_time: 0.0024  last_data_time: 0.0023   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:46 d2.utils.events]:  eta: 0:04:23  iter: 2679  total_loss: 0.3366  loss_cls: 0.07827  loss_box_reg: 0.041  loss_rpn_cls: 0.1876  loss_rpn_loc: 0.04018  validation_loss: 0.4095    time: 0.0789  last_time: 0.0806  data_time: 0.0026  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:48 d2.utils.events]:  eta: 0:04:21  iter: 2699  total_loss: 0.4528  loss_cls: 0.0823  loss_box_reg: 0.03107  loss_rpn_cls: 0.2165  loss_rpn_loc: 0.05602  validation_loss: 0.4095    time: 0.0789  last_time: 0.0771  data_time: 0.0026  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:49 d2.utils.events]:  eta: 0:04:19  iter: 2719  total_loss: 0.4271  loss_cls: 0.09698  loss_box_reg: 0.03502  loss_rpn_cls: 0.2192  loss_rpn_loc: 0.05816  validation_loss: 0.4095    time: 0.0789  last_time: 0.0774  data_time: 0.0026  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:51 d2.utils.events]:  eta: 0:04:18  iter: 2739  total_loss: 0.3817  loss_cls: 0.08583  loss_box_reg: 0.04578  loss_rpn_cls: 0.2018  loss_rpn_loc: 0.0428  validation_loss: 0.4095    time: 0.0788  last_time: 0.0759  data_time: 0.0024  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:52 d2.utils.events]:  eta: 0:04:16  iter: 2759  total_loss: 0.4564  loss_cls: 0.09847  loss_box_reg: 0.05203  loss_rpn_cls: 0.2127  loss_rpn_loc: 0.04806  validation_loss: 0.4095    time: 0.0788  last_time: 0.0810  data_time: 0.0026  last_data_time: 0.0029   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:54 d2.utils.events]:  eta: 0:04:15  iter: 2779  total_loss: 0.5381  loss_cls: 0.0815  loss_box_reg: 0.04427  loss_rpn_cls: 0.2641  loss_rpn_loc: 0.07495  validation_loss: 0.4095    time: 0.0788  last_time: 0.0792  data_time: 0.0028  last_data_time: 0.0028   lr: 2.5e-06  max_mem: 2107M\n",
      "[03/22 13:49:56 d2.utils.events]:  eta: 0:04:13  iter: 2799  total_loss: 0.5581  loss_cls: 0.1052  loss_box_reg: 0.05558  loss_rpn_cls: 0.2272  loss_rpn_loc: 0.05552  validation_loss: 0.4095    time: 0.0789  last_time: 0.0767  data_time: 0.0025  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:49:57 d2.utils.events]:  eta: 0:04:11  iter: 2819  total_loss: 0.385  loss_cls: 0.07552  loss_box_reg: 0.03791  loss_rpn_cls: 0.205  loss_rpn_loc: 0.06863  validation_loss: 0.4095    time: 0.0789  last_time: 0.0757  data_time: 0.0026  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:49:59 d2.utils.events]:  eta: 0:04:10  iter: 2839  total_loss: 0.3981  loss_cls: 0.08864  loss_box_reg: 0.03636  loss_rpn_cls: 0.1931  loss_rpn_loc: 0.03452  validation_loss: 0.4095    time: 0.0789  last_time: 0.0788  data_time: 0.0025  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:00 d2.utils.events]:  eta: 0:04:08  iter: 2859  total_loss: 0.5744  loss_cls: 0.1161  loss_box_reg: 0.05787  loss_rpn_cls: 0.262  loss_rpn_loc: 0.08506  validation_loss: 0.4095    time: 0.0789  last_time: 0.0755  data_time: 0.0026  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:02 d2.utils.events]:  eta: 0:04:07  iter: 2879  total_loss: 0.4385  loss_cls: 0.06756  loss_box_reg: 0.02973  loss_rpn_cls: 0.2389  loss_rpn_loc: 0.0773  validation_loss: 0.4095    time: 0.0789  last_time: 0.0760  data_time: 0.0026  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:04 d2.utils.events]:  eta: 0:04:05  iter: 2899  total_loss: 0.3777  loss_cls: 0.07664  loss_box_reg: 0.03518  loss_rpn_cls: 0.187  loss_rpn_loc: 0.05274  validation_loss: 0.4095    time: 0.0789  last_time: 0.0841  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:05 d2.utils.events]:  eta: 0:04:03  iter: 2919  total_loss: 0.4263  loss_cls: 0.09708  loss_box_reg: 0.0416  loss_rpn_cls: 0.2185  loss_rpn_loc: 0.06096  validation_loss: 0.4095    time: 0.0789  last_time: 0.0819  data_time: 0.0027  last_data_time: 0.0027   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:07 d2.utils.events]:  eta: 0:04:01  iter: 2939  total_loss: 0.4322  loss_cls: 0.1022  loss_box_reg: 0.04235  loss_rpn_cls: 0.2018  loss_rpn_loc: 0.05568  validation_loss: 0.4095    time: 0.0789  last_time: 0.0819  data_time: 0.0028  last_data_time: 0.0040   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:08 d2.utils.events]:  eta: 0:04:00  iter: 2959  total_loss: 0.3871  loss_cls: 0.08253  loss_box_reg: 0.03327  loss_rpn_cls: 0.2122  loss_rpn_loc: 0.04407  validation_loss: 0.4095    time: 0.0789  last_time: 0.0687  data_time: 0.0027  last_data_time: 0.0021   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:10 d2.utils.events]:  eta: 0:03:58  iter: 2979  total_loss: 0.3466  loss_cls: 0.06844  loss_box_reg: 0.027  loss_rpn_cls: 0.195  loss_rpn_loc: 0.05495  validation_loss: 0.4095    time: 0.0789  last_time: 0.0797  data_time: 0.0024  last_data_time: 0.0023   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:11 d2.utils.events]:  eta: 0:03:56  iter: 2999  total_loss: 0.3967  loss_cls: 0.07719  loss_box_reg: 0.02437  loss_rpn_cls: 0.2097  loss_rpn_loc: 0.05581  validation_loss: 0.4095    time: 0.0789  last_time: 0.0763  data_time: 0.0023  last_data_time: 0.0022   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:13 d2.utils.events]:  eta: 0:03:55  iter: 3019  total_loss: 0.4525  loss_cls: 0.07586  loss_box_reg: 0.02828  loss_rpn_cls: 0.2277  loss_rpn_loc: 0.0698  validation_loss: 0.4095    time: 0.0789  last_time: 0.0765  data_time: 0.0025  last_data_time: 0.0022   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:15 d2.utils.events]:  eta: 0:03:53  iter: 3039  total_loss: 0.4064  loss_cls: 0.0911  loss_box_reg: 0.05318  loss_rpn_cls: 0.2183  loss_rpn_loc: 0.05727  validation_loss: 0.4095    time: 0.0788  last_time: 0.0818  data_time: 0.0025  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:16 d2.utils.events]:  eta: 0:03:51  iter: 3059  total_loss: 0.5211  loss_cls: 0.08736  loss_box_reg: 0.02816  loss_rpn_cls: 0.2705  loss_rpn_loc: 0.06614  validation_loss: 0.4095    time: 0.0788  last_time: 0.0826  data_time: 0.0025  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2125M\n",
      "[03/22 13:50:18 d2.utils.events]:  eta: 0:03:50  iter: 3079  total_loss: 0.3906  loss_cls: 0.1041  loss_box_reg: 0.0502  loss_rpn_cls: 0.2049  loss_rpn_loc: 0.04962  validation_loss: 0.4095    time: 0.0788  last_time: 0.0814  data_time: 0.0027  last_data_time: 0.0034   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:19 d2.utils.events]:  eta: 0:03:48  iter: 3099  total_loss: 0.4565  loss_cls: 0.08751  loss_box_reg: 0.0268  loss_rpn_cls: 0.2405  loss_rpn_loc: 0.08649  validation_loss: 0.4095    time: 0.0789  last_time: 0.0805  data_time: 0.0027  last_data_time: 0.0027   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:21 d2.utils.events]:  eta: 0:03:47  iter: 3119  total_loss: 0.4721  loss_cls: 0.08981  loss_box_reg: 0.04498  loss_rpn_cls: 0.2107  loss_rpn_loc: 0.05564  validation_loss: 0.4095    time: 0.0789  last_time: 0.0746  data_time: 0.0026  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:23 d2.utils.events]:  eta: 0:03:45  iter: 3139  total_loss: 0.3449  loss_cls: 0.06521  loss_box_reg: 0.02949  loss_rpn_cls: 0.2021  loss_rpn_loc: 0.04939  validation_loss: 0.4095    time: 0.0789  last_time: 0.0768  data_time: 0.0026  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2126M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:50:24 d2.utils.events]:  eta: 0:03:44  iter: 3159  total_loss: 0.4684  loss_cls: 0.07761  loss_box_reg: 0.03055  loss_rpn_cls: 0.2424  loss_rpn_loc: 0.0653  validation_loss: 0.4095    time: 0.0789  last_time: 0.0793  data_time: 0.0026  last_data_time: 0.0028   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:26 d2.utils.events]:  eta: 0:03:42  iter: 3179  total_loss: 0.5305  loss_cls: 0.07074  loss_box_reg: 0.01813  loss_rpn_cls: 0.2769  loss_rpn_loc: 0.08202  validation_loss: 0.4095    time: 0.0789  last_time: 0.0795  data_time: 0.0026  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:27 d2.utils.events]:  eta: 0:03:41  iter: 3199  total_loss: 0.4681  loss_cls: 0.08813  loss_box_reg: 0.04047  loss_rpn_cls: 0.2442  loss_rpn_loc: 0.06993  validation_loss: 0.4095    time: 0.0789  last_time: 0.0847  data_time: 0.0029  last_data_time: 0.0030   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:29 d2.utils.events]:  eta: 0:03:39  iter: 3219  total_loss: 0.446  loss_cls: 0.08853  loss_box_reg: 0.03828  loss_rpn_cls: 0.2231  loss_rpn_loc: 0.05609  validation_loss: 0.4095    time: 0.0789  last_time: 0.0844  data_time: 0.0031  last_data_time: 0.0038   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:31 d2.utils.events]:  eta: 0:03:38  iter: 3239  total_loss: 0.4079  loss_cls: 0.08508  loss_box_reg: 0.03133  loss_rpn_cls: 0.2027  loss_rpn_loc: 0.04528  validation_loss: 0.4095    time: 0.0789  last_time: 0.0767  data_time: 0.0026  last_data_time: 0.0031   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:32 d2.utils.events]:  eta: 0:03:37  iter: 3259  total_loss: 0.3956  loss_cls: 0.06853  loss_box_reg: 0.006529  loss_rpn_cls: 0.2014  loss_rpn_loc: 0.05193  validation_loss: 0.4095    time: 0.0789  last_time: 0.0773  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:34 d2.utils.events]:  eta: 0:03:35  iter: 3279  total_loss: 0.4819  loss_cls: 0.1037  loss_box_reg: 0.05832  loss_rpn_cls: 0.2213  loss_rpn_loc: 0.06749  validation_loss: 0.4095    time: 0.0789  last_time: 0.0779  data_time: 0.0025  last_data_time: 0.0022   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:36 d2.utils.events]:  eta: 0:03:33  iter: 3299  total_loss: 0.3173  loss_cls: 0.07277  loss_box_reg: 0.01658  loss_rpn_cls: 0.1833  loss_rpn_loc: 0.04107  validation_loss: 0.4095    time: 0.0790  last_time: 0.0837  data_time: 0.0025  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:37 d2.utils.events]:  eta: 0:03:32  iter: 3319  total_loss: 0.3394  loss_cls: 0.07502  loss_box_reg: 0.01694  loss_rpn_cls: 0.1978  loss_rpn_loc: 0.03944  validation_loss: 0.4095    time: 0.0790  last_time: 0.0764  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:39 d2.utils.events]:  eta: 0:03:30  iter: 3339  total_loss: 0.3605  loss_cls: 0.06861  loss_box_reg: 0.02637  loss_rpn_cls: 0.2142  loss_rpn_loc: 0.05634  validation_loss: 0.4095    time: 0.0790  last_time: 0.0824  data_time: 0.0025  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:40 d2.utils.events]:  eta: 0:03:29  iter: 3359  total_loss: 0.4374  loss_cls: 0.09462  loss_box_reg: 0.05105  loss_rpn_cls: 0.2339  loss_rpn_loc: 0.06044  validation_loss: 0.4095    time: 0.0790  last_time: 0.0840  data_time: 0.0024  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:42 d2.utils.events]:  eta: 0:03:27  iter: 3379  total_loss: 0.3748  loss_cls: 0.08897  loss_box_reg: 0.05346  loss_rpn_cls: 0.2022  loss_rpn_loc: 0.05189  validation_loss: 0.4095    time: 0.0790  last_time: 0.0820  data_time: 0.0027  last_data_time: 0.0047   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:44 d2.utils.events]:  eta: 0:03:26  iter: 3399  total_loss: 0.444  loss_cls: 0.08236  loss_box_reg: 0.04301  loss_rpn_cls: 0.2373  loss_rpn_loc: 0.06229  validation_loss: 0.4095    time: 0.0790  last_time: 0.0760  data_time: 0.0026  last_data_time: 0.0030   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:45 d2.utils.events]:  eta: 0:03:24  iter: 3419  total_loss: 0.4898  loss_cls: 0.1283  loss_box_reg: 0.05218  loss_rpn_cls: 0.241  loss_rpn_loc: 0.05269  validation_loss: 0.4095    time: 0.0790  last_time: 0.0818  data_time: 0.0026  last_data_time: 0.0023   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:47 d2.utils.events]:  eta: 0:03:22  iter: 3439  total_loss: 0.4117  loss_cls: 0.09249  loss_box_reg: 0.05491  loss_rpn_cls: 0.2231  loss_rpn_loc: 0.05525  validation_loss: 0.4095    time: 0.0790  last_time: 0.0833  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:48 d2.utils.events]:  eta: 0:03:21  iter: 3459  total_loss: 0.4026  loss_cls: 0.09126  loss_box_reg: 0.03734  loss_rpn_cls: 0.2143  loss_rpn_loc: 0.04731  validation_loss: 0.4095    time: 0.0790  last_time: 0.0799  data_time: 0.0028  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:50 d2.utils.events]:  eta: 0:03:19  iter: 3479  total_loss: 0.3924  loss_cls: 0.09314  loss_box_reg: 0.03704  loss_rpn_cls: 0.229  loss_rpn_loc: 0.05047  validation_loss: 0.4095    time: 0.0790  last_time: 0.0765  data_time: 0.0026  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:52 d2.utils.events]:  eta: 0:03:18  iter: 3499  total_loss: 0.4689  loss_cls: 0.1023  loss_box_reg: 0.05845  loss_rpn_cls: 0.2324  loss_rpn_loc: 0.04554  validation_loss: 0.4095    time: 0.0790  last_time: 0.0830  data_time: 0.0028  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:53 d2.utils.events]:  eta: 0:03:16  iter: 3519  total_loss: 0.4576  loss_cls: 0.1147  loss_box_reg: 0.06014  loss_rpn_cls: 0.2248  loss_rpn_loc: 0.05689  validation_loss: 0.4095    time: 0.0790  last_time: 0.0775  data_time: 0.0025  last_data_time: 0.0022   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:55 d2.utils.events]:  eta: 0:03:15  iter: 3539  total_loss: 0.4133  loss_cls: 0.09511  loss_box_reg: 0.05311  loss_rpn_cls: 0.2071  loss_rpn_loc: 0.05473  validation_loss: 0.4095    time: 0.0790  last_time: 0.0780  data_time: 0.0025  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:56 d2.utils.events]:  eta: 0:03:13  iter: 3559  total_loss: 0.4499  loss_cls: 0.08337  loss_box_reg: 0.04  loss_rpn_cls: 0.2236  loss_rpn_loc: 0.06631  validation_loss: 0.4095    time: 0.0790  last_time: 0.0844  data_time: 0.0026  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:58 d2.utils.events]:  eta: 0:03:11  iter: 3579  total_loss: 0.4637  loss_cls: 0.0782  loss_box_reg: 0.03977  loss_rpn_cls: 0.2233  loss_rpn_loc: 0.0688  validation_loss: 0.4095    time: 0.0790  last_time: 0.0757  data_time: 0.0028  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:50:59 d2.utils.events]:  eta: 0:03:10  iter: 3599  total_loss: 0.4406  loss_cls: 0.08977  loss_box_reg: 0.05731  loss_rpn_cls: 0.2259  loss_rpn_loc: 0.06155  validation_loss: 0.4095    time: 0.0790  last_time: 0.0784  data_time: 0.0027  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:01 d2.utils.events]:  eta: 0:03:08  iter: 3619  total_loss: 0.3375  loss_cls: 0.08624  loss_box_reg: 0.03271  loss_rpn_cls: 0.1928  loss_rpn_loc: 0.04324  validation_loss: 0.4095    time: 0.0790  last_time: 0.0821  data_time: 0.0028  last_data_time: 0.0023   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:03 d2.utils.events]:  eta: 0:03:07  iter: 3639  total_loss: 0.4923  loss_cls: 0.09391  loss_box_reg: 0.04603  loss_rpn_cls: 0.2258  loss_rpn_loc: 0.05394  validation_loss: 0.4095    time: 0.0790  last_time: 0.0814  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:04 d2.utils.events]:  eta: 0:03:05  iter: 3659  total_loss: 0.4802  loss_cls: 0.1002  loss_box_reg: 0.05582  loss_rpn_cls: 0.2177  loss_rpn_loc: 0.05392  validation_loss: 0.4095    time: 0.0790  last_time: 0.0831  data_time: 0.0025  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:06 d2.utils.events]:  eta: 0:03:04  iter: 3679  total_loss: 0.4295  loss_cls: 0.09637  loss_box_reg: 0.03152  loss_rpn_cls: 0.233  loss_rpn_loc: 0.04647  validation_loss: 0.4095    time: 0.0790  last_time: 0.0808  data_time: 0.0028  last_data_time: 0.0030   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:07 d2.utils.events]:  eta: 0:03:02  iter: 3699  total_loss: 0.3957  loss_cls: 0.08343  loss_box_reg: 0.03415  loss_rpn_cls: 0.2334  loss_rpn_loc: 0.04773  validation_loss: 0.4095    time: 0.0790  last_time: 0.0799  data_time: 0.0026  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:51:09 d2.utils.events]:  eta: 0:03:01  iter: 3719  total_loss: 0.3982  loss_cls: 0.1009  loss_box_reg: 0.05939  loss_rpn_cls: 0.1859  loss_rpn_loc: 0.0407  validation_loss: 0.4095    time: 0.0790  last_time: 0.0816  data_time: 0.0027  last_data_time: 0.0027   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:11 d2.utils.events]:  eta: 0:02:59  iter: 3739  total_loss: 0.4238  loss_cls: 0.09885  loss_box_reg: 0.03662  loss_rpn_cls: 0.2203  loss_rpn_loc: 0.0612  validation_loss: 0.4095    time: 0.0790  last_time: 0.0778  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:12 d2.utils.events]:  eta: 0:02:58  iter: 3759  total_loss: 0.3825  loss_cls: 0.08166  loss_box_reg: 0.04299  loss_rpn_cls: 0.2076  loss_rpn_loc: 0.0506  validation_loss: 0.4095    time: 0.0790  last_time: 0.0776  data_time: 0.0025  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:14 d2.utils.events]:  eta: 0:02:56  iter: 3779  total_loss: 0.4032  loss_cls: 0.07171  loss_box_reg: 0.02868  loss_rpn_cls: 0.2197  loss_rpn_loc: 0.04805  validation_loss: 0.4095    time: 0.0790  last_time: 0.0769  data_time: 0.0027  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:15 d2.utils.events]:  eta: 0:02:54  iter: 3799  total_loss: 0.5028  loss_cls: 0.08969  loss_box_reg: 0.04482  loss_rpn_cls: 0.2145  loss_rpn_loc: 0.06872  validation_loss: 0.4095    time: 0.0790  last_time: 0.0812  data_time: 0.0026  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:17 d2.utils.events]:  eta: 0:02:53  iter: 3819  total_loss: 0.3507  loss_cls: 0.08094  loss_box_reg: 0.04618  loss_rpn_cls: 0.2007  loss_rpn_loc: 0.04871  validation_loss: 0.4095    time: 0.0790  last_time: 0.0819  data_time: 0.0025  last_data_time: 0.0027   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:18 d2.utils.events]:  eta: 0:02:51  iter: 3839  total_loss: 0.5231  loss_cls: 0.0991  loss_box_reg: 0.06512  loss_rpn_cls: 0.2689  loss_rpn_loc: 0.06256  validation_loss: 0.4095    time: 0.0790  last_time: 0.0798  data_time: 0.0026  last_data_time: 0.0025   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:20 d2.utils.events]:  eta: 0:02:50  iter: 3859  total_loss: 0.4187  loss_cls: 0.08875  loss_box_reg: 0.03062  loss_rpn_cls: 0.2249  loss_rpn_loc: 0.04756  validation_loss: 0.4095    time: 0.0790  last_time: 0.0838  data_time: 0.0026  last_data_time: 0.0023   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:22 d2.utils.events]:  eta: 0:02:48  iter: 3879  total_loss: 0.3716  loss_cls: 0.0839  loss_box_reg: 0.04469  loss_rpn_cls: 0.1932  loss_rpn_loc: 0.03911  validation_loss: 0.4095    time: 0.0790  last_time: 0.0771  data_time: 0.0028  last_data_time: 0.0023   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:23 d2.utils.events]:  eta: 0:02:46  iter: 3899  total_loss: 0.4109  loss_cls: 0.08275  loss_box_reg: 0.03478  loss_rpn_cls: 0.2256  loss_rpn_loc: 0.04399  validation_loss: 0.4095    time: 0.0790  last_time: 0.0850  data_time: 0.0026  last_data_time: 0.0045   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:25 d2.utils.events]:  eta: 0:02:45  iter: 3919  total_loss: 0.4252  loss_cls: 0.08427  loss_box_reg: 0.03947  loss_rpn_cls: 0.2359  loss_rpn_loc: 0.0614  validation_loss: 0.4095    time: 0.0790  last_time: 0.0767  data_time: 0.0028  last_data_time: 0.0024   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:26 d2.utils.events]:  eta: 0:02:43  iter: 3939  total_loss: 0.4583  loss_cls: 0.1074  loss_box_reg: 0.03533  loss_rpn_cls: 0.2188  loss_rpn_loc: 0.06162  validation_loss: 0.4095    time: 0.0790  last_time: 0.0784  data_time: 0.0027  last_data_time: 0.0022   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:28 d2.utils.events]:  eta: 0:02:42  iter: 3959  total_loss: 0.4376  loss_cls: 0.08789  loss_box_reg: 0.04415  loss_rpn_cls: 0.1974  loss_rpn_loc: 0.05953  validation_loss: 0.4095    time: 0.0790  last_time: 0.0846  data_time: 0.0025  last_data_time: 0.0027   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:51:30 d2.utils.events]:  eta: 0:02:40  iter: 3979  total_loss: 0.4238  loss_cls: 0.09152  loss_box_reg: 0.04129  loss_rpn_cls: 0.2186  loss_rpn_loc: 0.05716  validation_loss: 0.4095    time: 0.0790  last_time: 0.0827  data_time: 0.0027  last_data_time: 0.0033   lr: 2.5e-06  max_mem: 2126M\n",
      "WARNING [03/22 13:51:31 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/22 13:51:31 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/22 13:51:31 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[03/22 13:51:31 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "[03/22 13:51:31 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/22 13:51:31 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "[03/22 13:51:31 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n",
      "WARNING [03/22 13:51:31 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[03/22 13:51:31 d2.evaluation.evaluator]: Start inference on 1801 batches\n",
      "[03/22 13:51:32 d2.evaluation.evaluator]: Inference done 11/1801. Dataloading: 0.0007 s/iter. Inference: 0.0260 s/iter. Eval: 0.0001 s/iter. Total: 0.0268 s/iter. ETA=0:00:47\n",
      "[03/22 13:51:37 d2.evaluation.evaluator]: Inference done 194/1801. Dataloading: 0.0008 s/iter. Inference: 0.0263 s/iter. Eval: 0.0001 s/iter. Total: 0.0273 s/iter. ETA=0:00:43\n",
      "[03/22 13:51:42 d2.evaluation.evaluator]: Inference done 381/1801. Dataloading: 0.0008 s/iter. Inference: 0.0261 s/iter. Eval: 0.0001 s/iter. Total: 0.0271 s/iter. ETA=0:00:38\n",
      "[03/22 13:51:47 d2.evaluation.evaluator]: Inference done 572/1801. Dataloading: 0.0008 s/iter. Inference: 0.0258 s/iter. Eval: 0.0001 s/iter. Total: 0.0268 s/iter. ETA=0:00:32\n",
      "[03/22 13:51:52 d2.evaluation.evaluator]: Inference done 756/1801. Dataloading: 0.0008 s/iter. Inference: 0.0259 s/iter. Eval: 0.0001 s/iter. Total: 0.0269 s/iter. ETA=0:00:28\n",
      "[03/22 13:51:57 d2.evaluation.evaluator]: Inference done 944/1801. Dataloading: 0.0008 s/iter. Inference: 0.0258 s/iter. Eval: 0.0001 s/iter. Total: 0.0269 s/iter. ETA=0:00:23\n",
      "[03/22 13:52:02 d2.evaluation.evaluator]: Inference done 1121/1801. Dataloading: 0.0008 s/iter. Inference: 0.0261 s/iter. Eval: 0.0001 s/iter. Total: 0.0271 s/iter. ETA=0:00:18\n",
      "[03/22 13:52:07 d2.evaluation.evaluator]: Inference done 1311/1801. Dataloading: 0.0008 s/iter. Inference: 0.0260 s/iter. Eval: 0.0001 s/iter. Total: 0.0270 s/iter. ETA=0:00:13\n",
      "[03/22 13:52:12 d2.evaluation.evaluator]: Inference done 1494/1801. Dataloading: 0.0008 s/iter. Inference: 0.0260 s/iter. Eval: 0.0001 s/iter. Total: 0.0270 s/iter. ETA=0:00:08\n",
      "[03/22 13:52:17 d2.evaluation.evaluator]: Inference done 1681/1801. Dataloading: 0.0008 s/iter. Inference: 0.0260 s/iter. Eval: 0.0001 s/iter. Total: 0.0270 s/iter. ETA=0:00:03\n",
      "[03/22 13:52:20 d2.evaluation.evaluator]: Total inference time: 0:00:48.501640 (0.027005 s / iter per device, on 1 devices)\n",
      "[03/22 13:52:20 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:46 (0.025951 s / iter per device, on 1 devices)\n",
      "[03/22 13:52:20 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[03/22 13:52:20 d2.evaluation.coco_evaluation]: Saving results to /workspace/output/output_res030_bs2_03.22.13.44/inference/coco_instances_results.json\n",
      "[03/22 13:52:20 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.33s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "[03/22 13:52:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.044 | 0.195  | 0.005  | 0.052 | 0.002 | 0.000 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:52:24 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
      "| category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|\n",
      "| DT         | 0.088 | TT         | 0.000 |\n",
      "[03/22 13:52:24 d2.engine.defaults]: Evaluation results for tower_val_03012 in csv format:\n",
      "[03/22 13:52:24 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[03/22 13:52:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[03/22 13:52:24 d2.evaluation.testing]: copypaste: 0.0442,0.1947,0.0045,0.0523,0.0020,0.0000\n",
      "[03/22 13:53:26 d2.utils.events]:  eta: 0:02:39  iter: 3999  total_loss: 0.4484  loss_cls: 0.0921  loss_box_reg: 0.0433  loss_rpn_cls: 0.2269  loss_rpn_loc: 0.07332  validation_loss: 0.445    time: 0.0790  last_time: 0.0792  data_time: 0.0030  last_data_time: 0.0031   lr: 2.5e-06  max_mem: 2126M\n",
      "[03/22 13:53:27 d2.utils.events]:  eta: 0:02:37  iter: 4019  total_loss: 0.43  loss_cls: 0.09008  loss_box_reg: 0.03159  loss_rpn_cls: 0.237  loss_rpn_loc: 0.06633  validation_loss: 0.445    time: 0.0790  last_time: 0.0742  data_time: 0.0029  last_data_time: 0.0025   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:29 d2.utils.events]:  eta: 0:02:36  iter: 4039  total_loss: 0.487  loss_cls: 0.08924  loss_box_reg: 0.03795  loss_rpn_cls: 0.2406  loss_rpn_loc: 0.06628  validation_loss: 0.445    time: 0.0790  last_time: 0.0800  data_time: 0.0028  last_data_time: 0.0035   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:31 d2.utils.events]:  eta: 0:02:34  iter: 4059  total_loss: 0.4154  loss_cls: 0.09909  loss_box_reg: 0.05513  loss_rpn_cls: 0.2074  loss_rpn_loc: 0.04788  validation_loss: 0.445    time: 0.0790  last_time: 0.0767  data_time: 0.0029  last_data_time: 0.0025   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:32 d2.utils.events]:  eta: 0:02:32  iter: 4079  total_loss: 0.3856  loss_cls: 0.07705  loss_box_reg: 0.03829  loss_rpn_cls: 0.1908  loss_rpn_loc: 0.038  validation_loss: 0.445    time: 0.0790  last_time: 0.0819  data_time: 0.0029  last_data_time: 0.0026   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:34 d2.utils.events]:  eta: 0:02:31  iter: 4099  total_loss: 0.352  loss_cls: 0.06942  loss_box_reg: 0.01443  loss_rpn_cls: 0.1947  loss_rpn_loc: 0.04261  validation_loss: 0.445    time: 0.0790  last_time: 0.0844  data_time: 0.0028  last_data_time: 0.0032   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:35 d2.utils.events]:  eta: 0:02:29  iter: 4119  total_loss: 0.3417  loss_cls: 0.07256  loss_box_reg: 0.02628  loss_rpn_cls: 0.2027  loss_rpn_loc: 0.03913  validation_loss: 0.445    time: 0.0790  last_time: 0.0818  data_time: 0.0029  last_data_time: 0.0034   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:37 d2.utils.events]:  eta: 0:02:27  iter: 4139  total_loss: 0.4249  loss_cls: 0.1011  loss_box_reg: 0.05119  loss_rpn_cls: 0.2193  loss_rpn_loc: 0.04563  validation_loss: 0.445    time: 0.0790  last_time: 0.0830  data_time: 0.0029  last_data_time: 0.0030   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:39 d2.utils.events]:  eta: 0:02:26  iter: 4159  total_loss: 0.3396  loss_cls: 0.06801  loss_box_reg: 0.009853  loss_rpn_cls: 0.2018  loss_rpn_loc: 0.03702  validation_loss: 0.445    time: 0.0790  last_time: 0.0832  data_time: 0.0027  last_data_time: 0.0026   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:40 d2.utils.events]:  eta: 0:02:24  iter: 4179  total_loss: 0.3982  loss_cls: 0.07866  loss_box_reg: 0.02903  loss_rpn_cls: 0.2333  loss_rpn_loc: 0.03988  validation_loss: 0.445    time: 0.0790  last_time: 0.0757  data_time: 0.0030  last_data_time: 0.0025   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:42 d2.utils.events]:  eta: 0:02:22  iter: 4199  total_loss: 0.3484  loss_cls: 0.08757  loss_box_reg: 0.04032  loss_rpn_cls: 0.153  loss_rpn_loc: 0.03248  validation_loss: 0.445    time: 0.0790  last_time: 0.0761  data_time: 0.0029  last_data_time: 0.0031   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:43 d2.utils.events]:  eta: 0:02:21  iter: 4219  total_loss: 0.4338  loss_cls: 0.1072  loss_box_reg: 0.03723  loss_rpn_cls: 0.2294  loss_rpn_loc: 0.0587  validation_loss: 0.445    time: 0.0790  last_time: 0.0758  data_time: 0.0028  last_data_time: 0.0025   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:45 d2.utils.events]:  eta: 0:02:19  iter: 4239  total_loss: 0.4873  loss_cls: 0.08451  loss_box_reg: 0.0337  loss_rpn_cls: 0.2246  loss_rpn_loc: 0.07131  validation_loss: 0.445    time: 0.0790  last_time: 0.0829  data_time: 0.0029  last_data_time: 0.0024   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:46 d2.utils.events]:  eta: 0:02:18  iter: 4259  total_loss: 0.4716  loss_cls: 0.07946  loss_box_reg: 0.0359  loss_rpn_cls: 0.2108  loss_rpn_loc: 0.06649  validation_loss: 0.445    time: 0.0790  last_time: 0.0861  data_time: 0.0026  last_data_time: 0.0030   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:48 d2.utils.events]:  eta: 0:02:16  iter: 4279  total_loss: 0.4474  loss_cls: 0.08641  loss_box_reg: 0.04714  loss_rpn_cls: 0.2028  loss_rpn_loc: 0.05446  validation_loss: 0.445    time: 0.0790  last_time: 0.0828  data_time: 0.0027  last_data_time: 0.0027   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:50 d2.utils.events]:  eta: 0:02:14  iter: 4299  total_loss: 0.4605  loss_cls: 0.106  loss_box_reg: 0.04835  loss_rpn_cls: 0.2008  loss_rpn_loc: 0.06239  validation_loss: 0.445    time: 0.0790  last_time: 0.0810  data_time: 0.0026  last_data_time: 0.0031   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:51 d2.utils.events]:  eta: 0:02:13  iter: 4319  total_loss: 0.4659  loss_cls: 0.08877  loss_box_reg: 0.03301  loss_rpn_cls: 0.2451  loss_rpn_loc: 0.0886  validation_loss: 0.445    time: 0.0790  last_time: 0.0824  data_time: 0.0029  last_data_time: 0.0031   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:53 d2.utils.events]:  eta: 0:02:11  iter: 4339  total_loss: 0.4505  loss_cls: 0.08693  loss_box_reg: 0.0383  loss_rpn_cls: 0.2341  loss_rpn_loc: 0.07005  validation_loss: 0.445    time: 0.0790  last_time: 0.0778  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:54 d2.utils.events]:  eta: 0:02:10  iter: 4359  total_loss: 0.5606  loss_cls: 0.1163  loss_box_reg: 0.04675  loss_rpn_cls: 0.285  loss_rpn_loc: 0.08158  validation_loss: 0.445    time: 0.0790  last_time: 0.0766  data_time: 0.0027  last_data_time: 0.0029   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:56 d2.utils.events]:  eta: 0:02:08  iter: 4379  total_loss: 0.3491  loss_cls: 0.07538  loss_box_reg: 0.01312  loss_rpn_cls: 0.1936  loss_rpn_loc: 0.04666  validation_loss: 0.445    time: 0.0790  last_time: 0.0796  data_time: 0.0030  last_data_time: 0.0029   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:58 d2.utils.events]:  eta: 0:02:06  iter: 4399  total_loss: 0.4039  loss_cls: 0.1073  loss_box_reg: 0.05699  loss_rpn_cls: 0.202  loss_rpn_loc: 0.04817  validation_loss: 0.445    time: 0.0790  last_time: 0.0820  data_time: 0.0028  last_data_time: 0.0028   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:53:59 d2.utils.events]:  eta: 0:02:05  iter: 4419  total_loss: 0.3951  loss_cls: 0.09965  loss_box_reg: 0.04207  loss_rpn_cls: 0.2068  loss_rpn_loc: 0.04334  validation_loss: 0.445    time: 0.0790  last_time: 0.0845  data_time: 0.0029  last_data_time: 0.0027   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:01 d2.utils.events]:  eta: 0:02:03  iter: 4439  total_loss: 0.4196  loss_cls: 0.09277  loss_box_reg: 0.04872  loss_rpn_cls: 0.2092  loss_rpn_loc: 0.03767  validation_loss: 0.445    time: 0.0790  last_time: 0.0818  data_time: 0.0028  last_data_time: 0.0029   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:02 d2.utils.events]:  eta: 0:02:02  iter: 4459  total_loss: 0.3645  loss_cls: 0.08232  loss_box_reg: 0.03332  loss_rpn_cls: 0.1938  loss_rpn_loc: 0.03636  validation_loss: 0.445    time: 0.0790  last_time: 0.0864  data_time: 0.0029  last_data_time: 0.0029   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:04 d2.utils.events]:  eta: 0:02:00  iter: 4479  total_loss: 0.4783  loss_cls: 0.07615  loss_box_reg: 0.03773  loss_rpn_cls: 0.2267  loss_rpn_loc: 0.0611  validation_loss: 0.445    time: 0.0791  last_time: 0.0783  data_time: 0.0030  last_data_time: 0.0033   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:06 d2.utils.events]:  eta: 0:01:58  iter: 4499  total_loss: 0.401  loss_cls: 0.08194  loss_box_reg: 0.03052  loss_rpn_cls: 0.1864  loss_rpn_loc: 0.04183  validation_loss: 0.445    time: 0.0791  last_time: 0.0818  data_time: 0.0029  last_data_time: 0.0028   lr: 2.5e-07  max_mem: 2126M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:54:07 d2.utils.events]:  eta: 0:01:57  iter: 4519  total_loss: 0.4186  loss_cls: 0.091  loss_box_reg: 0.04234  loss_rpn_cls: 0.2319  loss_rpn_loc: 0.06676  validation_loss: 0.445    time: 0.0791  last_time: 0.0796  data_time: 0.0028  last_data_time: 0.0023   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:09 d2.utils.events]:  eta: 0:01:55  iter: 4539  total_loss: 0.4188  loss_cls: 0.09459  loss_box_reg: 0.03731  loss_rpn_cls: 0.2157  loss_rpn_loc: 0.05166  validation_loss: 0.445    time: 0.0791  last_time: 0.0764  data_time: 0.0026  last_data_time: 0.0026   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:10 d2.utils.events]:  eta: 0:01:54  iter: 4559  total_loss: 0.4609  loss_cls: 0.09506  loss_box_reg: 0.04277  loss_rpn_cls: 0.2326  loss_rpn_loc: 0.07201  validation_loss: 0.445    time: 0.0790  last_time: 0.0799  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:12 d2.utils.events]:  eta: 0:01:52  iter: 4579  total_loss: 0.4029  loss_cls: 0.08624  loss_box_reg: 0.03331  loss_rpn_cls: 0.2012  loss_rpn_loc: 0.05426  validation_loss: 0.445    time: 0.0791  last_time: 0.0850  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:14 d2.utils.events]:  eta: 0:01:50  iter: 4599  total_loss: 0.4061  loss_cls: 0.09115  loss_box_reg: 0.04519  loss_rpn_cls: 0.1864  loss_rpn_loc: 0.03989  validation_loss: 0.445    time: 0.0790  last_time: 0.0780  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:15 d2.utils.events]:  eta: 0:01:49  iter: 4619  total_loss: 0.4197  loss_cls: 0.07529  loss_box_reg: 0.03017  loss_rpn_cls: 0.2168  loss_rpn_loc: 0.06356  validation_loss: 0.445    time: 0.0791  last_time: 0.0850  data_time: 0.0028  last_data_time: 0.0027   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:17 d2.utils.events]:  eta: 0:01:47  iter: 4639  total_loss: 0.5069  loss_cls: 0.09856  loss_box_reg: 0.05345  loss_rpn_cls: 0.2418  loss_rpn_loc: 0.07142  validation_loss: 0.445    time: 0.0791  last_time: 0.0763  data_time: 0.0031  last_data_time: 0.0028   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:18 d2.utils.events]:  eta: 0:01:46  iter: 4659  total_loss: 0.4119  loss_cls: 0.08378  loss_box_reg: 0.02528  loss_rpn_cls: 0.2001  loss_rpn_loc: 0.05252  validation_loss: 0.445    time: 0.0791  last_time: 0.0750  data_time: 0.0030  last_data_time: 0.0026   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:20 d2.utils.events]:  eta: 0:01:44  iter: 4679  total_loss: 0.3565  loss_cls: 0.07476  loss_box_reg: 0.02933  loss_rpn_cls: 0.2  loss_rpn_loc: 0.05258  validation_loss: 0.445    time: 0.0791  last_time: 0.0747  data_time: 0.0030  last_data_time: 0.0027   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:21 d2.utils.events]:  eta: 0:01:43  iter: 4699  total_loss: 0.4676  loss_cls: 0.09855  loss_box_reg: 0.03628  loss_rpn_cls: 0.2088  loss_rpn_loc: 0.05261  validation_loss: 0.445    time: 0.0790  last_time: 0.0758  data_time: 0.0029  last_data_time: 0.0031   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:23 d2.utils.events]:  eta: 0:01:41  iter: 4719  total_loss: 0.4501  loss_cls: 0.08457  loss_box_reg: 0.04791  loss_rpn_cls: 0.2139  loss_rpn_loc: 0.05259  validation_loss: 0.445    time: 0.0790  last_time: 0.0790  data_time: 0.0028  last_data_time: 0.0027   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:25 d2.utils.events]:  eta: 0:01:39  iter: 4739  total_loss: 0.425  loss_cls: 0.09987  loss_box_reg: 0.05509  loss_rpn_cls: 0.2181  loss_rpn_loc: 0.05415  validation_loss: 0.445    time: 0.0790  last_time: 0.0733  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:26 d2.utils.events]:  eta: 0:01:38  iter: 4759  total_loss: 0.3761  loss_cls: 0.08833  loss_box_reg: 0.04136  loss_rpn_cls: 0.2052  loss_rpn_loc: 0.04412  validation_loss: 0.445    time: 0.0790  last_time: 0.0776  data_time: 0.0026  last_data_time: 0.0023   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:28 d2.utils.events]:  eta: 0:01:36  iter: 4779  total_loss: 0.4034  loss_cls: 0.09596  loss_box_reg: 0.05205  loss_rpn_cls: 0.2039  loss_rpn_loc: 0.05569  validation_loss: 0.445    time: 0.0790  last_time: 0.0788  data_time: 0.0026  last_data_time: 0.0034   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:29 d2.utils.events]:  eta: 0:01:34  iter: 4799  total_loss: 0.4668  loss_cls: 0.1018  loss_box_reg: 0.04152  loss_rpn_cls: 0.2165  loss_rpn_loc: 0.06311  validation_loss: 0.445    time: 0.0790  last_time: 0.0745  data_time: 0.0026  last_data_time: 0.0034   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:31 d2.utils.events]:  eta: 0:01:33  iter: 4819  total_loss: 0.5032  loss_cls: 0.07859  loss_box_reg: 0.0288  loss_rpn_cls: 0.2786  loss_rpn_loc: 0.1051  validation_loss: 0.445    time: 0.0790  last_time: 0.0812  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:33 d2.utils.events]:  eta: 0:01:31  iter: 4839  total_loss: 0.4444  loss_cls: 0.0979  loss_box_reg: 0.03802  loss_rpn_cls: 0.2347  loss_rpn_loc: 0.06834  validation_loss: 0.445    time: 0.0790  last_time: 0.0818  data_time: 0.0027  last_data_time: 0.0027   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:34 d2.utils.events]:  eta: 0:01:30  iter: 4859  total_loss: 0.3718  loss_cls: 0.08889  loss_box_reg: 0.04673  loss_rpn_cls: 0.2032  loss_rpn_loc: 0.04093  validation_loss: 0.445    time: 0.0791  last_time: 0.0794  data_time: 0.0028  last_data_time: 0.0024   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:36 d2.utils.events]:  eta: 0:01:28  iter: 4879  total_loss: 0.4879  loss_cls: 0.1011  loss_box_reg: 0.04668  loss_rpn_cls: 0.2374  loss_rpn_loc: 0.06107  validation_loss: 0.445    time: 0.0791  last_time: 0.0811  data_time: 0.0026  last_data_time: 0.0026   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:37 d2.utils.events]:  eta: 0:01:27  iter: 4899  total_loss: 0.3721  loss_cls: 0.08018  loss_box_reg: 0.03941  loss_rpn_cls: 0.1927  loss_rpn_loc: 0.05022  validation_loss: 0.445    time: 0.0791  last_time: 0.0809  data_time: 0.0029  last_data_time: 0.0027   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:39 d2.utils.events]:  eta: 0:01:25  iter: 4919  total_loss: 0.3549  loss_cls: 0.08451  loss_box_reg: 0.04471  loss_rpn_cls: 0.1766  loss_rpn_loc: 0.03842  validation_loss: 0.445    time: 0.0791  last_time: 0.0763  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:41 d2.utils.events]:  eta: 0:01:24  iter: 4939  total_loss: 0.3794  loss_cls: 0.08288  loss_box_reg: 0.03883  loss_rpn_cls: 0.2071  loss_rpn_loc: 0.04648  validation_loss: 0.445    time: 0.0791  last_time: 0.0854  data_time: 0.0029  last_data_time: 0.0027   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:42 d2.utils.events]:  eta: 0:01:22  iter: 4959  total_loss: 0.4219  loss_cls: 0.08792  loss_box_reg: 0.04553  loss_rpn_cls: 0.2161  loss_rpn_loc: 0.04615  validation_loss: 0.445    time: 0.0791  last_time: 0.0756  data_time: 0.0030  last_data_time: 0.0029   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:44 d2.utils.events]:  eta: 0:01:20  iter: 4979  total_loss: 0.4115  loss_cls: 0.08773  loss_box_reg: 0.04058  loss_rpn_cls: 0.2329  loss_rpn_loc: 0.05383  validation_loss: 0.445    time: 0.0791  last_time: 0.0835  data_time: 0.0029  last_data_time: 0.0032   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:46 d2.utils.events]:  eta: 0:01:19  iter: 4999  total_loss: 0.3868  loss_cls: 0.08192  loss_box_reg: 0.04516  loss_rpn_cls: 0.1813  loss_rpn_loc: 0.03954  validation_loss: 0.445    time: 0.0791  last_time: 0.0769  data_time: 0.0031  last_data_time: 0.0036   lr: 2.5e-07  max_mem: 2126M\n",
      "[03/22 13:54:47 d2.utils.events]:  eta: 0:01:17  iter: 5019  total_loss: 0.4598  loss_cls: 0.1011  loss_box_reg: 0.05347  loss_rpn_cls: 0.2246  loss_rpn_loc: 0.05411  validation_loss: 0.445    time: 0.0791  last_time: 0.0830  data_time: 0.0028  last_data_time: 0.0025   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:54:49 d2.utils.events]:  eta: 0:01:16  iter: 5039  total_loss: 0.4159  loss_cls: 0.0843  loss_box_reg: 0.04989  loss_rpn_cls: 0.2052  loss_rpn_loc: 0.04976  validation_loss: 0.445    time: 0.0791  last_time: 0.0760  data_time: 0.0026  last_data_time: 0.0025   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:54:51 d2.utils.events]:  eta: 0:01:14  iter: 5059  total_loss: 0.4235  loss_cls: 0.07981  loss_box_reg: 0.02647  loss_rpn_cls: 0.2166  loss_rpn_loc: 0.06574  validation_loss: 0.445    time: 0.0791  last_time: 0.0757  data_time: 0.0028  last_data_time: 0.0024   lr: 2.5e-08  max_mem: 2126M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:54:52 d2.utils.events]:  eta: 0:01:12  iter: 5079  total_loss: 0.4493  loss_cls: 0.0872  loss_box_reg: 0.06273  loss_rpn_cls: 0.2094  loss_rpn_loc: 0.06414  validation_loss: 0.445    time: 0.0791  last_time: 0.0802  data_time: 0.0030  last_data_time: 0.0028   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:54:54 d2.utils.events]:  eta: 0:01:11  iter: 5099  total_loss: 0.4393  loss_cls: 0.1035  loss_box_reg: 0.06586  loss_rpn_cls: 0.1952  loss_rpn_loc: 0.04694  validation_loss: 0.445    time: 0.0791  last_time: 0.0850  data_time: 0.0029  last_data_time: 0.0037   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:54:55 d2.utils.events]:  eta: 0:01:09  iter: 5119  total_loss: 0.4941  loss_cls: 0.09797  loss_box_reg: 0.04549  loss_rpn_cls: 0.2334  loss_rpn_loc: 0.05289  validation_loss: 0.445    time: 0.0791  last_time: 0.0762  data_time: 0.0027  last_data_time: 0.0028   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:54:57 d2.utils.events]:  eta: 0:01:08  iter: 5139  total_loss: 0.4852  loss_cls: 0.1048  loss_box_reg: 0.05737  loss_rpn_cls: 0.2325  loss_rpn_loc: 0.06651  validation_loss: 0.445    time: 0.0791  last_time: 0.0834  data_time: 0.0031  last_data_time: 0.0030   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:54:59 d2.utils.events]:  eta: 0:01:06  iter: 5159  total_loss: 0.4275  loss_cls: 0.1018  loss_box_reg: 0.03701  loss_rpn_cls: 0.2256  loss_rpn_loc: 0.05472  validation_loss: 0.445    time: 0.0791  last_time: 0.0763  data_time: 0.0027  last_data_time: 0.0028   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:00 d2.utils.events]:  eta: 0:01:04  iter: 5179  total_loss: 0.4159  loss_cls: 0.08193  loss_box_reg: 0.03419  loss_rpn_cls: 0.2219  loss_rpn_loc: 0.0471  validation_loss: 0.445    time: 0.0791  last_time: 0.0781  data_time: 0.0027  last_data_time: 0.0027   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:02 d2.utils.events]:  eta: 0:01:03  iter: 5199  total_loss: 0.4567  loss_cls: 0.0866  loss_box_reg: 0.02262  loss_rpn_cls: 0.2573  loss_rpn_loc: 0.05837  validation_loss: 0.445    time: 0.0791  last_time: 0.0955  data_time: 0.0029  last_data_time: 0.0041   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:03 d2.utils.events]:  eta: 0:01:01  iter: 5219  total_loss: 0.4188  loss_cls: 0.09424  loss_box_reg: 0.03622  loss_rpn_cls: 0.2011  loss_rpn_loc: 0.04133  validation_loss: 0.445    time: 0.0791  last_time: 0.0853  data_time: 0.0030  last_data_time: 0.0028   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:05 d2.utils.events]:  eta: 0:01:00  iter: 5239  total_loss: 0.3931  loss_cls: 0.06887  loss_box_reg: 0.02754  loss_rpn_cls: 0.2077  loss_rpn_loc: 0.05599  validation_loss: 0.445    time: 0.0791  last_time: 0.0798  data_time: 0.0029  last_data_time: 0.0026   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:07 d2.utils.events]:  eta: 0:00:58  iter: 5259  total_loss: 0.4963  loss_cls: 0.09398  loss_box_reg: 0.02826  loss_rpn_cls: 0.2263  loss_rpn_loc: 0.0779  validation_loss: 0.445    time: 0.0791  last_time: 0.0771  data_time: 0.0028  last_data_time: 0.0030   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:08 d2.utils.events]:  eta: 0:00:57  iter: 5279  total_loss: 0.4349  loss_cls: 0.1044  loss_box_reg: 0.0453  loss_rpn_cls: 0.2099  loss_rpn_loc: 0.05633  validation_loss: 0.445    time: 0.0791  last_time: 0.0833  data_time: 0.0030  last_data_time: 0.0026   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:10 d2.utils.events]:  eta: 0:00:55  iter: 5299  total_loss: 0.3616  loss_cls: 0.06905  loss_box_reg: 0.02442  loss_rpn_cls: 0.1992  loss_rpn_loc: 0.04864  validation_loss: 0.445    time: 0.0791  last_time: 0.0808  data_time: 0.0027  last_data_time: 0.0026   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:11 d2.utils.events]:  eta: 0:00:53  iter: 5319  total_loss: 0.3995  loss_cls: 0.07263  loss_box_reg: 0.02758  loss_rpn_cls: 0.2146  loss_rpn_loc: 0.04783  validation_loss: 0.445    time: 0.0791  last_time: 0.0759  data_time: 0.0026  last_data_time: 0.0026   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:13 d2.utils.events]:  eta: 0:00:52  iter: 5339  total_loss: 0.3607  loss_cls: 0.07964  loss_box_reg: 0.03209  loss_rpn_cls: 0.183  loss_rpn_loc: 0.04858  validation_loss: 0.445    time: 0.0791  last_time: 0.0836  data_time: 0.0027  last_data_time: 0.0026   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:15 d2.utils.events]:  eta: 0:00:50  iter: 5359  total_loss: 0.3755  loss_cls: 0.08136  loss_box_reg: 0.0244  loss_rpn_cls: 0.1956  loss_rpn_loc: 0.04922  validation_loss: 0.445    time: 0.0791  last_time: 0.0803  data_time: 0.0028  last_data_time: 0.0027   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:16 d2.utils.events]:  eta: 0:00:49  iter: 5379  total_loss: 0.3734  loss_cls: 0.07526  loss_box_reg: 0.02866  loss_rpn_cls: 0.2028  loss_rpn_loc: 0.04058  validation_loss: 0.445    time: 0.0791  last_time: 0.0783  data_time: 0.0027  last_data_time: 0.0027   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:18 d2.utils.events]:  eta: 0:00:47  iter: 5399  total_loss: 0.4529  loss_cls: 0.07696  loss_box_reg: 0.02594  loss_rpn_cls: 0.2271  loss_rpn_loc: 0.08044  validation_loss: 0.445    time: 0.0791  last_time: 0.0812  data_time: 0.0027  last_data_time: 0.0027   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:19 d2.utils.events]:  eta: 0:00:45  iter: 5419  total_loss: 0.4557  loss_cls: 0.08736  loss_box_reg: 0.03461  loss_rpn_cls: 0.2239  loss_rpn_loc: 0.05595  validation_loss: 0.445    time: 0.0791  last_time: 0.0829  data_time: 0.0026  last_data_time: 0.0027   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:21 d2.utils.events]:  eta: 0:00:44  iter: 5439  total_loss: 0.4454  loss_cls: 0.07747  loss_box_reg: 0.03754  loss_rpn_cls: 0.2269  loss_rpn_loc: 0.06121  validation_loss: 0.445    time: 0.0791  last_time: 0.0785  data_time: 0.0027  last_data_time: 0.0029   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:23 d2.utils.events]:  eta: 0:00:42  iter: 5459  total_loss: 0.4002  loss_cls: 0.07534  loss_box_reg: 0.02643  loss_rpn_cls: 0.1888  loss_rpn_loc: 0.03833  validation_loss: 0.445    time: 0.0791  last_time: 0.0778  data_time: 0.0027  last_data_time: 0.0022   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:24 d2.utils.events]:  eta: 0:00:41  iter: 5479  total_loss: 0.4338  loss_cls: 0.09515  loss_box_reg: 0.03983  loss_rpn_cls: 0.2329  loss_rpn_loc: 0.07178  validation_loss: 0.445    time: 0.0791  last_time: 0.0820  data_time: 0.0027  last_data_time: 0.0029   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:26 d2.utils.events]:  eta: 0:00:39  iter: 5499  total_loss: 0.3378  loss_cls: 0.06925  loss_box_reg: 0.02416  loss_rpn_cls: 0.1856  loss_rpn_loc: 0.04369  validation_loss: 0.445    time: 0.0791  last_time: 0.0863  data_time: 0.0028  last_data_time: 0.0036   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:27 d2.utils.events]:  eta: 0:00:38  iter: 5519  total_loss: 0.4587  loss_cls: 0.09846  loss_box_reg: 0.04888  loss_rpn_cls: 0.2103  loss_rpn_loc: 0.05721  validation_loss: 0.445    time: 0.0791  last_time: 0.0806  data_time: 0.0026  last_data_time: 0.0023   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:29 d2.utils.events]:  eta: 0:00:36  iter: 5539  total_loss: 0.4055  loss_cls: 0.08078  loss_box_reg: 0.03197  loss_rpn_cls: 0.2094  loss_rpn_loc: 0.06542  validation_loss: 0.445    time: 0.0791  last_time: 0.0770  data_time: 0.0026  last_data_time: 0.0023   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:31 d2.utils.events]:  eta: 0:00:34  iter: 5559  total_loss: 0.4072  loss_cls: 0.09453  loss_box_reg: 0.0632  loss_rpn_cls: 0.1844  loss_rpn_loc: 0.04357  validation_loss: 0.445    time: 0.0791  last_time: 0.0794  data_time: 0.0025  last_data_time: 0.0023   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:32 d2.utils.events]:  eta: 0:00:33  iter: 5579  total_loss: 0.4237  loss_cls: 0.1033  loss_box_reg: 0.04507  loss_rpn_cls: 0.2137  loss_rpn_loc: 0.04428  validation_loss: 0.445    time: 0.0791  last_time: 0.0819  data_time: 0.0025  last_data_time: 0.0036   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:34 d2.utils.events]:  eta: 0:00:31  iter: 5599  total_loss: 0.3553  loss_cls: 0.08315  loss_box_reg: 0.03524  loss_rpn_cls: 0.1664  loss_rpn_loc: 0.03553  validation_loss: 0.445    time: 0.0791  last_time: 0.0782  data_time: 0.0027  last_data_time: 0.0028   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:35 d2.utils.events]:  eta: 0:00:30  iter: 5619  total_loss: 0.3323  loss_cls: 0.07364  loss_box_reg: 0.03706  loss_rpn_cls: 0.1719  loss_rpn_loc: 0.0443  validation_loss: 0.445    time: 0.0791  last_time: 0.0733  data_time: 0.0024  last_data_time: 0.0026   lr: 2.5e-08  max_mem: 2126M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:55:37 d2.utils.events]:  eta: 0:00:28  iter: 5639  total_loss: 0.4078  loss_cls: 0.07942  loss_box_reg: 0.04023  loss_rpn_cls: 0.2314  loss_rpn_loc: 0.05553  validation_loss: 0.445    time: 0.0791  last_time: 0.0768  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:38 d2.utils.events]:  eta: 0:00:26  iter: 5659  total_loss: 0.5276  loss_cls: 0.09586  loss_box_reg: 0.04368  loss_rpn_cls: 0.2506  loss_rpn_loc: 0.0891  validation_loss: 0.445    time: 0.0791  last_time: 0.0833  data_time: 0.0029  last_data_time: 0.0040   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:40 d2.utils.events]:  eta: 0:00:25  iter: 5679  total_loss: 0.4621  loss_cls: 0.09833  loss_box_reg: 0.05539  loss_rpn_cls: 0.2141  loss_rpn_loc: 0.05159  validation_loss: 0.445    time: 0.0791  last_time: 0.0818  data_time: 0.0030  last_data_time: 0.0025   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:42 d2.utils.events]:  eta: 0:00:23  iter: 5699  total_loss: 0.4272  loss_cls: 0.09628  loss_box_reg: 0.04563  loss_rpn_cls: 0.2115  loss_rpn_loc: 0.05736  validation_loss: 0.445    time: 0.0791  last_time: 0.0835  data_time: 0.0027  last_data_time: 0.0025   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:43 d2.utils.events]:  eta: 0:00:22  iter: 5719  total_loss: 0.4379  loss_cls: 0.108  loss_box_reg: 0.06187  loss_rpn_cls: 0.1884  loss_rpn_loc: 0.05599  validation_loss: 0.445    time: 0.0791  last_time: 0.0801  data_time: 0.0028  last_data_time: 0.0031   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:45 d2.utils.events]:  eta: 0:00:20  iter: 5739  total_loss: 0.3894  loss_cls: 0.07193  loss_box_reg: 0.02655  loss_rpn_cls: 0.2065  loss_rpn_loc: 0.05627  validation_loss: 0.445    time: 0.0791  last_time: 0.0739  data_time: 0.0030  last_data_time: 0.0024   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:46 d2.utils.events]:  eta: 0:00:19  iter: 5759  total_loss: 0.426  loss_cls: 0.0908  loss_box_reg: 0.03684  loss_rpn_cls: 0.2419  loss_rpn_loc: 0.0551  validation_loss: 0.445    time: 0.0791  last_time: 0.0758  data_time: 0.0029  last_data_time: 0.0032   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:48 d2.utils.events]:  eta: 0:00:17  iter: 5779  total_loss: 0.4468  loss_cls: 0.1048  loss_box_reg: 0.0563  loss_rpn_cls: 0.2211  loss_rpn_loc: 0.06338  validation_loss: 0.445    time: 0.0791  last_time: 0.0760  data_time: 0.0028  last_data_time: 0.0026   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:49 d2.utils.events]:  eta: 0:00:15  iter: 5799  total_loss: 0.4304  loss_cls: 0.08755  loss_box_reg: 0.0447  loss_rpn_cls: 0.2158  loss_rpn_loc: 0.05351  validation_loss: 0.445    time: 0.0791  last_time: 0.0761  data_time: 0.0026  last_data_time: 0.0027   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:51 d2.utils.events]:  eta: 0:00:14  iter: 5819  total_loss: 0.4851  loss_cls: 0.1009  loss_box_reg: 0.04991  loss_rpn_cls: 0.2186  loss_rpn_loc: 0.06165  validation_loss: 0.445    time: 0.0791  last_time: 0.0780  data_time: 0.0028  last_data_time: 0.0034   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:53 d2.utils.events]:  eta: 0:00:12  iter: 5839  total_loss: 0.4066  loss_cls: 0.0905  loss_box_reg: 0.03765  loss_rpn_cls: 0.2112  loss_rpn_loc: 0.0587  validation_loss: 0.445    time: 0.0791  last_time: 0.0768  data_time: 0.0026  last_data_time: 0.0026   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:54 d2.utils.events]:  eta: 0:00:11  iter: 5859  total_loss: 0.3539  loss_cls: 0.08969  loss_box_reg: 0.03997  loss_rpn_cls: 0.1827  loss_rpn_loc: 0.03834  validation_loss: 0.445    time: 0.0791  last_time: 0.0856  data_time: 0.0028  last_data_time: 0.0030   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:56 d2.utils.events]:  eta: 0:00:09  iter: 5879  total_loss: 0.4225  loss_cls: 0.07767  loss_box_reg: 0.03285  loss_rpn_cls: 0.2331  loss_rpn_loc: 0.05273  validation_loss: 0.445    time: 0.0791  last_time: 0.0808  data_time: 0.0028  last_data_time: 0.0036   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:57 d2.utils.events]:  eta: 0:00:07  iter: 5899  total_loss: 0.4391  loss_cls: 0.0815  loss_box_reg: 0.02907  loss_rpn_cls: 0.2217  loss_rpn_loc: 0.06226  validation_loss: 0.445    time: 0.0791  last_time: 0.0745  data_time: 0.0029  last_data_time: 0.0027   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:55:59 d2.utils.events]:  eta: 0:00:06  iter: 5919  total_loss: 0.3719  loss_cls: 0.06943  loss_box_reg: 0.02495  loss_rpn_cls: 0.2098  loss_rpn_loc: 0.05043  validation_loss: 0.445    time: 0.0791  last_time: 0.0789  data_time: 0.0027  last_data_time: 0.0024   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:56:01 d2.utils.events]:  eta: 0:00:04  iter: 5939  total_loss: 0.3824  loss_cls: 0.07932  loss_box_reg: 0.03152  loss_rpn_cls: 0.2235  loss_rpn_loc: 0.06135  validation_loss: 0.445    time: 0.0791  last_time: 0.0787  data_time: 0.0031  last_data_time: 0.0042   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:56:02 d2.utils.events]:  eta: 0:00:03  iter: 5959  total_loss: 0.4798  loss_cls: 0.0818  loss_box_reg: 0.03519  loss_rpn_cls: 0.2133  loss_rpn_loc: 0.06277  validation_loss: 0.445    time: 0.0791  last_time: 0.0777  data_time: 0.0032  last_data_time: 0.0027   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:56:04 d2.utils.events]:  eta: 0:00:01  iter: 5979  total_loss: 0.4343  loss_cls: 0.08647  loss_box_reg: 0.03744  loss_rpn_cls: 0.2054  loss_rpn_loc: 0.05748  validation_loss: 0.445    time: 0.0791  last_time: 0.0848  data_time: 0.0027  last_data_time: 0.0028   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:57:07 d2.utils.events]:  eta: 0:00:00  iter: 5999  total_loss: 0.4535  loss_cls: 0.08135  loss_box_reg: 0.03712  loss_rpn_cls: 0.216  loss_rpn_loc: 0.06803  validation_loss: 0.4474    time: 0.0791  last_time: 0.0836  data_time: 0.0027  last_data_time: 0.0034   lr: 2.5e-08  max_mem: 2126M\n",
      "[03/22 13:57:07 d2.engine.hooks]: Overall training speed: 5998 iterations in 0:07:54 (0.0791 s / it)\n",
      "[03/22 13:57:07 d2.engine.hooks]: Total training time: 0:12:43 (0:04:49 on hooks)\n",
      "WARNING [03/22 13:57:07 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/22 13:57:07 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/22 13:57:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[03/22 13:57:07 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "[03/22 13:57:07 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/22 13:57:07 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "[03/22 13:57:07 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n",
      "WARNING [03/22 13:57:07 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[03/22 13:57:07 d2.evaluation.evaluator]: Start inference on 1801 batches\n",
      "[03/22 13:57:08 d2.evaluation.evaluator]: Inference done 11/1801. Dataloading: 0.0007 s/iter. Inference: 0.0261 s/iter. Eval: 0.0001 s/iter. Total: 0.0269 s/iter. ETA=0:00:48\n",
      "[03/22 13:57:13 d2.evaluation.evaluator]: Inference done 196/1801. Dataloading: 0.0009 s/iter. Inference: 0.0260 s/iter. Eval: 0.0002 s/iter. Total: 0.0271 s/iter. ETA=0:00:43\n",
      "[03/22 13:57:18 d2.evaluation.evaluator]: Inference done 384/1801. Dataloading: 0.0009 s/iter. Inference: 0.0258 s/iter. Eval: 0.0001 s/iter. Total: 0.0269 s/iter. ETA=0:00:38\n",
      "[03/22 13:57:23 d2.evaluation.evaluator]: Inference done 572/1801. Dataloading: 0.0009 s/iter. Inference: 0.0258 s/iter. Eval: 0.0001 s/iter. Total: 0.0268 s/iter. ETA=0:00:32\n",
      "[03/22 13:57:28 d2.evaluation.evaluator]: Inference done 759/1801. Dataloading: 0.0009 s/iter. Inference: 0.0258 s/iter. Eval: 0.0001 s/iter. Total: 0.0268 s/iter. ETA=0:00:27\n",
      "[03/22 13:57:33 d2.evaluation.evaluator]: Inference done 947/1801. Dataloading: 0.0009 s/iter. Inference: 0.0257 s/iter. Eval: 0.0001 s/iter. Total: 0.0268 s/iter. ETA=0:00:22\n",
      "[03/22 13:57:38 d2.evaluation.evaluator]: Inference done 1136/1801. Dataloading: 0.0009 s/iter. Inference: 0.0257 s/iter. Eval: 0.0001 s/iter. Total: 0.0267 s/iter. ETA=0:00:17\n",
      "[03/22 13:57:43 d2.evaluation.evaluator]: Inference done 1328/1801. Dataloading: 0.0009 s/iter. Inference: 0.0256 s/iter. Eval: 0.0001 s/iter. Total: 0.0267 s/iter. ETA=0:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/22 13:57:48 d2.evaluation.evaluator]: Inference done 1517/1801. Dataloading: 0.0009 s/iter. Inference: 0.0256 s/iter. Eval: 0.0001 s/iter. Total: 0.0266 s/iter. ETA=0:00:07\n",
      "[03/22 13:57:53 d2.evaluation.evaluator]: Inference done 1707/1801. Dataloading: 0.0009 s/iter. Inference: 0.0256 s/iter. Eval: 0.0001 s/iter. Total: 0.0266 s/iter. ETA=0:00:02\n",
      "[03/22 13:57:56 d2.evaluation.evaluator]: Total inference time: 0:00:47.827062 (0.026630 s / iter per device, on 1 devices)\n",
      "[03/22 13:57:56 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:45 (0.025544 s / iter per device, on 1 devices)\n",
      "[03/22 13:57:56 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[03/22 13:57:56 d2.evaluation.coco_evaluation]: Saving results to /workspace/output/output_res030_bs2_03.22.13.44/inference/coco_instances_results.json\n",
      "[03/22 13:57:56 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.32s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "[03/22 13:58:00 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.046 | 0.198  | 0.005  | 0.054 | 0.002 | 0.000 |\n",
      "[03/22 13:58:00 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
      "| category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|\n",
      "| DT         | 0.092 | TT         | 0.000 |\n",
      "[03/22 13:58:00 d2.engine.defaults]: Evaluation results for tower_val_03012 in csv format:\n",
      "[03/22 13:58:00 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[03/22 13:58:00 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[03/22 13:58:00 d2.evaluation.testing]: copypaste: 0.0462,0.1984,0.0049,0.0536,0.0021,0.0000\n",
      "[03/22 13:58:00 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /workspace/output/output_res030_bs2_03.22.13.44/model_final.pth ...\n",
      "[03/22 13:58:00 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n",
      "WARNING [03/22 13:58:00 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/22 13:58:00 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/22 13:58:00 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[03/22 13:58:00 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "[03/22 13:58:00 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/22 13:58:00 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "[03/22 13:58:00 d2.evaluation.evaluator]: Start inference on 1801 batches\n",
      "[03/22 13:58:01 d2.evaluation.evaluator]: Inference done 11/1801. Dataloading: 0.0007 s/iter. Inference: 0.0273 s/iter. Eval: 0.0000 s/iter. Total: 0.0281 s/iter. ETA=0:00:50\n",
      "[03/22 13:58:06 d2.evaluation.evaluator]: Inference done 200/1801. Dataloading: 0.0008 s/iter. Inference: 0.0256 s/iter. Eval: 0.0000 s/iter. Total: 0.0265 s/iter. ETA=0:00:42\n",
      "[03/22 13:58:11 d2.evaluation.evaluator]: Inference done 395/1801. Dataloading: 0.0008 s/iter. Inference: 0.0252 s/iter. Eval: 0.0000 s/iter. Total: 0.0261 s/iter. ETA=0:00:36\n",
      "[03/22 13:58:16 d2.evaluation.evaluator]: Inference done 589/1801. Dataloading: 0.0008 s/iter. Inference: 0.0251 s/iter. Eval: 0.0000 s/iter. Total: 0.0260 s/iter. ETA=0:00:31\n",
      "[03/22 13:58:21 d2.evaluation.evaluator]: Inference done 785/1801. Dataloading: 0.0008 s/iter. Inference: 0.0250 s/iter. Eval: 0.0000 s/iter. Total: 0.0259 s/iter. ETA=0:00:26\n",
      "[03/22 13:58:26 d2.evaluation.evaluator]: Inference done 980/1801. Dataloading: 0.0008 s/iter. Inference: 0.0249 s/iter. Eval: 0.0000 s/iter. Total: 0.0259 s/iter. ETA=0:00:21\n",
      "[03/22 13:58:31 d2.evaluation.evaluator]: Inference done 1174/1801. Dataloading: 0.0009 s/iter. Inference: 0.0249 s/iter. Eval: 0.0000 s/iter. Total: 0.0259 s/iter. ETA=0:00:16\n",
      "[03/22 13:58:36 d2.evaluation.evaluator]: Inference done 1371/1801. Dataloading: 0.0009 s/iter. Inference: 0.0249 s/iter. Eval: 0.0000 s/iter. Total: 0.0258 s/iter. ETA=0:00:11\n",
      "[03/22 13:58:41 d2.evaluation.evaluator]: Inference done 1568/1801. Dataloading: 0.0008 s/iter. Inference: 0.0248 s/iter. Eval: 0.0000 s/iter. Total: 0.0258 s/iter. ETA=0:00:06\n",
      "[03/22 13:58:46 d2.evaluation.evaluator]: Inference done 1765/1801. Dataloading: 0.0008 s/iter. Inference: 0.0248 s/iter. Eval: 0.0000 s/iter. Total: 0.0257 s/iter. ETA=0:00:00\n",
      "[03/22 13:58:47 d2.evaluation.evaluator]: Total inference time: 0:00:46.248777 (0.025751 s / iter per device, on 1 devices)\n",
      "[03/22 13:58:47 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:44 (0.024792 s / iter per device, on 1 devices)\n",
      "[03/22 13:58:47 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[03/22 13:58:47 d2.evaluation.coco_evaluation]: Saving results to /workspace/output/output030/coco_instances_results.json\n",
      "[03/22 13:58:47 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 30 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 30 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 30 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets= 30 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 30 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 30 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 30 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets= 30 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 30 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 30 ] = 0.000\n",
      "[03/22 13:58:47 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "[03/22 13:58:47 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
      "| category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|\n",
      "| DT         | 0.000 | TT         | 0.000 |\n"
     ]
    }
   ],
   "source": [
    "resolution_set = ['030']#, '035','040','045','050','070','100']\n",
    "batch_size = [2]\n",
    "\n",
    "eval_objs = []\n",
    "for bs in batch_size:\n",
    "\n",
    "    res = '030'\n",
    "    #define the names \n",
    "    dataset_name_train = \"tower_train_\" + str(res) + \"1\"\n",
    "    dataset_name_val = \"tower_val_\" + str(res) + \"1\"\n",
    "\n",
    "    try: \n",
    "        # if it throws an error that name is already registered, just change the name... \n",
    "        register_coco_instances(dataset_name_train, {}, base_path+\"labels_train.json\", base_path+\"data_\"+str(res)+\"/train/data\")\n",
    "        register_coco_instances(dataset_name_val, {}, base_path+\"labels_val.json\", base_path+\"data_\"+str(res)+\"/val/data\")\n",
    "\n",
    "        #MetadataCatalog.get(dataset_name_train).set(thing_classes=[\"distribution\", \"transmission\"])\n",
    "        #MetadataCatalog.get(dataset_name_val).set(thing_classes=[\"distribution\", \"transmission\"])\n",
    "    \n",
    "    except: \n",
    "        regis_num += 1\n",
    "        dataset_name_train += str(regis_num)\n",
    "        dataset_name_val += str(regis_num)\n",
    "\n",
    "        # if it throws an error that name is already registered, just change the name... \n",
    "        register_coco_instances(dataset_name_train, {}, base_path+\"labels_train.json\", base_path+\"data_\"+str(res)+\"/train/data\")\n",
    "        register_coco_instances(dataset_name_val, {}, base_path+\"labels_val.json\", base_path+\"data_\"+str(res)+\"/val/data\")\n",
    "        #MetadataCatalog.get(dataset_name_train).set(thing_classes=[\"distribution\", \"transmission\"])\n",
    "        #MetadataCatalog.get(dataset_name_val).set(thing_classes=[\"distribution\", \"transmission\"])\n",
    "\n",
    "    configuration, train_obj, predictor_obj = train_detectron_standard(dataset_name_train, dataset_name_val, res, batch_size = bs)\n",
    "\n",
    "    eval_objs.append(evaluate_detectron(configuration, predictor_obj, res, dataset_name_val))\n",
    "\n",
    "with open('../eval.txt', 'w') as f:\n",
    "    f.write(str(eval_objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning message at the beginning of training \"Skip loading parameter ....\" can be ignored, \n",
    "#it is due to the fact that pretrained model had a different number of categories than our dataset\n",
    "#https://github.com/facebookresearch/detectron2/issues/196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_detectron(configuration, predictor_obj, res, dataset_name_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from plyer import notification\n",
    "notification.notify(\n",
    "    title = \"DETECTRON2\",\n",
    "    message = \"YOU'R MODEL FINISHED TRAINING. LOOK AT THE OUTPUT NOW\",\n",
    "    timeout = 15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/scripts'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/output/output_res030_bs2_03.22.13.44\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "list_of_files = glob.glob('/workspace/output/*') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_file = '/workspace/ue_setup/outputs_small_thesis_trainsmall_thesis_val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taken from https://eidos-ai.medium.com/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e\n",
    "# https://gist.github.com/ortegatron/c0dad15e49c2b74de8bb09a5615d9f6b\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "resolution = \"030\"\n",
    "\n",
    "for b in [5]:\n",
    "    \n",
    "    experiment_folder = latest_file\n",
    "    def load_json_arr(json_path):\n",
    "        lines = []\n",
    "        with open(json_path, 'r') as f:\n",
    "            for line in f:\n",
    "                lines.append(json.loads(line))\n",
    "        return lines\n",
    "\n",
    "    experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
    "\n",
    "    plt.plot(\n",
    "        [x['iteration'] for x in experiment_metrics if 'loss_box_reg' in x], \n",
    "        [x['loss_box_reg'] for x in experiment_metrics if 'loss_box_reg' in x])\n",
    "    plt.plot(\n",
    "        [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \n",
    "        [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x])\n",
    "    plt.plot(\n",
    "        [x['iteration'] for x in experiment_metrics if 'loss_cls' in x], \n",
    "        [x['loss_cls'] for x in experiment_metrics if 'loss_cls' in x])\n",
    "    plt.plot(\n",
    "        [x['iteration'] for x in experiment_metrics if 'total_loss' in x], \n",
    "        [x['total_loss'] for x in experiment_metrics if 'total_loss' in x])\n",
    "    plt.legend(['loss_box_reg', 'validation_loss', 'loss_cls', 'total_loss'], loc='upper left')\n",
    "\n",
    "    \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise how the boxes look at the best model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "APs = [list(i.items())[0][1][\"AP\"] for i in eval_objs]\n",
    "RES = [int(r) for r in resolution_set]\n",
    "\n",
    "plt.scatter(RES, APs)\n",
    "plt.plot(RES, APs)\n",
    "plt.grid()\n",
    "plt.title(\"Average Precision (AP) scores against Image Resolution in cm\")\n",
    "plt.xlabel(\"Image Resolution in cm/pixel\")\n",
    "plt.ylabel(\"Average Precision (0-100)\")\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('../figures/mastergraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-7MAVA5BeEA"
   },
   "source": [
    "## Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check whether detectron loads dataset correctly\n",
    "## TODO JOHANNES: KANNST DU BITTE MAL CHECKEN, OB DER UNSER DATASET CATALOG RICHTIG LÄD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dataset_function():\n",
    "  ...\n",
    "  return list[dict] in the following format\n",
    "\n",
    "from detectron2.data import DatasetCatalog\n",
    "DatasetCatalog.register(\"my_dataset\", my_dataset_function)\n",
    "# later, to access the data:\n",
    "data: List[Dict] = DatasetCatalog.get(\"my_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sample(dataset_name, n=1):\n",
    "    dataset_custom = DatasetCatalog.get(dataset_name)\n",
    "    dataset_custom_metadata = MetadataCatalog.get(dataset_name)\n",
    "    \n",
    "    for s in random.sample(dataset_custom, n):\n",
    "        img = cv2.imread(s[\"file_name\"])\n",
    "        v = Visualizer(img[:, :, ::-1], metadata=dataset_custom_metadata, scale=0.5)\n",
    "        v = v.draw_dataset_dict(s)\n",
    "        plt.figure(figsize=(15,20))\n",
    "        plt.imshow(v.get_image())\n",
    "        plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "executionInfo": {
     "elapsed": 2294,
     "status": "ok",
     "timestamp": 1675598581911,
     "user": {
      "displayName": "Johannes Halkenhäußer",
      "userId": "10212423884318197669"
     },
     "user_tz": -60
    },
    "id": "LvjGgcmttyok",
    "outputId": "1494f733-b837-4276-9820-f7b50402574d"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "val_or_train = \"train\" # write a string here (either \"val\" or \"train\")\n",
    "location = \"\"\n",
    "dataset_dicts = json.load(open(f'{base_path}/labels_{val_or_train}.json'))\n",
    "\n",
    "for d in random.sample(dataset_dicts['images'], 3):  \n",
    "    im = cv2.imread(f'{base_path}/data_030/{val_or_train}/data/{d[\"file_name\"]}')\n",
    "\n",
    "    outputs = predictor_obj(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata= MetadataCatalog.get(\"tower_val1\"), \n",
    "                   scale=0.5 \n",
    "                   #,instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1675598420454,
     "user": {
      "displayName": "Johannes Halkenhäußer",
      "userId": "10212423884318197669"
     },
     "user_tz": -60
    },
    "id": "l8b2tdrNCdNd",
    "outputId": "84cb3de8-417b-44e4-b446-4b4f8f1433dc"
   },
   "outputs": [],
   "source": [
    "eval_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4adq9_Bctfj"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(eval_obs[])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPBfVVlldJ7aWYNaGGPTTGN",
   "mount_file_id": "1C9LTrJRVpxxodMuaNcbt8uuqvk4obW12",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
