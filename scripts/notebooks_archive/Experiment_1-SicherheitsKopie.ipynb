{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "R19i2qhe5m6l"
   },
   "outputs": [],
   "source": [
    "# we set a counter to register the same dataset again under a different name when we are debugging\n",
    "global regis_num \n",
    "regis_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BG_KCRSk5m6n",
    "outputId": "2ba489e6-f6c9-4231-9ea3-65d9e01bc6e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.8/dist-packages (5.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Found existing installation: detectron2 0.6+cu111\n",
      "Uninstalling detectron2-0.6+cu111:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.8/dist-packages/detectron2-0.6+cu111.dist-info/*\n",
      "    /usr/local/lib/python3.8/dist-packages/detectron2/*\n",
      "    /usr/local/lib/python3.8/dist-packages/tools/*\n",
      "Proceed (y/n)?   Successfully uninstalled detectron2-0.6+cu111\n",
      "yes: standard output: Broken pipe\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /usr/local/lib/python3.8/dist-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /usr/local/lib/python3.8/dist-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0+cu111) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (1.23.4)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (9.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html\n",
      "Collecting detectron2\n",
      "  Using cached https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/detectron2-0.6%2Bcu111-cp38-cp38-linux_x86_64.whl (6.9 MB)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.8/dist-packages (from detectron2) (0.1.8)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from detectron2) (2.0.6)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from detectron2) (0.1.5.post20221221)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.8/dist-packages (from detectron2) (4.65.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from detectron2) (1.15.0)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from detectron2) (0.1.9)\n",
      "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.8/dist-packages (from detectron2) (2.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from detectron2) (3.6.2)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from detectron2) (2.1.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from detectron2) (0.9.0)\n",
      "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.8/dist-packages (from detectron2) (9.3.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from detectron2) (0.18.3)\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.8/dist-packages (from detectron2) (1.4.2)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from detectron2) (2.2.1)\n",
      "Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.8/dist-packages (from detectron2) (21.4b2)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.8/dist-packages (from detectron2) (1.3.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs>=0.1.8->detectron2) (5.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pycocotools>=2.0.2->detectron2) (1.23.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2) (3.4.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorboard->detectron2) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2) (1.3.0)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2) (1.50.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorboard->detectron2) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2) (3.19.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2) (59.5.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2) (2.2.2)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2) (2.7.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.8/dist-packages (from omegaconf>=2.1->detectron2) (4.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2) (4.38.0)\n",
      "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.8/dist-packages (from black==21.4b2->detectron2) (2022.10.31)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from black==21.4b2->detectron2) (1.0.0)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.8/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
      "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from black==21.4b2->detectron2) (8.1.3)\n",
      "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n",
      "Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from black==21.4b2->detectron2) (0.11.1)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.1->detectron2) (5.10.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=0.11.15->tensorboard->detectron2) (2.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core>=1.1->detectron2) (3.10.0)\n",
      "Installing collected packages: detectron2\n",
      "Successfully installed detectron2-0.6+cu111\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml==5.1\n",
    "#!pip uninstall torch\n",
    "!yes | pip uninstall detectron2\n",
    "#!pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    \n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueMgUQW15m6o",
    "outputId": "6bd56297-f308-4ef0-83f8-0b78557a20d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Sun_Feb_14_21:12:58_PST_2021\n",
      "Cuda compilation tools, release 11.2, V11.2.152\n",
      "Build cuda_11.2.r11.2/compiler.29618528_0\n",
      "torch:  1.9 ; cuda:  cu111\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datetime\n",
      "  Downloading DateTime-5.1-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.6 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from datetime) (2023.3)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
      "\u001b[K     |████████████████████████████████| 249 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from zope.interface->datetime) (59.5.0)\n",
      "Installing collected packages: zope.interface, datetime\n",
      "Successfully installed datetime-5.1 zope.interface-6.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8j7rmkU25m6p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "AcLpVhlazWfn"
   },
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import build_detection_train_loader\n",
    "from detectron2.data import DatasetMapper\n",
    "from detectron2.data import DatasetCatalog\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "y3ZJEwI6zWXz"
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Message while training: module 'distutils' has no attribute 'version'\n",
    "#!python3 -m pip install setuptools==58.2.0\n",
    "# then restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to register our datasets \n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "dataset_name_train = \"small_thesis_train\"\n",
    "dataset_name_val = \"small_thesis_val\"\n",
    "\n",
    "def register(name, path_labels, path_data):\n",
    "\n",
    "    # Check if dataset name already exists in catalog\n",
    "    if name in DatasetCatalog.list():\n",
    "        # Remove existing dataset from catalog\n",
    "        DatasetCatalog.remove(name)\n",
    "        MetadataCatalog.remove(name)\n",
    "\n",
    "    # Register your dataset using register_coco_instances\n",
    "    register_coco_instances(name, {}, path_labels, path_data)\n",
    "\n",
    "# if it throws an error that name is already registered, just change the name... \n",
    "register(dataset_name_train, \"/workspace/data/labels_train.json\", \"/workspace/data/data_030/train/data\")\n",
    "register(dataset_name_val, \"/workspace/data/labels_val.json\", \"/workspace/data/data_030/val/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "83lEnr370GG_"
   },
   "outputs": [],
   "source": [
    "# register datasets\n",
    "\n",
    "dataset_name_train = \"thesis_030_train\"\n",
    "dataset_name_val = \"thesis_030_val\"\n",
    "\n",
    "register_coco_instances(dataset_name_train,{}, \"/workspace/data/labels_train.json\", \"/workspace/data/data_030/train/data\")\n",
    "register_coco_instances(dataset_name_val,{}, \"/workspace/data/labels_val.json\", \"/workspace/data/data_030/val/data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "PInSAHfom6lT"
   },
   "outputs": [],
   "source": [
    "base_path = \"/workspace/scripts\"\n",
    "\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "SE6J25QHkooF"
   },
   "outputs": [],
   "source": [
    "# Taken from https://eidos-ai.medium.com/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e\n",
    "# https://gist.github.com/ortegatron/c0dad15e49c2b74de8bb09a5615d9f6b\n",
    "\n",
    "from EvalLossHook import LossEvalHook\n",
    "\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "                     \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1,LossEvalHook(\n",
    "            self.cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg,True)\n",
    "            )\n",
    "        ))\n",
    "        return hooks\n",
    "\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lukas Univ Edingbourgh Trainer Version \n",
    "\n",
    "class OurTrainer(DefaultTrainer):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__(cfg)\n",
    "\n",
    "        if isinstance(cfg.DATASETS.EVAL, str):\n",
    "            self.eval_datasets = [cfg.DATASETS.EVAL]\n",
    "        else:\n",
    "            self.eval_datasets = cfg.DATASETS.EVAL\n",
    "\n",
    "        # prepare evaluation\n",
    "        self.eval_loaders = []\n",
    "        self.evaluators = []\n",
    "        for dataset in self.eval_datasets:\n",
    "\n",
    "            loader = build_detection_test_loader(DatasetCatalog.get(dataset), \n",
    "                                                 mapper=DatasetMapper(cfg, is_train=False))\n",
    "\n",
    "            self.eval_loaders.append(loader)\n",
    "            self.evaluators.append(COCOEvaluator(\n",
    "                dataset,\n",
    "                output_dir=cfg.OUTPUT_DIR \n",
    "                ))\n",
    "    \n",
    "    def build_train_loader(cls, cfg):\n",
    "        if cfg.SOLVER.STRONG_AUGMENT:\n",
    "            print(\"STRONG AUGMENTATIONS TO TRAINING SET\")\n",
    "            return build_detection_train_loader(cfg, mapper=DatasetMapperAugment(cfg, is_train=True)) \n",
    "        else:\n",
    "            return build_detection_train_loader(cfg)\n",
    "\n",
    "    \n",
    "    def after_step(self):\n",
    "        super().after_step()\n",
    "\n",
    "        if (self.iter+1) % self.cfg.TEST.INTERVAL == 0:                                   \n",
    "    \n",
    "            for dataset, loader, evaluator in zip(self.eval_datasets, \n",
    "                                                    self.eval_loaders,\n",
    "                                                    self.evaluators):\n",
    "    \n",
    "                results = inference_on_dataset(self.model,\n",
    "                                                loader,\n",
    "                                                evaluator)\n",
    "                with open(\n",
    "                    os.path.join(\n",
    "                        self.cfg.OUTPUT_DIR,\n",
    "                        'eval_'+dataset+'_iter_'+str(self.iter)+'.json'),\n",
    "                        'w') as out:\n",
    "                    json.dump(results, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BmkngU_Q0GEQ"
   },
   "outputs": [],
   "source": [
    "# set up the model for training\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now() \n",
    "\n",
    "output_dir = f\"/workspace/output/output_new_res030_{now.strftime('%m.%d.%H.%M')}\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.OUTPUT_DIR = output_dir\n",
    "\n",
    "cfg.DATASETS.TRAIN = (dataset_name_train)\n",
    "cfg.DATASETS.TEST = (dataset_name_val,)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[4, 8, 16, 32, 64]]\n",
    "cfg.SOLVER.MAX_ITER = 500\n",
    "cfg.TEST.EVAL_PERIOD = 200 # für unseren Evaluator\n",
    "#cfg.TEST.INTERVAL = 400 # für Lukas Evaluator\n",
    "#cfg.SOLVER.STEPS = (2000, 2500)\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jLjIMcU0GBr",
    "outputId": "703cf390-8601-4546-e7b7-1d5cd1fbe006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIND EXPERIMENT RESULTS AT \n",
      " /workspace/output/output_new_res030_03.30.13.51\n"
     ]
    }
   ],
   "source": [
    "print(f\"FIND EXPERIMENT RESULTS AT \\n {cfg.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "8dtz-Cav0F_q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30 13:52:06 d2.engine.defaults]: Model:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING [03/30 13:52:06 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/30 13:52:06 d2.data.datasets.coco]: Loaded 11696 images in COCO format from /workspace/data/labels_train.json\n",
      "[03/30 13:52:06 d2.data.build]: Removed 0 images with no usable annotations. 11696 images left.\n",
      "[03/30 13:52:07 d2.data.build]: Distribution of instances among all 3 categories:\n",
      "|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|     DT     | 53154        |     OT     | 103          |     TT     | 1905         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 55162        |            |              |            |              |\n",
      "[03/30 13:52:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "[03/30 13:52:07 d2.data.build]: Using training sampler TrainingSampler\n",
      "[03/30 13:52:07 d2.data.common]: Serializing 11696 elements to byte tensors and concatenating them all ...\n",
      "[03/30 13:52:07 d2.data.common]: Serialized dataset takes 5.84 MiB\n",
      "WARNING [03/30 13:52:07 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "[03/30 13:52:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "WARNING [03/30 13:52:08 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/30 13:52:08 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/30 13:52:08 d2.data.build]: Distribution of instances among all 2 categories:\n",
      "|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|     DT     | 8429         |     TT     | 460          |\n",
      "|            |              |            |              |\n",
      "|   total    | 8889         |            |              |\n",
      "[03/30 13:52:08 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/30 13:52:08 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "[03/30 13:52:08 d2.checkpoint.c2_model_loading]: Renaming Caffe2 weights ......\n",
      "[03/30 13:52:09 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up:\n",
      "| Names in Model    | Names in Checkpoint      | Shapes                                          |\n",
      "|:------------------|:-------------------------|:------------------------------------------------|\n",
      "| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |\n",
      "| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "backbone.fpn_lateral2.{bias, weight}\n",
      "backbone.fpn_lateral3.{bias, weight}\n",
      "backbone.fpn_lateral4.{bias, weight}\n",
      "backbone.fpn_lateral5.{bias, weight}\n",
      "backbone.fpn_output2.{bias, weight}\n",
      "backbone.fpn_output3.{bias, weight}\n",
      "backbone.fpn_output4.{bias, weight}\n",
      "backbone.fpn_output5.{bias, weight}\n",
      "proposal_generator.rpn_head.anchor_deltas.{bias, weight}\n",
      "proposal_generator.rpn_head.conv.{bias, weight}\n",
      "proposal_generator.rpn_head.objectness_logits.{bias, weight}\n",
      "roi_heads.box_head.fc1.{bias, weight}\n",
      "roi_heads.box_head.fc2.{bias, weight}\n",
      "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
      "roi_heads.box_predictor.cls_score.{bias, weight}\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  fc1000.{bias, weight}\n",
      "  stem.conv1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30 13:52:09 d2.engine.train_loop]: Starting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30 13:52:17 d2.utils.events]:  eta: 0:02:53  iter: 19  total_loss: 1.024  loss_cls: 0.1302  loss_box_reg: 0.001226  loss_rpn_cls: 0.7036  loss_rpn_loc: 0.1259  time: 0.3587  data_time: 0.0683  lr: 0.00077924  max_mem: 5394M\n",
      "[03/30 13:52:24 d2.utils.events]:  eta: 0:02:46  iter: 39  total_loss: 0.8309  loss_cls: 0.141  loss_box_reg: 0.002363  loss_rpn_cls: 0.6006  loss_rpn_loc: 0.07201  time: 0.3608  data_time: 0.0604  lr: 0.0015784  max_mem: 5394M\n",
      "[03/30 13:52:31 d2.utils.events]:  eta: 0:02:39  iter: 59  total_loss: 0.4876  loss_cls: 0.05479  loss_box_reg: 0.001844  loss_rpn_cls: 0.3457  loss_rpn_loc: 0.06985  time: 0.3582  data_time: 0.0591  lr: 0.0023776  max_mem: 5394M\n",
      "[03/30 13:52:38 d2.utils.events]:  eta: 0:02:32  iter: 79  total_loss: 0.4271  loss_cls: 0.05595  loss_box_reg: 0.01025  loss_rpn_cls: 0.2663  loss_rpn_loc: 0.06889  time: 0.3571  data_time: 0.0630  lr: 0.0031768  max_mem: 5394M\n",
      "[03/30 13:52:45 d2.utils.events]:  eta: 0:02:25  iter: 99  total_loss: 0.3972  loss_cls: 0.05886  loss_box_reg: 0.01649  loss_rpn_cls: 0.2024  loss_rpn_loc: 0.07157  time: 0.3588  data_time: 0.0614  lr: 0.003976  max_mem: 5394M\n",
      "[03/30 13:52:52 d2.utils.events]:  eta: 0:02:17  iter: 119  total_loss: 0.4929  loss_cls: 0.1408  loss_box_reg: 0.1102  loss_rpn_cls: 0.202  loss_rpn_loc: 0.07879  time: 0.3588  data_time: 0.0611  lr: 0.0047752  max_mem: 5394M\n",
      "[03/30 13:53:00 d2.utils.events]:  eta: 0:02:10  iter: 139  total_loss: 0.476  loss_cls: 0.1072  loss_box_reg: 0.07694  loss_rpn_cls: 0.1844  loss_rpn_loc: 0.07358  time: 0.3588  data_time: 0.0629  lr: 0.0055744  max_mem: 5394M\n",
      "[03/30 13:53:07 d2.utils.events]:  eta: 0:02:03  iter: 159  total_loss: 0.5883  loss_cls: 0.1574  loss_box_reg: 0.1576  loss_rpn_cls: 0.1481  loss_rpn_loc: 0.08212  time: 0.3579  data_time: 0.0596  lr: 0.0063736  max_mem: 5394M\n",
      "[03/30 13:53:14 d2.utils.events]:  eta: 0:01:55  iter: 179  total_loss: 0.649  loss_cls: 0.1685  loss_box_reg: 0.217  loss_rpn_cls: 0.1507  loss_rpn_loc: 0.07995  time: 0.3575  data_time: 0.0625  lr: 0.0071728  max_mem: 5394M\n",
      "WARNING [03/30 13:53:21 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/30 13:53:21 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/30 13:53:21 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[03/30 13:53:21 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/30 13:53:21 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "WARNING [03/30 13:53:21 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[03/30 13:53:21 d2.evaluation.evaluator]: Start inference on 1801 batches\n",
      "[03/30 13:53:22 d2.evaluation.evaluator]: Inference done 11/1801. Dataloading: 0.0007 s/iter. Inference: 0.0281 s/iter. Eval: 0.0002 s/iter. Total: 0.0290 s/iter. ETA=0:00:51\n",
      "[03/30 13:53:27 d2.evaluation.evaluator]: Inference done 181/1801. Dataloading: 0.0008 s/iter. Inference: 0.0285 s/iter. Eval: 0.0002 s/iter. Total: 0.0296 s/iter. ETA=0:00:47\n",
      "[03/30 13:53:32 d2.evaluation.evaluator]: Inference done 351/1801. Dataloading: 0.0008 s/iter. Inference: 0.0285 s/iter. Eval: 0.0002 s/iter. Total: 0.0295 s/iter. ETA=0:00:42\n",
      "[03/30 13:53:37 d2.evaluation.evaluator]: Inference done 515/1801. Dataloading: 0.0008 s/iter. Inference: 0.0288 s/iter. Eval: 0.0002 s/iter. Total: 0.0299 s/iter. ETA=0:00:38\n",
      "[03/30 13:53:42 d2.evaluation.evaluator]: Inference done 685/1801. Dataloading: 0.0008 s/iter. Inference: 0.0287 s/iter. Eval: 0.0002 s/iter. Total: 0.0298 s/iter. ETA=0:00:33\n",
      "[03/30 13:53:47 d2.evaluation.evaluator]: Inference done 856/1801. Dataloading: 0.0009 s/iter. Inference: 0.0286 s/iter. Eval: 0.0002 s/iter. Total: 0.0297 s/iter. ETA=0:00:28\n",
      "[03/30 13:53:52 d2.evaluation.evaluator]: Inference done 1027/1801. Dataloading: 0.0009 s/iter. Inference: 0.0286 s/iter. Eval: 0.0002 s/iter. Total: 0.0296 s/iter. ETA=0:00:22\n",
      "[03/30 13:53:57 d2.evaluation.evaluator]: Inference done 1199/1801. Dataloading: 0.0009 s/iter. Inference: 0.0285 s/iter. Eval: 0.0002 s/iter. Total: 0.0296 s/iter. ETA=0:00:17\n",
      "[03/30 13:54:02 d2.evaluation.evaluator]: Inference done 1369/1801. Dataloading: 0.0009 s/iter. Inference: 0.0285 s/iter. Eval: 0.0002 s/iter. Total: 0.0296 s/iter. ETA=0:00:12\n",
      "[03/30 13:54:07 d2.evaluation.evaluator]: Inference done 1534/1801. Dataloading: 0.0009 s/iter. Inference: 0.0285 s/iter. Eval: 0.0003 s/iter. Total: 0.0297 s/iter. ETA=0:00:07\n",
      "[03/30 13:54:12 d2.evaluation.evaluator]: Inference done 1703/1801. Dataloading: 0.0009 s/iter. Inference: 0.0285 s/iter. Eval: 0.0003 s/iter. Total: 0.0297 s/iter. ETA=0:00:02\n",
      "[03/30 13:54:15 d2.evaluation.evaluator]: Total inference time: 0:00:53.331624 (0.029695 s / iter per device, on 1 devices)\n",
      "[03/30 13:54:15 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:51 (0.028472 s / iter per device, on 1 devices)\n",
      "[03/30 13:54:15 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[03/30 13:54:15 d2.evaluation.coco_evaluation]: Saving results to /workspace/output/output_new_res030_03.30.13.51/inference/coco_instances_results.json\n",
      "[03/30 13:54:16 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "[03/30 13:54:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[03/30 13:54:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.55 seconds.\n",
      "[03/30 13:54:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[03/30 13:54:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.15 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.037\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "[03/30 13:54:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.332 | 5.049  | 0.570  | 1.365 | 0.008 | 0.000 |\n",
      "[03/30 13:54:17 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
      "| category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|\n",
      "| DT         | 2.664 | TT         | 0.000 |\n",
      "[03/30 13:54:17 d2.engine.defaults]: Evaluation results for thesis_030_val in csv format:\n",
      "[03/30 13:54:17 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[03/30 13:54:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[03/30 13:54:17 d2.evaluation.testing]: copypaste: 1.3321,5.0491,0.5700,1.3653,0.0081,0.0000\n",
      "[03/30 13:55:22 d2.utils.events]:  eta: 0:01:48  iter: 199  total_loss: 0.6439  loss_cls: 0.1509  loss_box_reg: 0.1289  loss_rpn_cls: 0.2058  loss_rpn_loc: 0.1066  validation_loss: 0.5844  time: 0.3582  data_time: 0.0650  lr: 0.007972  max_mem: 5394M\n",
      "[03/30 13:55:29 d2.utils.events]:  eta: 0:01:41  iter: 219  total_loss: 0.5934  loss_cls: 0.1596  loss_box_reg: 0.1652  loss_rpn_cls: 0.145  loss_rpn_loc: 0.06666  validation_loss: 0.5844  time: 0.3580  data_time: 0.0646  lr: 0.0087712  max_mem: 5394M\n",
      "[03/30 13:55:36 d2.utils.events]:  eta: 0:01:34  iter: 239  total_loss: 0.6234  loss_cls: 0.1888  loss_box_reg: 0.1928  loss_rpn_cls: 0.1572  loss_rpn_loc: 0.06612  validation_loss: 0.5844  time: 0.3582  data_time: 0.0600  lr: 0.0095704  max_mem: 5394M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30 13:55:43 d2.utils.events]:  eta: 0:01:27  iter: 259  total_loss: 0.6472  loss_cls: 0.1941  loss_box_reg: 0.2289  loss_rpn_cls: 0.1304  loss_rpn_loc: 0.08655  validation_loss: 0.5844  time: 0.3572  data_time: 0.0594  lr: 0.01037  max_mem: 5394M\n",
      "[03/30 13:55:50 d2.utils.events]:  eta: 0:01:19  iter: 279  total_loss: 0.6474  loss_cls: 0.2088  loss_box_reg: 0.2469  loss_rpn_cls: 0.1304  loss_rpn_loc: 0.05432  validation_loss: 0.5844  time: 0.3576  data_time: 0.0626  lr: 0.011169  max_mem: 5394M\n",
      "[03/30 13:55:57 d2.utils.events]:  eta: 0:01:12  iter: 299  total_loss: 0.6944  loss_cls: 0.2048  loss_box_reg: 0.2144  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.0927  validation_loss: 0.5844  time: 0.3580  data_time: 0.0621  lr: 0.011968  max_mem: 5394M\n",
      "[03/30 13:56:05 d2.utils.events]:  eta: 0:01:05  iter: 319  total_loss: 0.7218  loss_cls: 0.2196  loss_box_reg: 0.2439  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.06089  validation_loss: 0.5844  time: 0.3583  data_time: 0.0638  lr: 0.012767  max_mem: 5394M\n",
      "[03/30 13:56:12 d2.utils.events]:  eta: 0:00:58  iter: 339  total_loss: 0.654  loss_cls: 0.1856  loss_box_reg: 0.2293  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.1063  validation_loss: 0.5844  time: 0.3588  data_time: 0.0643  lr: 0.013566  max_mem: 5394M\n",
      "[03/30 13:56:19 d2.utils.events]:  eta: 0:00:50  iter: 359  total_loss: 0.6787  loss_cls: 0.2195  loss_box_reg: 0.2908  loss_rpn_cls: 0.07727  loss_rpn_loc: 0.07502  validation_loss: 0.5844  time: 0.3592  data_time: 0.0637  lr: 0.014366  max_mem: 5394M\n",
      "[03/30 13:56:27 d2.utils.events]:  eta: 0:00:43  iter: 379  total_loss: 0.6964  loss_cls: 0.1858  loss_box_reg: 0.2213  loss_rpn_cls: 0.1293  loss_rpn_loc: 0.1024  validation_loss: 0.5844  time: 0.3593  data_time: 0.0615  lr: 0.015165  max_mem: 5394M\n",
      "WARNING [03/30 13:56:34 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/30 13:56:34 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/30 13:56:34 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[03/30 13:56:34 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/30 13:56:34 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "WARNING [03/30 13:56:34 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[03/30 13:56:34 d2.evaluation.evaluator]: Start inference on 1801 batches\n",
      "[03/30 13:56:34 d2.evaluation.evaluator]: Inference done 11/1801. Dataloading: 0.0008 s/iter. Inference: 0.0285 s/iter. Eval: 0.0001 s/iter. Total: 0.0294 s/iter. ETA=0:00:52\n",
      "[03/30 13:56:40 d2.evaluation.evaluator]: Inference done 182/1801. Dataloading: 0.0009 s/iter. Inference: 0.0283 s/iter. Eval: 0.0002 s/iter. Total: 0.0294 s/iter. ETA=0:00:47\n",
      "[03/30 13:56:45 d2.evaluation.evaluator]: Inference done 342/1801. Dataloading: 0.0008 s/iter. Inference: 0.0293 s/iter. Eval: 0.0002 s/iter. Total: 0.0303 s/iter. ETA=0:00:44\n",
      "[03/30 13:56:50 d2.evaluation.evaluator]: Inference done 512/1801. Dataloading: 0.0008 s/iter. Inference: 0.0290 s/iter. Eval: 0.0002 s/iter. Total: 0.0300 s/iter. ETA=0:00:38\n",
      "[03/30 13:56:55 d2.evaluation.evaluator]: Inference done 682/1801. Dataloading: 0.0009 s/iter. Inference: 0.0288 s/iter. Eval: 0.0002 s/iter. Total: 0.0299 s/iter. ETA=0:00:33\n",
      "[03/30 13:57:00 d2.evaluation.evaluator]: Inference done 852/1801. Dataloading: 0.0009 s/iter. Inference: 0.0287 s/iter. Eval: 0.0002 s/iter. Total: 0.0298 s/iter. ETA=0:00:28\n",
      "[03/30 13:57:05 d2.evaluation.evaluator]: Inference done 1019/1801. Dataloading: 0.0009 s/iter. Inference: 0.0288 s/iter. Eval: 0.0002 s/iter. Total: 0.0298 s/iter. ETA=0:00:23\n",
      "[03/30 13:57:10 d2.evaluation.evaluator]: Inference done 1189/1801. Dataloading: 0.0009 s/iter. Inference: 0.0287 s/iter. Eval: 0.0002 s/iter. Total: 0.0298 s/iter. ETA=0:00:18\n",
      "[03/30 13:57:15 d2.evaluation.evaluator]: Inference done 1361/1801. Dataloading: 0.0009 s/iter. Inference: 0.0286 s/iter. Eval: 0.0002 s/iter. Total: 0.0297 s/iter. ETA=0:00:13\n",
      "[03/30 13:57:20 d2.evaluation.evaluator]: Inference done 1529/1801. Dataloading: 0.0009 s/iter. Inference: 0.0286 s/iter. Eval: 0.0003 s/iter. Total: 0.0297 s/iter. ETA=0:00:08\n",
      "[03/30 13:57:25 d2.evaluation.evaluator]: Inference done 1703/1801. Dataloading: 0.0008 s/iter. Inference: 0.0285 s/iter. Eval: 0.0003 s/iter. Total: 0.0296 s/iter. ETA=0:00:02\n",
      "[03/30 13:57:28 d2.evaluation.evaluator]: Total inference time: 0:00:53.248210 (0.029648 s / iter per device, on 1 devices)\n",
      "[03/30 13:57:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:51 (0.028444 s / iter per device, on 1 devices)\n",
      "[03/30 13:57:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[03/30 13:57:28 d2.evaluation.coco_evaluation]: Saving results to /workspace/output/output_new_res030_03.30.13.51/inference/coco_instances_results.json\n",
      "[03/30 13:57:29 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "[03/30 13:57:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[03/30 13:57:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.55 seconds.\n",
      "[03/30 13:57:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[03/30 13:57:30 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.15 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "[03/30 13:57:30 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 3.530 | 13.287 | 0.530  | 3.629 | 0.826 | 0.000 |\n",
      "[03/30 13:57:30 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
      "| category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|\n",
      "| DT         | 7.059 | TT         | 0.000 |\n",
      "[03/30 13:57:30 d2.engine.defaults]: Evaluation results for thesis_030_val in csv format:\n",
      "[03/30 13:57:30 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[03/30 13:57:30 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[03/30 13:57:30 d2.evaluation.testing]: copypaste: 3.5297,13.2869,0.5303,3.6286,0.8260,0.0000\n",
      "[03/30 13:58:34 d2.utils.events]:  eta: 0:00:36  iter: 399  total_loss: 0.6689  loss_cls: 0.212  loss_box_reg: 0.2406  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.1238  validation_loss: 0.6494  time: 0.3595  data_time: 0.0610  lr: 0.015964  max_mem: 5394M\n",
      "[03/30 13:58:41 d2.utils.events]:  eta: 0:00:29  iter: 419  total_loss: 0.7195  loss_cls: 0.2318  loss_box_reg: 0.2735  loss_rpn_cls: 0.1303  loss_rpn_loc: 0.09389  validation_loss: 0.6494  time: 0.3595  data_time: 0.0602  lr: 0.016763  max_mem: 5394M\n",
      "[03/30 13:58:49 d2.utils.events]:  eta: 0:00:21  iter: 439  total_loss: 0.6083  loss_cls: 0.1654  loss_box_reg: 0.1709  loss_rpn_cls: 0.1503  loss_rpn_loc: 0.08676  validation_loss: 0.6494  time: 0.3598  data_time: 0.0629  lr: 0.017562  max_mem: 5394M\n",
      "[03/30 13:58:56 d2.utils.events]:  eta: 0:00:14  iter: 459  total_loss: 0.6629  loss_cls: 0.1771  loss_box_reg: 0.2155  loss_rpn_cls: 0.09734  loss_rpn_loc: 0.1067  validation_loss: 0.6494  time: 0.3600  data_time: 0.0659  lr: 0.018362  max_mem: 5394M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30 13:59:03 d2.utils.events]:  eta: 0:00:07  iter: 479  total_loss: 0.6794  loss_cls: 0.2212  loss_box_reg: 0.2586  loss_rpn_cls: 0.1  loss_rpn_loc: 0.06771  validation_loss: 0.6494  time: 0.3599  data_time: 0.0622  lr: 0.019161  max_mem: 5394M\n",
      "[03/30 14:00:16 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.6766  loss_cls: 0.2248  loss_box_reg: 0.241  loss_rpn_cls: 0.1135  loss_rpn_loc: 0.08935  validation_loss: 0.7143  time: 0.3602  data_time: 0.0656  lr: 0.01996  max_mem: 5394M\n",
      "[03/30 14:00:16 d2.engine.hooks]: Overall training speed: 498 iterations in 0:02:59 (0.3602 s / it)\n",
      "[03/30 14:00:16 d2.engine.hooks]: Total training time: 0:08:05 (0:05:06 on hooks)\n",
      "WARNING [03/30 14:00:16 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/30 14:00:16 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/30 14:00:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[03/30 14:00:16 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/30 14:00:16 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "WARNING [03/30 14:00:16 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[03/30 14:00:16 d2.evaluation.evaluator]: Start inference on 1801 batches\n",
      "[03/30 14:00:16 d2.evaluation.evaluator]: Inference done 11/1801. Dataloading: 0.0008 s/iter. Inference: 0.0289 s/iter. Eval: 0.0002 s/iter. Total: 0.0299 s/iter. ETA=0:00:53\n",
      "[03/30 14:00:21 d2.evaluation.evaluator]: Inference done 171/1801. Dataloading: 0.0009 s/iter. Inference: 0.0286 s/iter. Eval: 0.0018 s/iter. Total: 0.0312 s/iter. ETA=0:00:50\n",
      "[03/30 14:00:26 d2.evaluation.evaluator]: Inference done 343/1801. Dataloading: 0.0008 s/iter. Inference: 0.0283 s/iter. Eval: 0.0010 s/iter. Total: 0.0302 s/iter. ETA=0:00:44\n",
      "[03/30 14:00:31 d2.evaluation.evaluator]: Inference done 513/1801. Dataloading: 0.0008 s/iter. Inference: 0.0284 s/iter. Eval: 0.0007 s/iter. Total: 0.0300 s/iter. ETA=0:00:38\n",
      "[03/30 14:00:36 d2.evaluation.evaluator]: Inference done 685/1801. Dataloading: 0.0009 s/iter. Inference: 0.0283 s/iter. Eval: 0.0006 s/iter. Total: 0.0298 s/iter. ETA=0:00:33\n",
      "[03/30 14:00:41 d2.evaluation.evaluator]: Inference done 857/1801. Dataloading: 0.0009 s/iter. Inference: 0.0283 s/iter. Eval: 0.0005 s/iter. Total: 0.0297 s/iter. ETA=0:00:27\n",
      "[03/30 14:00:46 d2.evaluation.evaluator]: Inference done 1023/1801. Dataloading: 0.0009 s/iter. Inference: 0.0284 s/iter. Eval: 0.0005 s/iter. Total: 0.0297 s/iter. ETA=0:00:23\n",
      "[03/30 14:00:51 d2.evaluation.evaluator]: Inference done 1195/1801. Dataloading: 0.0009 s/iter. Inference: 0.0283 s/iter. Eval: 0.0004 s/iter. Total: 0.0297 s/iter. ETA=0:00:17\n",
      "[03/30 14:00:56 d2.evaluation.evaluator]: Inference done 1364/1801. Dataloading: 0.0009 s/iter. Inference: 0.0284 s/iter. Eval: 0.0004 s/iter. Total: 0.0297 s/iter. ETA=0:00:12\n",
      "[03/30 14:01:01 d2.evaluation.evaluator]: Inference done 1531/1801. Dataloading: 0.0009 s/iter. Inference: 0.0284 s/iter. Eval: 0.0004 s/iter. Total: 0.0297 s/iter. ETA=0:00:08\n",
      "[03/30 14:01:06 d2.evaluation.evaluator]: Inference done 1702/1801. Dataloading: 0.0009 s/iter. Inference: 0.0284 s/iter. Eval: 0.0004 s/iter. Total: 0.0297 s/iter. ETA=0:00:02\n",
      "[03/30 14:01:09 d2.evaluation.evaluator]: Total inference time: 0:00:53.531843 (0.029806 s / iter per device, on 1 devices)\n",
      "[03/30 14:01:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:51 (0.028404 s / iter per device, on 1 devices)\n",
      "[03/30 14:01:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[03/30 14:01:10 d2.evaluation.coco_evaluation]: Saving results to /workspace/output/output_new_res030_03.30.13.51/inference/coco_instances_results.json\n",
      "[03/30 14:01:11 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.42s)\n",
      "creating index...\n",
      "index created!\n",
      "[03/30 14:01:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[03/30 14:01:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.71 seconds.\n",
      "[03/30 14:01:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[03/30 14:01:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.20 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "[03/30 14:01:12 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 4.976 | 17.274 | 0.741  | 5.186 | 0.388 | 0.000 |\n",
      "[03/30 14:01:12 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
      "| category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|\n",
      "| DT         | 9.951 | TT         | 0.000 |\n",
      "[03/30 14:01:12 d2.engine.defaults]: Evaluation results for thesis_030_val in csv format:\n",
      "[03/30 14:01:12 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[03/30 14:01:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[03/30 14:01:12 d2.evaluation.testing]: copypaste: 4.9756,17.2737,0.7412,5.1861,0.3882,0.0000\n"
     ]
    }
   ],
   "source": [
    "# start the training\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it all in a function to be able to build a loop for the different resolutions\n",
    "\n",
    "def train_detectron_standard(dataset_name_train, dataset_name_val, resolution):\n",
    "    \n",
    "    now = datetime.now() \n",
    "    output_dir = f\"/workspace/output/output_new_res{resolution}_{now.strftime('%m.%d.%H.%M')}\"\n",
    "\n",
    "    cfg = get_cfg()\n",
    "    \n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.OUTPUT_DIR = output_dir\n",
    "\n",
    "    cfg.DATASETS.TRAIN = (dataset_name_train)\n",
    "    cfg.DATASETS.TEST = (dataset_name_val,)\n",
    "\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[4, 8, 16, 32, 64]]\n",
    "    cfg.SOLVER.MAX_ITER = 30000\n",
    "    cfg.TEST.EVAL_PERIOD = 5000 # für unseren Evaluator\n",
    "    #cfg.TEST.INTERVAL = 400 # für Lukas Evaluator\n",
    "    #cfg.SOLVER.STEPS = (2000, 2500)\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    trainer = MyTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "    \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    \n",
    "    return cfg, trainer, predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/29 15:14:00 d2.engine.defaults]: Model:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING [03/29 15:14:00 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/29 15:14:00 d2.data.datasets.coco]: Loaded 11696 images in COCO format from /workspace/data/labels_train.json\n",
      "[03/29 15:14:00 d2.data.build]: Removed 0 images with no usable annotations. 11696 images left.\n",
      "[03/29 15:14:01 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "[03/29 15:14:01 d2.data.build]: Using training sampler TrainingSampler\n",
      "[03/29 15:14:01 d2.data.common]: Serializing 11696 elements to byte tensors and concatenating them all ...\n",
      "[03/29 15:14:01 d2.data.common]: Serialized dataset takes 5.84 MiB\n",
      "WARNING [03/29 15:14:01 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "[03/29 15:14:01 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "WARNING [03/29 15:14:01 d2.data.datasets.coco]: \n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "[03/29 15:14:01 d2.data.datasets.coco]: Loaded 1801 images in COCO format from /workspace/data/labels_val.json\n",
      "[03/29 15:14:01 d2.data.common]: Serializing 1801 elements to byte tensors and concatenating them all ...\n",
      "[03/29 15:14:01 d2.data.common]: Serialized dataset takes 0.92 MiB\n",
      "[03/29 15:14:01 d2.checkpoint.c2_model_loading]: Renaming Caffe2 weights ......\n",
      "[03/29 15:14:01 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up:\n",
      "| Names in Model    | Names in Checkpoint      | Shapes                                          |\n",
      "|:------------------|:-------------------------|:------------------------------------------------|\n",
      "| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |\n",
      "| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "backbone.fpn_lateral2.{bias, weight}\n",
      "backbone.fpn_lateral3.{bias, weight}\n",
      "backbone.fpn_lateral4.{bias, weight}\n",
      "backbone.fpn_lateral5.{bias, weight}\n",
      "backbone.fpn_output2.{bias, weight}\n",
      "backbone.fpn_output3.{bias, weight}\n",
      "backbone.fpn_output4.{bias, weight}\n",
      "backbone.fpn_output5.{bias, weight}\n",
      "proposal_generator.rpn_head.anchor_deltas.{bias, weight}\n",
      "proposal_generator.rpn_head.conv.{bias, weight}\n",
      "proposal_generator.rpn_head.objectness_logits.{bias, weight}\n",
      "roi_heads.box_head.fc1.{bias, weight}\n",
      "roi_heads.box_head.fc2.{bias, weight}\n",
      "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
      "roi_heads.box_predictor.cls_score.{bias, weight}\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  fc1000.{bias, weight}\n",
      "  stem.conv1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/29 15:14:01 d2.engine.train_loop]: Starting training from iteration 0\n",
      "[03/29 15:14:09 d2.utils.events]:  eta: 3:01:14  iter: 19  total_loss: 0.9213  loss_cls: 0.1291  loss_box_reg: 0.004402  loss_rpn_cls: 0.6921  loss_rpn_loc: 0.093  time: 0.3608  data_time: 0.0771  lr: 0.00039962  max_mem: 6032M\n",
      "[03/29 15:14:16 d2.utils.events]:  eta: 3:00:39  iter: 39  total_loss: 0.8399  loss_cls: 0.1261  loss_box_reg: 0.004666  loss_rpn_cls: 0.6078  loss_rpn_loc: 0.07499  time: 0.3590  data_time: 0.0653  lr: 0.00079922  max_mem: 6033M\n",
      "[03/29 15:14:23 d2.utils.events]:  eta: 3:00:34  iter: 59  total_loss: 0.6104  loss_cls: 0.05824  loss_box_reg: 0.00354  loss_rpn_cls: 0.4561  loss_rpn_loc: 0.06981  time: 0.3597  data_time: 0.0662  lr: 0.0011988  max_mem: 6033M\n",
      "[03/29 15:14:30 d2.utils.events]:  eta: 3:00:51  iter: 79  total_loss: 0.4779  loss_cls: 0.05255  loss_box_reg: 0.005566  loss_rpn_cls: 0.3075  loss_rpn_loc: 0.1133  time: 0.3614  data_time: 0.0662  lr: 0.0015984  max_mem: 6033M\n",
      "[03/29 15:14:38 d2.utils.events]:  eta: 3:00:42  iter: 99  total_loss: 0.4292  loss_cls: 0.04961  loss_box_reg: 0.007682  loss_rpn_cls: 0.2619  loss_rpn_loc: 0.1163  time: 0.3617  data_time: 0.0644  lr: 0.001998  max_mem: 6033M\n",
      "[03/29 15:14:45 d2.utils.events]:  eta: 3:00:50  iter: 119  total_loss: 0.4069  loss_cls: 0.07462  loss_box_reg: 0.03421  loss_rpn_cls: 0.243  loss_rpn_loc: 0.09739  time: 0.3622  data_time: 0.0634  lr: 0.0023976  max_mem: 6033M\n",
      "[03/29 15:14:52 d2.utils.events]:  eta: 3:00:42  iter: 139  total_loss: 0.4396  loss_cls: 0.09933  loss_box_reg: 0.08664  loss_rpn_cls: 0.1701  loss_rpn_loc: 0.06105  time: 0.3615  data_time: 0.0636  lr: 0.0027972  max_mem: 6033M\n",
      "[03/29 15:14:59 d2.utils.events]:  eta: 3:00:47  iter: 159  total_loss: 0.5086  loss_cls: 0.1168  loss_box_reg: 0.09986  loss_rpn_cls: 0.1672  loss_rpn_loc: 0.08467  time: 0.3613  data_time: 0.0653  lr: 0.0031968  max_mem: 6033M\n",
      "[03/29 15:15:07 d2.utils.events]:  eta: 3:00:57  iter: 179  total_loss: 0.5719  loss_cls: 0.1443  loss_box_reg: 0.1365  loss_rpn_cls: 0.1503  loss_rpn_loc: 0.1053  time: 0.3620  data_time: 0.0654  lr: 0.0035964  max_mem: 6033M\n",
      "[03/29 15:15:14 d2.utils.events]:  eta: 3:01:15  iter: 199  total_loss: 0.5774  loss_cls: 0.1489  loss_box_reg: 0.1478  loss_rpn_cls: 0.1453  loss_rpn_loc: 0.1093  time: 0.3620  data_time: 0.0664  lr: 0.003996  max_mem: 6033M\n",
      "[03/29 15:15:21 d2.utils.events]:  eta: 3:01:18  iter: 219  total_loss: 0.6005  loss_cls: 0.1787  loss_box_reg: 0.1794  loss_rpn_cls: 0.1368  loss_rpn_loc: 0.08233  time: 0.3626  data_time: 0.0668  lr: 0.0043956  max_mem: 6033M\n",
      "[03/29 15:15:29 d2.utils.events]:  eta: 3:01:18  iter: 239  total_loss: 0.5549  loss_cls: 0.1686  loss_box_reg: 0.1766  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.1189  time: 0.3629  data_time: 0.0657  lr: 0.0047952  max_mem: 6033M\n",
      "[03/29 15:15:36 d2.utils.events]:  eta: 3:01:08  iter: 259  total_loss: 0.6932  loss_cls: 0.2011  loss_box_reg: 0.207  loss_rpn_cls: 0.1322  loss_rpn_loc: 0.1128  time: 0.3631  data_time: 0.0629  lr: 0.0051948  max_mem: 6033M\n",
      "[03/29 15:15:43 d2.utils.events]:  eta: 3:01:01  iter: 279  total_loss: 0.7486  loss_cls: 0.2344  loss_box_reg: 0.2599  loss_rpn_cls: 0.145  loss_rpn_loc: 0.1349  time: 0.3628  data_time: 0.0636  lr: 0.0055944  max_mem: 6033M\n",
      "[03/29 15:15:50 d2.utils.events]:  eta: 3:00:48  iter: 299  total_loss: 0.6098  loss_cls: 0.1967  loss_box_reg: 0.2103  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.09842  time: 0.3623  data_time: 0.0613  lr: 0.005994  max_mem: 6033M\n",
      "[03/29 15:15:57 d2.utils.events]:  eta: 3:00:40  iter: 319  total_loss: 0.6078  loss_cls: 0.2001  loss_box_reg: 0.2211  loss_rpn_cls: 0.09214  loss_rpn_loc: 0.05565  time: 0.3618  data_time: 0.0641  lr: 0.0063936  max_mem: 6033M\n",
      "[03/29 15:16:05 d2.utils.events]:  eta: 3:00:42  iter: 339  total_loss: 0.6353  loss_cls: 0.2243  loss_box_reg: 0.249  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.0592  time: 0.3623  data_time: 0.0671  lr: 0.0067932  max_mem: 6033M\n",
      "[03/29 15:16:12 d2.utils.events]:  eta: 3:00:48  iter: 359  total_loss: 0.634  loss_cls: 0.205  loss_box_reg: 0.2396  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.06646  time: 0.3628  data_time: 0.0686  lr: 0.0071928  max_mem: 6033M\n",
      "[03/29 15:16:19 d2.utils.events]:  eta: 3:00:46  iter: 379  total_loss: 0.6732  loss_cls: 0.2293  loss_box_reg: 0.274  loss_rpn_cls: 0.07914  loss_rpn_loc: 0.05756  time: 0.3627  data_time: 0.0673  lr: 0.0075924  max_mem: 6033M\n",
      "[03/29 15:16:27 d2.utils.events]:  eta: 3:00:38  iter: 399  total_loss: 0.6535  loss_cls: 0.2068  loss_box_reg: 0.2541  loss_rpn_cls: 0.09903  loss_rpn_loc: 0.0745  time: 0.3625  data_time: 0.0648  lr: 0.007992  max_mem: 6033M\n"
     ]
    }
   ],
   "source": [
    "# train the model for all our resolutions\n",
    "\n",
    "resolution_set = ['030', '035','040','045','050','070','100']\n",
    "\n",
    "for res in resolution_set:\n",
    "\n",
    "    #define the names \n",
    "    dataset_name_train = \"tower_train_\" + str(res) + \"1\"\n",
    "    dataset_name_val = \"tower_val_\" + str(res) + \"1\"\n",
    "\n",
    "    try: \n",
    "        # if it throws an error that name is already registered, just change the name... \n",
    "        register_coco_instances(dataset_name_train, {}, \"/workspace/data/labels_train.json\", \"/workspace/data/data_\"+str(res)+\"/train/data\")\n",
    "        register_coco_instances(dataset_name_val, {}, \"/workspace/data/labels_val.json\", \"/workspace/data/data_\"+str(res)+\"/val/data\")\n",
    "\n",
    "        #MetadataCatalog.get(dataset_name_train).set(thing_classes=[\"distribution\", \"transmission\"])\n",
    "        #MetadataCatalog.get(dataset_name_val).set(thing_classes=[\"distribution\", \"transmission\"])\n",
    "    \n",
    "    except: \n",
    "        regis_num += 1\n",
    "        dataset_name_train += str(regis_num)\n",
    "        dataset_name_val += str(regis_num)\n",
    "\n",
    "        # if it throws an error that name is already registered, just change the name... \n",
    "        register_coco_instances(dataset_name_train, {}, \"/workspace/data/labels_train.json\", \"/workspace/data/data_\"+str(res)+\"/train/data\")\n",
    "        register_coco_instances(dataset_name_val, {}, \"/workspace/data/labels_val.json\",  \"/workspace/data/data_\"+str(res)+\"/val/data\")\n",
    "        #MetadataCatalog.get(dataset_name_train).set(thing_classes=[\"distribution\", \"transmission\"])\n",
    "        #MetadataCatalog.get(dataset_name_val).set(thing_classes=[\"distribution\", \"transmission\"])\n",
    "\n",
    "    configuration, train_obj, predictor_obj = train_detectron_standard(dataset_name_train, dataset_name_val, res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sample(dataset_name, n=1):\n",
    "    dataset_custom = DatasetCatalog.get(dataset_name)\n",
    "    dataset_custom_metadata = MetadataCatalog.get(dataset_name)\n",
    "    \n",
    "    for s in random.sample(dataset_custom, n):\n",
    "        img = cv2.imread(s[\"file_name\"])\n",
    "        v = Visualizer(img[:, :, ::-1], metadata=dataset_custom_metadata, scale=0.5)\n",
    "        v = v.draw_dataset_dict(s)\n",
    "        plt.figure(figsize=(15,20))\n",
    "        plt.imshow(v.get_image())\n",
    "        plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(dataset_dicts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m3\u001b[39m):  \n\u001b[1;32m      7\u001b[0m     im \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data_030/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_or_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor_obj\u001b[49m(im)  \u001b[38;5;66;03m# format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     v \u001b[38;5;241m=\u001b[39m Visualizer(im[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     11\u001b[0m                    metadata\u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtower_val1\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[1;32m     12\u001b[0m                    scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m \n\u001b[1;32m     13\u001b[0m                    \u001b[38;5;66;03m#,instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m     out \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mdraw_instance_predictions(outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor_obj' is not defined"
     ]
    }
   ],
   "source": [
    "val_or_train = \"train\" # write a string here (either \"val\" or \"train\")\n",
    "location = \"\"\n",
    "predict_path = '/workspace/data'\n",
    "dataset_dicts = json.load(open(f'{predict_path}/labels_{val_or_train}.json'))\n",
    "\n",
    "for d in random.sample(dataset_dicts['images'], 3):  \n",
    "    im = cv2.imread(f'{base_path}/data_030/{val_or_train}/data/{d[\"file_name\"]}')\n",
    "\n",
    "    outputs = predictor_obj(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata= MetadataCatalog.get(\"tower_val1\"), \n",
    "                   scale=0.5 \n",
    "                   #,instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inspect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/workspace/data/data_030/val/data/AR_3258.1283105585248_669.62722839057085_166.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TEST[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imshow(\"some\", out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.imshow"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
